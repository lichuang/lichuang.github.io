<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>codedump的网络日志 on codedump的网络日志</title>
    <link>https://www.codedump.info/</link>
    <description>Recent content in codedump的网络日志 on codedump的网络日志</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 16 Jan 2022 10:00:54 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>博客系列文章索引</title>
      <link>https://www.codedump.info/post/20200122-series-pages/</link>
      <pubDate>Wed, 22 Jan 2020 14:36:00 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20200122-series-pages/</guid>
      <description>

&lt;p&gt;在博客已经写了很多文章了，有一些文章独立成体，有一些则是系列文章来讲述一个主题，在这里将这些系列文章整理下来，本页面将不定期更新。&lt;/p&gt;

&lt;h1 id=&#34;linux系统相关&#34;&gt;Linux系统相关&lt;/h1&gt;

&lt;h2 id=&#34;面向应用开发者的系统指南&#34;&gt;面向应用开发者的系统指南&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200501-system-guide-for-application-programmer/&#34;&gt;《面向应用开发者的系统指南》导论&amp;amp;目录&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;基础篇&#34;&gt;基础篇&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200128-systemtap-by-example/&#34;&gt;通过实例快速入门Systemtap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200218-linux-traceevent/&#34;&gt;Systemtap中内核trace事件的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cpu篇&#34;&gt;CPU篇&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200502-sgfap-process/&#34;&gt;进程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200503-sgfap-process-schedule/&#34;&gt;进程调度&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200503-sgfap-process-systemtap/&#34;&gt;使用systemtap分析进程的行为&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200516-sgfap-syscall/&#34;&gt;系统调用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200522-sgfap-softirq/&#34;&gt;软中断&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;分布式相关&#34;&gt;分布式相关&lt;/h1&gt;

&lt;h2 id=&#34;etcd及raft原理&#34;&gt;etcd及Raft原理&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180921-raft/&#34;&gt;Raft算法原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180922-etcd-raft/&#34;&gt;etcd Raft库解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20181125-etcd-server/&#34;&gt;Etcd存储的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20210515-raft/&#34;&gt;Etcd Raft库的工程化实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20210628-etcd-wal/&#34;&gt;Etcd Raft库的日志存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20211011-raft-propose-prev-term/&#34;&gt;为什么Raft协议不能提交之前任期的日志？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20220101-etcd3.5-joint-consensus/&#34;&gt;etcd 3.5版本的joint consensus实现解析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;存储引擎&#34;&gt;存储引擎&lt;/h1&gt;

&lt;h2 id=&#34;理论基础&#34;&gt;理论基础&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200609-btree-1/&#34;&gt;B树、B+树索引算法原理（上）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200615-btree-2/&#34;&gt;B树、B+树索引算法原理（下）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;sqlite&#34;&gt;sqlite&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20211217-sqlite-btree-0/&#34;&gt;sqlite3.36版本 btree实现（零）- 起步及概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20211217-sqlite-btree-1-pagecache/&#34;&gt;sqlite3.36版本 btree实现（一）- 管理页面缓存&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20211218-sqlite-btree-2-concurrency-control/&#34;&gt;sqlite3.36版本 btree实现（二）- 并发控制框架&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20211222-sqlite-btree-3-journal/&#34;&gt;sqlite3.36版本 btree实现（三）- journal文件备份机制&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;leveldb&#34;&gt;leveldb&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190215-leveldb/&#34;&gt;Leveldb代码阅读笔记&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;boltdb&#34;&gt;boltdb&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200625-boltdb-1/&#34;&gt;boltdb 1.3.0实现分析（一）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200711-boltdb-2/&#34;&gt;boltdb 1.3.0实现分析（二）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200725-boltdb-3/&#34;&gt;boltdb 1.3.0实现分析（三）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200726-boltdb-4/&#34;&gt;boltdb 1.3.0实现分析（四）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;缓存服务&#34;&gt;缓存服务&lt;/h1&gt;

&lt;h2 id=&#34;memcached&#34;&gt;memcached&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20210701-memcached/&#34;&gt;Memcached的存储原理解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20210812-memcached/&#34;&gt;Memcached的存储原理解析（续）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;系统设计相关&#34;&gt;系统设计相关&lt;/h1&gt;

&lt;h2 id=&#34;im服务器设计&#34;&gt;IM服务器设计&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190608-im-design-base/&#34;&gt;IM服务器设计-基础&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190608-im-msg-storage/&#34;&gt;IM服务器设计-消息存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190818-im-msg-gate/&#34;&gt;IM服务器设计-网关接入层 &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20191013-im-msg-out-of-order/&#34;&gt;IM服务器设计-如何解决消息的乱序&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;服务调用&#34;&gt;服务调用&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190629-service-history/&#34;&gt;服务调用的演进历史&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;多核编程&#34;&gt;多核编程&lt;/h1&gt;

&lt;h2 id=&#34;内存模型&#34;&gt;内存模型&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20191214-cxx11-memory-model-1/&#34;&gt;C++11中的内存模型上篇 - 内存模型基础&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20191214-cxx11-memory-model-2/&#34;&gt;C++11中的内存模型下篇 - C++11支持的几种内存模型&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;源码解析类&#34;&gt;源码解析类&lt;/h1&gt;

&lt;h2 id=&#34;etcd&#34;&gt;Etcd&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180922-etcd-raft/&#34;&gt;etcd Raft库解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20181125-etcd-server/&#34;&gt;Etcd存储的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;nginx-openresty&#34;&gt;Nginx &amp;amp;&amp;amp; OpenResty&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190103-nginx-config-parse/&#34;&gt;Nginx源码阅读笔记-配置解析流程 &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190131-nginx-master-worker/&#34;&gt;Nginx源码阅读笔记-Master Woker进程模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190131-nginx-event/&#34;&gt;Nginx源码阅读笔记-事件处理模块&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190131-nginx-read-http-request/&#34;&gt;Nginx源码阅读笔记-接收HTTP请求流程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190212-nginx-http-config/&#34;&gt;Nginx源码阅读笔记-查询HTTP配置流程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190213-nginx-process-http-request/&#34;&gt;Nginx源码阅读笔记-处理HTTP请求&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190214-nginx-memory-pool/&#34;&gt;Nginx源码阅读笔记-内存池的设计&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190501-lua-stream/&#34;&gt;OpenResty Lua Stream实现分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;zeromq&#34;&gt;Zeromq&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190209-zeromq-lockfree-queue/&#34;&gt;zeromq所谓的“无锁消息队列”&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;redis&#34;&gt;Redis&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190409-redis-sentinel/&#34;&gt;redis高可用原理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;glog&#34;&gt;Glog&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190729-glog/&#34;&gt;glog C++版本代码分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;libuv&#34;&gt;Libuv&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190123-libuv/&#34;&gt;Libuv代码简单分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;读书笔记&#34;&gt;读书笔记&lt;/h1&gt;

&lt;h2 id=&#34;数据密集型应用系统设计&#34;&gt;《数据密集型应用系统设计》&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20181118-ddia-chapter05-replication/&#34;&gt;《数据密集型应用系统设计》第五章数据复制笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20181124-ddia-chapter06-partitioning/&#34;&gt;《数据密集型应用系统设计》第六章数据分区笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190403-ddia-chapter07-transaction/&#34;&gt;《数据密集型应用系统设计》第七章《事务》笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190405-ddia-chapter08-the-trouble-with-distributed-system/&#34;&gt;《数据密集型应用系统设计》第八章《分布式系统的挑战》笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190406-ddia-chapter09-consistency-and-consensus/&#34;&gt;《数据密集型应用系统设计》第九章《一致性与共识》笔记 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;杂&#34;&gt;杂&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190324-how-to-read-code/&#34;&gt;如何阅读一份源代码？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200605-how-to-read-code-v2020/&#34;&gt;如何阅读一份源代码？（2020年版）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>周刊第1期：开刊，数字化生活数据</title>
      <link>https://www.codedump.info/post/20220116-weekly-1/</link>
      <pubDate>Sun, 16 Jan 2022 10:00:54 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20220116-weekly-1/</guid>
      <description>

&lt;h1 id=&#34;为什么会写周刊&#34;&gt;为什么会写周刊&lt;/h1&gt;

&lt;p&gt;我为写周刊这个事情思考了小一阵子。&lt;/p&gt;

&lt;p&gt;列举了好几个优点和缺点。比如，优点有能以输出来倒逼自己的输入，缺点有我的积累是否能够足以支撑我每周写一点东西，以及这种有明确时间限制的输出，是否会给我带来心智负担，等等。再比如，以往的博客内容都是很“硬”的技术内容，周刊不可能也不会每周都更新硬技术文章，会不会导致读者群有点分裂。&lt;/p&gt;

&lt;p&gt;思考到最后，我还是决定写周刊。&lt;/p&gt;

&lt;p&gt;从去年开始远程工作，大部分时间都在家里。由于我又很宅，网购也足够的发达，这又让我更宅了。然而，“物理”意义上的活动范围变小，并不意味着“逻辑”上能触达的范围也变小了，实际情况是，由于把通勤时间节省下来，我有更多时间看书、跑步了。所以，我需要一种方式，能输出我看到的一些东西，来与外界发生交流。&lt;/p&gt;

&lt;p&gt;我在微博上看到了这么两句话，也反向让我坚定了这么做的意义。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;（&lt;a href=&#34;https://weibo.com/1244214071/LagQ8fzm0&#34;&gt;宋一松SYS的微博&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;社交媒体在我看来最大的价值：它是最开放的peer review system&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://weibo.com/5339148412/L6LhDE7Zu&#34;&gt;硅谷王川的微博&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;让读书产生好处的最简单办法是，一旦有灵感和想法之后，马上写出来，公开发布在社交媒体上，即使不成熟也没关系。写的过程也是自己深度思考的一个步骤，外人的有价值评论可帮你不断推敲，或给你带来新的线索，积累多了自然会出深刻的洞见。一个人孤立封闭的傻读写笔记，很难迅速提高思考深度。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;周刊于我的意义，就是能定期把自己想到、看到的事情都公开出去，反向的让自己定期整理、输出，这是我突破“物理”界限和人交流的手段之一。内容将会以自己的一些想法、业界的动态、推荐、读书、影视等为准，与我写的其他技术文章相比，不会这么“硬”。&lt;/p&gt;

&lt;p&gt;另外，写周刊还有一个好处，之前有很多想法、念头会散落在各种社交平台这样的新媒体上，实际对整理、汇总、索引等也不好，把念头汇之于文章，用这种更老式的传播方式可以更好得记录下来。&lt;/p&gt;

&lt;h1 id=&#34;数字化生活数据&#34;&gt;数字化生活数据&lt;/h1&gt;

&lt;p&gt;既然谈到了周刊做为个人对外输出的一个手段，我就想起最近几年一直在做的事情：数字化各种生活数据。&lt;/p&gt;

&lt;p&gt;做过一阵子时序数据库的开发，有些人当时并不太了解什么叫做“时序数据”，于是我当时想了一下生活里的类比，其实“时序数据”就好比我们的“流水账”：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;9:00：起床，洗漱。&lt;/li&gt;
&lt;li&gt;9:30：工作。&lt;/li&gt;
&lt;li&gt;12:00：午餐。&lt;/li&gt;
&lt;li&gt;&amp;hellip;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所谓“数字化生活数据”，也就是按照时间顺序把这些记录下来。“时序数据”，说白了就是时间强相关的数据，以时间为第一维度来存储、查询的数据。&lt;/p&gt;

&lt;p&gt;“数字化各种生活数据”，这么做的好处有什么？在我看来，有这些好处：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;形成上面的“时序数据”之后，可以方便进行聚合、统计、查询。&lt;/li&gt;
&lt;li&gt;定期还能依赖于各种工具来进行汇总、回顾等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;比如，我每天都在用的&lt;code&gt;DayOne&lt;/code&gt; app，就有一个“每年今日”的功能，提醒我以往的这一天我都记录了什么，这就是基于这些时序数据的汇总；再比如，每到年底各种app都会自动给用户汇总生成这一年的用户行为统计数据，告诉你最喜欢的歌、和你爱好最匹配的人，等等。&lt;/p&gt;

&lt;p&gt;这些功能，都依赖于你之前上报过的“时序数据”。&lt;/p&gt;

&lt;p&gt;今天要推荐的两个相关的开源项目，作者都是&lt;a href=&#34;https://github.com/yihong0618&#34;&gt;yihong0618 (yihong)&lt;/a&gt;，他也是“数字化生活数据”的提倡者，可以在小宇宙里收听他的访问：&lt;a href=&#34;https://www.xiaoyuzhoufm.com/episode/619896e8138b51cbd78f3912&#34;&gt;S01E03 专访 YiHong，自学成为流行开源项目作者的点滴 - 开源面对面 | 小宇宙 - 听播客，上小宇宙&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;第一个项目是&lt;a href=&#34;https://github.com/yihong0618/running_page&#34;&gt;yihong0618/running_page: Make your own running home page&lt;/a&gt;，可以抓取主流的几个跑步app数据，生成好看的跑步数据展示页面：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15976103/98808834-c02f1d80-2457-11eb-9a7c-70e91faa5e30.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;第二个项目是&lt;a href=&#34;https://github.com/yihong0618/GitHubPoster&#34;&gt;yihong0618/GitHubPoster: Make everything a GitHub svg poster and Skyline!&lt;/a&gt;，可以将在各种app上（twitter、多邻国、扇贝等）上报的数据可视化：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/yihong0618/GitHubPoster/raw/main/examples/summary_2021.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/yihong0618/GitHubPoster/raw/main/examples/strava_circular.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可视化展示，会给人很直观的反馈。人的行为如果能得到即时的反馈，某种程度上会有正向作用。以我来说，去年9月份开始跑步，也是fork了这个项目每天生成跑步的可视化数据到我的网站，时不时会看一看数据，知道自己都做了哪些努力，潜移默化的会让我有一些成就感。&lt;/p&gt;

&lt;p&gt;一个想法：未来会不会有一天，可以拿到一个人所有的数字化数据，在这个人去世之后以这些数据重塑回一个“一样”的人？&lt;/p&gt;

&lt;h1 id=&#34;推荐&#34;&gt;推荐&lt;/h1&gt;

&lt;h2 id=&#34;算法可视化交互动图&#34;&gt;算法可视化交互动图&lt;/h2&gt;

&lt;p&gt;既然这一期讲到了数字化数据之后方便交互演示，就接着推荐旧金山大学制作的系列算法可视化交互动图，包括常见的堆、栈、队列等。学习算法数据结构的时候，如果能图示化的展现其变化过程，理解起来就会更顺畅，在学习B+Tree算法的时候，我就用过这里的演示来理解流程。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cs.usfca.edu/~galles/visualization/Algorithms.html&#34;&gt;Data Structure Visualization&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;b-tree中的-b-是什么意思&#34;&gt;B-Tree中的“B”是什么意思？&lt;/h2&gt;

&lt;p&gt;上面提到了B+Tree，B-Tree数据结构中的“B”到底是什么单词的缩写？&lt;/p&gt;

&lt;p&gt;下意识的，都认为是“balance”的缩写，毕竟这是一个平衡的树形数据结构。但是其实，连几位发明人，也从来没有解释过。&lt;/p&gt;

&lt;p&gt;有可能是“boeing”的缩写，因为作者当时就职于波音公司；还有可能是第一作者Bayer的名字首字母。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;B-trees were invented by &lt;a href=&#34;https://en.wikipedia.org/wiki/Rudolf_Bayer&#34;&gt;Rudolf Bayer&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Edward_M._McCreight&#34;&gt;Edward M. McCreight&lt;/a&gt; while working at &lt;a href=&#34;https://en.wikipedia.org/wiki/Boeing&#34;&gt;Boeing Research Labs&lt;/a&gt;, for the purpose of efficiently managing index pages for large random-access files. The basic assumption was that indexes would be so voluminous that only small chunks of the tree could fit in main memory. Bayer and McCreight&amp;rsquo;s paper, &lt;em&gt;Organization and maintenance of large ordered indices&lt;/em&gt;,[&lt;a href=&#34;https://en.wikipedia.org/wiki/B-tree#cite_note-bayer-mccreight-1970-1&#34;&gt;1]&lt;/a&gt; was first circulated in July 1970 and later published in &lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Acta_Informatica&#34;&gt;Acta Informatica&lt;/a&gt;&lt;/em&gt;.[&lt;a href=&#34;https://en.wikipedia.org/wiki/B-tree#cite_note-FOOTNOTEBayerMcCreight1972-3&#34;&gt;3]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bayer and McCreight never explained what, if anything, the &lt;em&gt;B&lt;/em&gt; stands for: &lt;em&gt;Boeing&lt;/em&gt;, &lt;em&gt;balanced&lt;/em&gt;, &lt;em&gt;broad&lt;/em&gt;, &lt;em&gt;bushy&lt;/em&gt;, and &lt;em&gt;Bayer&lt;/em&gt; have been suggested.[&lt;a href=&#34;https://en.wikipedia.org/wiki/B-tree#cite_note-FOOTNOTEComer1979123_footnote_1-4&#34;&gt;4]&lt;/a&gt;[&lt;a href=&#34;https://en.wikipedia.org/wiki/B-tree#cite_note-herrenalb-5&#34;&gt;5]&lt;/a&gt;[&lt;a href=&#34;https://en.wikipedia.org/wiki/B-tree#cite_note-6&#34;&gt;6]&lt;/a&gt; McCreight has said that &amp;ldquo;the more you think about what the B in B-trees means, the better you understand B-trees.&amp;rdquo;[&lt;a href=&#34;https://en.wikipedia.org/wiki/B-tree#cite_note-herrenalb-5&#34;&gt;5]&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/B-tree&#34;&gt;B-tree - Wikipedia&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>etcd 3.5版本的joint consensus实现解析</title>
      <link>https://www.codedump.info/post/20220101-etcd3.5-joint-consensus/</link>
      <pubDate>Sat, 01 Jan 2022 15:02:50 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20220101-etcd3.5-joint-consensus/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;在以前的etcd实现中，“集群节点变更”这一功能，仅支持每次变更一个节点，最新的etcd已经能支持一次变更多个节点配置的功能了。本文将就这部分的实现进行解析。&lt;/p&gt;

&lt;h1 id=&#34;原理&#34;&gt;原理&lt;/h1&gt;

&lt;p&gt;Raft论文《CONSENSUS: BRIDGING THEORY AND PRACTICE》的第四章”集群成员变更“中，支持两种集群变更方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每次变更单节点，即“One Server Config Change”。&lt;/li&gt;
&lt;li&gt;多节点联合共识，即“Joint Consensus”。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文先就这两种实现方式进行原理上的讲解。&lt;/p&gt;

&lt;h2 id=&#34;集群节点变更的问题&#34;&gt;集群节点变更的问题&lt;/h2&gt;

&lt;p&gt;要保证Raft协议的安全性，就是要保证任意时刻，集群中只有唯一的&lt;code&gt;leader&lt;/code&gt;节点。如果不加限制条件，那么动态向当前运行集群增删节点的操作，有可能会导致存在多个&lt;code&gt;leader&lt;/code&gt;的情况。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20220101-etcd3.5-joint-Consensus/multi-server.png&#34; alt=&#34;集群节点变更问题&#34; title=&#34;集群节点变更问题&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;图中有两种颜色的配置，绿色表示旧的集群配置（&lt;code&gt;C_old&lt;/code&gt;），蓝色表示新的集群配置（&lt;code&gt;C_new&lt;/code&gt;），如果不加任何限制，直接将配置启用，由于不同的集群节点之间，存在时间差，那么可能出现这样的情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Server{1,2}：当前都使用旧的集群配置，所以可能选出server1为集群的leader。&lt;/li&gt;
&lt;li&gt;Server{3,4,5}：当前都使用新的集群配置，可能选出server3为集群的leader。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;由上图可以看到：如果不加任何限制，直接应用新的集群配置，由于时间差的原因，可能导致集群中出现两个不同leader的情况。&lt;/p&gt;

&lt;h2 id=&#34;单节点成员变更-one-server-confchange&#34;&gt;单节点成员变更（One Server ConfChange）&lt;/h2&gt;

&lt;p&gt;“单节点成员变更”，意指每次只添加或删除一个节点，这样就能保证集群的安全性，不会在同一时间出现多个&lt;code&gt;leader&lt;/code&gt;的情况。之所以能有这个保证，是因为每次变更一个节点，那么新旧两种配置的半数节点（majorrity）肯定存在交集。以下图来说明：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20220101-etcd3.5-joint-Consensus/one-server-confchange.png&#34; alt=&#34;单节点成员变更&#34; title=&#34;单节点成员变更&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;上图演示了向偶数或奇数的集群增删一个节点的所有可能情况。不论哪种情况，新旧配置都有交集，在每个任期只能投出一张票的情况下，是不会出现多&lt;code&gt;leader&lt;/code&gt;的情况的。&lt;/p&gt;

&lt;p&gt;有了上面的理论基础，下面来看&lt;code&gt;单节点集群变更&lt;/code&gt;的全流程，当下发集群节点变更配置时，新的配置会以一种特殊的日志方式进行提交，即：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;普通日志：半数通过，提交成功时，会传给应用层的状态机。&lt;/li&gt;
&lt;li&gt;配置变更类日志：半数通过，提交成功时，集群节点将以新的集群配置生效。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;将集群配置变更数据，序列化为日志数据，需要将日志类型标记为&lt;code&gt;集群配置变更&lt;/code&gt;类的日志，提交给&lt;code&gt;leader&lt;/code&gt;节点。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leader&lt;/code&gt;节点收到日志后，需要存储该日志的索引为&lt;code&gt;未完成的集群配置变更索引&lt;/code&gt;，像其它正常日志一样处理：先写本地的日志，再广播给集群的其他节点，半数应答则认为日志达成一致可以提交了。如果提交了这类日志，可以将前面保存的&lt;code&gt;未完成的集群配置变更索引&lt;/code&gt;置为空了。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;集群配置变更&lt;/code&gt;日志提交之后，对照新旧的集群变更数据，该添加到集群的添加到集群，该删除的节点停机。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要注意的是，同一时间只能有唯一一个&lt;code&gt;集群变更类日志&lt;/code&gt;存在，怎么保证这一点？就算是在&lt;code&gt;leader&lt;/code&gt;收到该类型日志时，判断&lt;code&gt;未完成的集群配置变更索引&lt;/code&gt;是否为空。&lt;/p&gt;

&lt;h2 id=&#34;多节点联合共识-joint-consensus&#34;&gt;多节点联合共识（Joint Consensus）&lt;/h2&gt;

&lt;p&gt;除了上面的单节点变更，有时候还需要一次提交多个节点的变更。但是按照前面的描述，如果一次提交多个节点，很可能会导致集群的安全性被破坏，即同时出现多个&lt;code&gt;leader&lt;/code&gt;的情况。因此，一次提交多节点时，就需要走&lt;code&gt;联合共识&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;所谓的&lt;code&gt;联合共识&lt;/code&gt;，就是将新旧配置的节点一起做为一个节点集合，只有该节点集合达成半数一致，才能认为日志可以提交，由于新旧两个集合做了合并，那么就不会出现多&lt;code&gt;leader&lt;/code&gt;的情况了。具体流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;leader&lt;/code&gt;收到成员变更请求，新集群节点集合为&lt;code&gt;C_new&lt;/code&gt;，当前集群节点集合为&lt;code&gt;C_old&lt;/code&gt;，此时首先会以新旧节点集合的交集&lt;code&gt;C_{old,new}&lt;/code&gt;做为一个&lt;code&gt;集群配置变更&lt;/code&gt;类的日志，走正常的日志提交流程。注意，这时候的日志，需要提交到&lt;code&gt;C_{old,new}&lt;/code&gt;中的所有节点。&lt;/li&gt;
&lt;li&gt;当&lt;code&gt;C_{old,new}&lt;/code&gt;集群变更日志提交之后，&lt;code&gt;leader&lt;/code&gt;节点再马上创建一个只有&lt;code&gt;C_new&lt;/code&gt;节点集合的&lt;code&gt;集群配置变更&lt;/code&gt;类日志，再次走正常的日志提交流程。这时候的日志，只需要提交到&lt;code&gt;C_new&lt;/code&gt;中的所有节点。&lt;/li&gt;
&lt;li&gt;当&lt;code&gt;C_new&lt;/code&gt;日志被提交之后，集群的配置就能切换到&lt;code&gt;C_new&lt;/code&gt;对应的新集群配置下了。而不在&lt;code&gt;C_new&lt;/code&gt;配置内的节点，将被移除。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以看到，&lt;code&gt;多节点联合共识&lt;/code&gt;的提交流程分为了两次提交：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;先提交新旧集合的交集&lt;code&gt;C_{old,new}&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;再提交新节点集合&lt;code&gt;C_new&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下图来说明，这几个阶段中，集群的安全性都得到了保证：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20220101-etcd3.5-joint-Consensus/Joint-Consensus.png&#34; alt=&#34;多节点联合共识&#34; title=&#34;多节点联合共识&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;C_{old,new}&lt;/code&gt;配置提交之前：在做个阶段，集群中的节点，要么处于&lt;code&gt;C_old&lt;/code&gt;配置下，要么处于&lt;code&gt;C_new,old&lt;/code&gt;配置之下。此时，如果集群的&lt;code&gt;leader&lt;/code&gt;节点宕机，那么将会基于&lt;code&gt;C_old&lt;/code&gt;或者&lt;code&gt;C_new,old&lt;/code&gt;配置来选出新的&lt;code&gt;leader&lt;/code&gt;，而不会仅仅基于&lt;code&gt;C_new&lt;/code&gt;，因此不会选出不同的&lt;code&gt;leader&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C_{old,new}&lt;/code&gt;配置提交之后，&lt;code&gt;C_new&lt;/code&gt;下发之前：如果这时候&lt;code&gt;leader&lt;/code&gt;宕机，只会基于&lt;code&gt;C_{old,new}&lt;/code&gt;的配置选出&lt;code&gt;leader&lt;/code&gt;，因此也不会选出不同的&lt;code&gt;leader&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C_new&lt;/code&gt;下发但还未提交时：如果这时候&lt;code&gt;leader&lt;/code&gt;宕机，只会基于&lt;code&gt;C_{old,new}&lt;/code&gt;或者&lt;code&gt;C_new&lt;/code&gt;的配置选出&lt;code&gt;leader&lt;/code&gt;，同时也不再会发给仅仅在&lt;code&gt;C_old&lt;/code&gt;中的节点了，所以无论是哪个配置，都需要得到&lt;code&gt;C_new&lt;/code&gt;的半数同意，因此不会选出不同的&lt;code&gt;leader&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C_new&lt;/code&gt;提交之后：此时集群中只有一种配置了，安全性得到了保证。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;实现&#34;&gt;实现&lt;/h1&gt;

&lt;p&gt;了解了原理之后，可以来具体看etcd 3.5中这部分的实现了。&lt;/p&gt;

&lt;h2 id=&#34;learner&#34;&gt;learner&lt;/h2&gt;

&lt;p&gt;首先需要了解&lt;code&gt;learner&lt;/code&gt;这个概念，在Raft中，这类型节点有以下特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;与其他节点一样，能正常接收&lt;code&gt;leader&lt;/code&gt;同步的日志。&lt;/li&gt;
&lt;li&gt;但是&lt;code&gt;learner&lt;/code&gt;节点没有投票权，即：投票时会忽略掉这类型节点。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;也因为这样，所以&lt;code&gt;learner&lt;/code&gt;节点也常被称为&lt;code&gt;non voter&lt;/code&gt;类型的节点。&lt;/p&gt;

&lt;p&gt;那么，什么时候需要&lt;code&gt;learner&lt;/code&gt;节点呢？如果一个节点刚加入集群，此时要追上当前的进度，需要一段时间，但是由于这个新节点的加入，导致集群的不可用风险增加了，即原来三节点的集群，挂了一个还能工作；加入这个新节点之后，新节点还没赶上进度，那么可能挂了一个节点集群就不可用了。&lt;/p&gt;

&lt;p&gt;所以，对于新加入的节点，可以先将它置为&lt;code&gt;learner&lt;/code&gt;类型，即：只同步日志，不参与投票。等到进度追上了，再变成正常的有投票权的节点。&lt;/p&gt;

&lt;p&gt;一个节点，需要添加到集群中变成集群的&lt;code&gt;learner&lt;/code&gt;，或者从原集群的&lt;code&gt;voter&lt;/code&gt;变成&lt;code&gt;learner&lt;/code&gt;，也都不能直接添加，而是必须走前面正常的&lt;code&gt;集群变更&lt;/code&gt;流程，即：集群中的&lt;code&gt;learner&lt;/code&gt;集合也是集群节点配置的一部分。&lt;/p&gt;

&lt;h2 id=&#34;数据结构&#34;&gt;数据结构&lt;/h2&gt;

&lt;h3 id=&#34;每个节点的进度数据-progress结构体&#34;&gt;每个节点的进度数据（Progress结构体）&lt;/h3&gt;

&lt;p&gt;etcd中，使用&lt;code&gt;Progress&lt;/code&gt;结构体来存储集群中每个节点当前的进度数据，包括以下成员：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;日志索引类成员：

&lt;ul&gt;
&lt;li&gt;Match索引&lt;/li&gt;
&lt;li&gt;Next索引。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;当前的进度状态：

&lt;ul&gt;
&lt;li&gt;探针状态（probe）：节点刚加入，或者刚恢复都是该状态。&lt;/li&gt;
&lt;li&gt;正常同步状态（replicate）。&lt;/li&gt;
&lt;li&gt;同步快照状态：当前没有在进行日志同步，而是在同步快照。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;IsLearner：标记当前该节点是否是&lt;code&gt;learner&lt;/code&gt;状态的节点。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中，&lt;code&gt;进度状态&lt;/code&gt;类似于TCP协议中的流控，不在这里做阐述了；两个&lt;code&gt;日志索引&lt;/code&gt;也是Raft论文中用于存储节点进度数据的索引，也不在这里阐述了；唯独需要注意的是&lt;code&gt;IsLearner&lt;/code&gt;，该成员标记了该节点是否&lt;code&gt;learner&lt;/code&gt;节点。&lt;/p&gt;

&lt;h3 id=&#34;集群配置-config结构体&#34;&gt;集群配置（Config结构体）&lt;/h3&gt;

&lt;p&gt;集群配置使用&lt;code&gt;Config&lt;/code&gt;结构体来保存，其成员如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Voters：包括新旧两个配置。新旧两个配置的节点集合合集，成为当前的所有节点集合。

&lt;ul&gt;
&lt;li&gt;[0]：&lt;code&gt;incoming&lt;/code&gt;配置，新的集群配置。&lt;/li&gt;
&lt;li&gt;[1]：&lt;code&gt;outgoing&lt;/code&gt;配置，旧的集群配置。一般这个集合为空，这个集合不为空时，存储的是变更之前旧的集群配置，因此不为空时表示当前有未提交的&lt;code&gt;joint consensus&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Learners：当前的learner集合，learner集合和前面的所有节点集合交集必须为空集。&lt;/li&gt;
&lt;li&gt;LearnersNext：集群配置提交后，从原集群的&lt;code&gt;voter&lt;/code&gt;降级为&lt;code&gt;learner&lt;/code&gt;的节点集合。&lt;/li&gt;
&lt;li&gt;AutoLeave：该配置为true时，自动让新配置生效。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前面原理的部分，只讲解了新旧配置的变更流程，但是在etcd的实现中，集群配置里除了新旧配置，还多了存储&lt;code&gt;Learner&lt;/code&gt;节点的两种集合，这会让情况变得更复杂一些。&lt;/p&gt;

&lt;p&gt;如果一个节点要在新的集群配置中变成&lt;code&gt;Learner&lt;/code&gt;，需要区分两种情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;该节点原先是集群的&lt;code&gt;voter&lt;/code&gt;：并不是直接加入到&lt;code&gt;Learner&lt;/code&gt;集合的，而是首先提交到&lt;code&gt;LearnersNext&lt;/code&gt;集合中，同样也是等待这个新的集群配置被成功之后，才移动到&lt;code&gt;Learner&lt;/code&gt;集合中。否则，如果直接修改加入到&lt;code&gt;Learner&lt;/code&gt;集合中，可能导致集群的安全性受到影响。比如一个三节点{a,b,c}的集群，原先有只挂了一个节点还能继续工作；现在由于各种原因，想将节点c降级为&lt;code&gt;learner&lt;/code&gt;，将节点d加入到集群中，如果直接将c节点降级为&lt;code&gt;learner&lt;/code&gt;，就会导致在这个流程里一旦一个节点不可用，整个集群就不可用了。&lt;/li&gt;
&lt;li&gt;该节点原先不是集群中的成员：这种节点由于之前并不存在，并不影响集群的安全性，这时候可以直接移动到&lt;code&gt;Learner&lt;/code&gt;中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20220101-etcd3.5-joint-Consensus/add-learner.png&#34; alt=&#34;单节点成员变更&#34; title=&#34;单节点成员变更&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;所以：&lt;code&gt;Voters&lt;/code&gt;两个配置，与两种&lt;code&gt;Learner&lt;/code&gt;集合，必须满足以下的关系（见函数&lt;code&gt;checkInvariants&lt;/code&gt;）：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在&lt;code&gt;LearnersNext&lt;/code&gt;中的节点，表示未提交的集群配置中待添加&lt;code&gt;learner&lt;/code&gt;节点集合的节点：

&lt;ul&gt;
&lt;li&gt;必须出现在&lt;code&gt;outgoing&lt;/code&gt;中，即必须出现在旧的集群配置中。&lt;/li&gt;
&lt;li&gt;该节点的进度数据中，&lt;code&gt;IsLearner&lt;/code&gt;为False。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;Learners&lt;/code&gt;中的节点，表示当前集群的&lt;code&gt;learner&lt;/code&gt;节点集合：

&lt;ul&gt;
&lt;li&gt;不能出现在任一个&lt;code&gt;voter&lt;/code&gt;集合中（&lt;code&gt;incoming&lt;/code&gt;和&lt;code&gt;outgoing&lt;/code&gt;）中，即不能出现在新、旧的集群配置中。&lt;/li&gt;
&lt;li&gt;该节点的进度数据中，&lt;code&gt;IsLearner&lt;/code&gt;为True。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;集群整体监控-progresstracker结构体&#34;&gt;集群整体监控（ProgressTracker结构体）&lt;/h3&gt;

&lt;p&gt;有了节点的进度数据（Progress结构体），以及集群配置数据（Config结构体），整个集群的进度管控，都放在了结构体&lt;code&gt;ProgressTracker&lt;/code&gt;中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Config：存储当前集群的配置。&lt;/li&gt;
&lt;li&gt;Progress：以节点ID为键，值为&lt;code&gt;Progress结构体&lt;/code&gt;的map。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;负责提交配置流程-changer结构体&#34;&gt;负责提交配置流程（Changer结构体）&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;Changer&lt;/code&gt;属于提交流程中存储中间状态的数据结构，对其输入：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当前的&lt;code&gt;ProgressTracker结构体&lt;/code&gt;数据，即当前的配置和进度数据。&lt;/li&gt;
&lt;li&gt;要进行的变更数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;输出：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需要提交的配置数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Raft最终以其输入的配置数据，来生成&lt;code&gt;集群配置类型&lt;/code&gt;的日志，走正常的日志提交流程。提交成功之后，配置生效。&lt;/p&gt;

&lt;h2 id=&#34;流程&#34;&gt;流程&lt;/h2&gt;

&lt;p&gt;按照前面原理部分的分析，&lt;code&gt;多节点联合共识&lt;/code&gt;的提交分为两步：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;先提交新旧集合的交集&lt;code&gt;C_{old,new}&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;再提交新节点集合&lt;code&gt;C_new&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际在etcd中，也是这样做的，分为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;EnterJoint：将新旧集合的交集提交。&lt;/li&gt;
&lt;li&gt;LeaveJoint：提交新节点集合。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;enterjoint&#34;&gt;EnterJoint&lt;/h3&gt;

&lt;p&gt;该流程在&lt;code&gt;Changer::EnterJoint&lt;/code&gt;中实现：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;拷贝当前&lt;code&gt;ProgressTracker&lt;/code&gt;结构体当前的进度（&lt;code&gt;Progress&lt;/code&gt;）和配置数据（&lt;code&gt;Config&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;如果当前有在提交的配置，就返回退出，因为同一时间只能有一个未提交的配置变更。如何判断当前是否有未提交的配置？看&lt;code&gt;Config&lt;/code&gt;中的&lt;code&gt;outgoing&lt;/code&gt;（即&lt;code&gt;voters[1]&lt;/code&gt;）是否为空。我们下面再详细解释。&lt;/li&gt;
&lt;li&gt;下面，以第一步拷贝的配置数据，生成新的配置数据：

&lt;ul&gt;
&lt;li&gt;将&lt;code&gt;Config&lt;/code&gt;中的&lt;code&gt;incoming&lt;/code&gt;数据拷贝到&lt;code&gt;outgoing&lt;/code&gt;中，即先保存当前的配置到&lt;code&gt;outgoing&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;遍历需要修改的配置，根据不同的操作类型做操作，生成新的配置：&lt;/li&gt;
&lt;li&gt;如果要删除某节点，调用&lt;code&gt;Changer::remove&lt;/code&gt;函数：

&lt;ul&gt;
&lt;li&gt;从&lt;code&gt;incoming&lt;/code&gt;中删除该节点。&lt;/li&gt;
&lt;li&gt;从&lt;code&gt;Learner&lt;/code&gt;以及&lt;code&gt;LearnerNext&lt;/code&gt;集合中删除该节点。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果增加&lt;code&gt;voter&lt;/code&gt;，调用&lt;code&gt;Changer::makeVoter&lt;/code&gt;函数：

&lt;ul&gt;
&lt;li&gt;该节点的进度数据中，&lt;code&gt;IsLearner&lt;/code&gt;变为&lt;code&gt;false&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;从&lt;code&gt;Learner&lt;/code&gt;以及&lt;code&gt;LearnerNext&lt;/code&gt;集合中删除该节点。&lt;/li&gt;
&lt;li&gt;将节点ID加入&lt;code&gt;incoming&lt;/code&gt;集合中。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果增加&lt;code&gt;learner&lt;/code&gt;，调用&lt;code&gt;Changer::makeLearner&lt;/code&gt;函数：

&lt;ul&gt;
&lt;li&gt;调用&lt;code&gt;Changer::remove&lt;/code&gt;函数先删除该节点。&lt;/li&gt;
&lt;li&gt;判断是否在&lt;code&gt;outgoing&lt;/code&gt;配置中有该节点，表示该节点是降级节点：&lt;/li&gt;
&lt;li&gt;有：表示在新配置下变成了&lt;code&gt;learner&lt;/code&gt;，但是此时并不能直接变成&lt;code&gt;learner&lt;/code&gt;，所以这种情况下该节点加入到了配置的&lt;code&gt;LearnersNext&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;否则，说明是新增节点，直接加入到&lt;code&gt;Learner&lt;/code&gt;集合中。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;上面生成了新旧配置的交集配置，以这个配置数据生成日志来进行提交，生效后应用该配置。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;leavejoint&#34;&gt;LeaveJoint&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;拷贝当前&lt;code&gt;ProgressTracker&lt;/code&gt;结构体当前的进度（&lt;code&gt;Progress&lt;/code&gt;）和配置数据（&lt;code&gt;Config&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;下面，以第一步拷贝的配置数据，生成新的配置数据：

&lt;ul&gt;
&lt;li&gt;遍历&lt;code&gt;LearnersNext&lt;/code&gt;集合，将其中的节点：&lt;/li&gt;
&lt;li&gt;加入&lt;code&gt;Learner&lt;/code&gt;集合。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;IsLearner&lt;/code&gt;置为true。&lt;/li&gt;
&lt;li&gt;清空&lt;code&gt;LearnerNext&lt;/code&gt;集合。&lt;/li&gt;
&lt;li&gt;遍历&lt;code&gt;outgoing&lt;/code&gt;节点集合：&lt;/li&gt;
&lt;li&gt;如果一个节点，既不在&lt;code&gt;incoming&lt;/code&gt;集合中，也不在&lt;code&gt;Learner&lt;/code&gt;集合中，则认为在新的配置中没有该节点了，删除其进度数据。&lt;/li&gt;
&lt;li&gt;清空&lt;code&gt;outgoing&lt;/code&gt;节点集合。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;上面生成了新旧配置的交集配置，以这个配置数据生成日志来进行提交，生效后应用该配置。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;例子&#34;&gt;例子&lt;/h3&gt;

&lt;p&gt;以一个例子来说明上面的流程，假设集群当前的配置为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;投票节点：{1,2}。&lt;/li&gt;
&lt;li&gt;Learner节点：{}。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;新提交的配置中有以下三个操作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新增投票节点：{3}。&lt;/li&gt;
&lt;li&gt;降级节点{2}为&lt;code&gt;learner&lt;/code&gt;节点。&lt;/li&gt;
&lt;li&gt;新增Learner节点：{4}。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要再次强调：&lt;strong&gt;无论是&lt;code&gt;EnterJoint&lt;/code&gt;还是&lt;code&gt;LeaveJoint&lt;/code&gt;操作，都并不会让配置马上生效，而是生成了一份待提交的配置，Raft拿到这份配置生成一个提交配置变更的日志，走正常的日志提交流程，待这条日志被半数通过时，才生效该配置。&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;阶段&lt;/th&gt;
&lt;th&gt;incoming节点集合&lt;/th&gt;
&lt;th&gt;outgoing节点集合&lt;/th&gt;
&lt;th&gt;Learner节点集合&lt;/th&gt;
&lt;th&gt;LearnerNext节点集合&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;提交之前&lt;/td&gt;
&lt;td&gt;{1,2}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;EnterJoint&lt;/td&gt;
&lt;td&gt;{1,3}&lt;/td&gt;
&lt;td&gt;{1,2}&lt;/td&gt;
&lt;td&gt;{4}&lt;/td&gt;
&lt;td&gt;{2}&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LeaveJoint&lt;/td&gt;
&lt;td&gt;{1,3}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;{2,4}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;读者可以对着上面的流程，以这个例子来理解一下。&lt;/p&gt;

&lt;h2 id=&#34;自动提交&#34;&gt;自动提交&lt;/h2&gt;

&lt;p&gt;这里还有一个细节，即&lt;code&gt;多节点联合共识&lt;/code&gt;是一个两阶段的提交流程：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;EnterJoint&lt;/code&gt;之后，&lt;code&gt;outgoing&lt;/code&gt;节点集合变为一个非空集合，这时候不再能提交新的配置，需要到&lt;code&gt;LeaveJoint&lt;/code&gt;之后，才会清空这个集合。&lt;/li&gt;
&lt;li&gt;在etcd中，&lt;code&gt;LeaveJoint&lt;/code&gt;操作，并不见得会自动执行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;是否在&lt;code&gt;EnterJoint&lt;/code&gt;之后自动执行&lt;code&gt;LeaveJoint&lt;/code&gt;，取决于当前提交的&lt;code&gt;Config&lt;/code&gt;结构体中的&lt;code&gt;AutoLeave&lt;/code&gt;字段，它有两种可能，见&lt;code&gt;ConfChangeTransition&lt;/code&gt;枚举类型的定义：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ConfChangeTransitionAuto&lt;/code&gt;和&lt;code&gt;ConfChangeTransitionJointImplicit&lt;/code&gt;：如果是这两种情况，都会自动做转换。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ConfChangeTransitionJointExplicit&lt;/code&gt;：需要用户手动执行&lt;code&gt;LeaveJoint&lt;/code&gt;操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;（见函数&lt;code&gt;ConfChangeV2::EnterJoint&lt;/code&gt;的实现。）&lt;/p&gt;

&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;《CONSENSUS: BRIDGING THEORY AND PRACTICE》chapter4”Cluster membership changes“&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://etcd.io/docs/v3.3/learning/learner/&#34;&gt;Learner | etcd&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>sqlite3.36版本 btree实现（三）- journal文件备份机制</title>
      <link>https://www.codedump.info/post/20211222-sqlite-btree-3-journal/</link>
      <pubDate>Wed, 22 Dec 2021 19:15:31 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20211222-sqlite-btree-3-journal/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;在上一节中（&lt;a href=&#34;https://www.codedump.info/post/20211218-sqlite-btree-2-concurrency-control/&#34;&gt;sqlite3.36版本 btree实现（二）- 并发控制框架&lt;/a&gt;），已经讲解了sqlite中的并发控制机制，里面会涉及到一个“备份页面”的模块：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;备份所有在一个事务中会修改到的页面。&lt;/li&gt;
&lt;li&gt;出错时回滚页面内容。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;里面也提到，有两种备份文件的机制：journal文件，以及WAL文件。今天首先讲解journal文件的实现，它的效率会更低一些，也正是因为这个原因后续推出了更优的WAL机制。&lt;/p&gt;

&lt;h2 id=&#34;相关命令&#34;&gt;相关命令&lt;/h2&gt;

&lt;p&gt;sqlite中，可以使用&lt;code&gt;PRAGMA journal_mode&lt;/code&gt;来修改备份文件机制，包括以下几种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;delete：默认模式。在该模式下，在事务结束时，备份文件将被删除。&lt;/li&gt;
&lt;li&gt;truncate：日志文件被阶段为零字节长度。&lt;/li&gt;
&lt;li&gt;persist：日志文件被留在原地，但头部被重写，表明日志不再有效。&lt;/li&gt;
&lt;li&gt;memory：日志记录保留在内存中，而不是磁盘上。&lt;/li&gt;
&lt;li&gt;off：不保留任何备份记录。&lt;/li&gt;
&lt;li&gt;wal：采用wal形式的备份文件。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中，前面三种delete、truncate、persist都是使用journal文件来实现的备份，区别在于事务结束之后的对备份文件的处理罢了。&lt;/p&gt;

&lt;p&gt;本节首先讲解journal文件，下一节讲解wal备份文件。&lt;/p&gt;

&lt;h1 id=&#34;journal文件格式&#34;&gt;journal文件格式&lt;/h1&gt;

&lt;p&gt;journal文件的文件名规则是：与同目录的数据库文件同名，但是多了字符串“-journal”为后缀。比如数据库文件是“test.db”，那么对应的journal文件名为“test.db-journal”。&lt;/p&gt;

&lt;h2 id=&#34;文件头&#34;&gt;文件头&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;偏移量&lt;/th&gt;
&lt;th&gt;大小&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;文件头的magic number: 0xd9, 0xd5, 0x05, 0xf9, 0x20, 0xa1, 0x63, 0xd7&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;journal文件中的页面数量，如果为-1表示一直到journal文件尾&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;每次计算校验值时算出来的随机数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;在开始备份前数据库文件的页面数量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;磁盘扇区大小&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;journal文件中的页面大小&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这里大部分的字段都自解释了，不必多做解释，唯一需要注意的是随机数，因为这是用来后续校验备份页面的字段，这将在后面结合流程来说明。&lt;/p&gt;

&lt;h2 id=&#34;页面内容&#34;&gt;页面内容&lt;/h2&gt;

&lt;p&gt;紧跟着文件头之后，journal文件还有一系列页面数据组成的内容，其中每部分的结构如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;偏移量&lt;/th&gt;
&lt;th&gt;大小&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;页面编号&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;备份的页面内容，N以页面大小为准，其中每页面大小在文件头中定义&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;N+4&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;页面的校验值&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;由上面分析可见，整个journal文件是这样来组织的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;28字节的文件头。&lt;/li&gt;
&lt;li&gt;页面数据组成的数组，其中数组每个元素的大小为：4+页面大小（N）+4。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211222-sqlite-btree-3-journal/journal.png&#34; alt=&#34;journal文件结构&#34; title=&#34;journal文件结构&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h1 id=&#34;流程&#34;&gt;流程&lt;/h1&gt;

&lt;h2 id=&#34;判断页面是否已经备份&#34;&gt;判断页面是否已经备份&lt;/h2&gt;

&lt;p&gt;启动一个写事务的时候，可能会修改多个页面，但是这其中可能有些修改，修改的是同一个页面的内容，因此这种情况下只需要对这个页面备份一次即可。&lt;/p&gt;

&lt;p&gt;如何知道页面是否已经被备份过？页面管理器通过一个位图数据结构来保存这个信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Bitvec *pInJournal;         /* One bit for each page in the database file */
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;计算页面校验值&#34;&gt;计算页面校验值&lt;/h2&gt;

&lt;p&gt;计算一个页面校验码的流程在函数&lt;code&gt;pager_cksum&lt;/code&gt;中实现，其核心逻辑是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;以随机算出的校验值为初始值，这个初始值就是存在journal文件头中偏移量为[12,16]的数据。&lt;/li&gt;
&lt;li&gt;从后往前遍历页面数据，每隔200字节取一个u32类型的值，累加起来。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有了这样的关联，进行数据恢复时就能马上通过文件头存储的随机数，计算出来页面的数据是否准确。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;static u32 pager_cksum(Pager *pPager, const u8 *aData){
  u32 cksum = pPager-&amp;gt;cksumInit;         /* Checksum value to return */
  int i = pPager-&amp;gt;pageSize-200;          /* Loop counter */
  // 每隔200字节算一个值累加起来
  while( i&amp;gt;0 ){
    cksum += aData[i];
    i -= 200;
  }
  return cksum;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;备份页面&#34;&gt;备份页面&lt;/h2&gt;

&lt;p&gt;有了前面计算校验值、以位图来判断页面是否已经备份过的了解，现在开始将备份页面的流程。&lt;/p&gt;

&lt;p&gt;每一次需要修改一个页面之前，都会调用函数&lt;code&gt;pager_write&lt;/code&gt;，这样就能在修改之前首先备份这个页面的内容。&lt;/p&gt;

&lt;p&gt;要区分两种不同的页面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果页面编号比当前数据库文件的页面数量小，说明是已有页面，需要走备份页面的流程。&lt;/li&gt;
&lt;li&gt;否则，说明是新增页面，新增的页面不需要备份，只需要修改该页面的标志位是需要落盘（&lt;code&gt;PGHDR_NEED_SYNC&lt;/code&gt;），并且放入脏页面链表即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第二种情况是新增页面，没有备份的需求，这里就不做解释。&lt;/p&gt;

&lt;p&gt;这里具体解释第一种情况，即备份已有页面的流程，其主要逻辑如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先根据前面的&lt;code&gt;pInJournal&lt;/code&gt;位图数据，传入页面编号，判断这个页面是否备份过，如果已经备份过，不做任何操作。&lt;/li&gt;
&lt;li&gt;否则说明需要备份页面，将进入函数&lt;code&gt;pagerAddPageToRollbackJournal&lt;/code&gt;中将该页面内容备份写入journal文件：

&lt;ul&gt;
&lt;li&gt;调用前面提到的&lt;code&gt;pager_cksum&lt;/code&gt;函数，计算页面的校验值。&lt;/li&gt;
&lt;li&gt;按照上面解释的journal文件格式，依次写入页面编号、页面内容、第一步计算出来的校验值。&lt;/li&gt;
&lt;li&gt;由于备份了页面，所以要把这个新增的备份页面编号写入&lt;code&gt;pInJournal&lt;/code&gt;位图数据。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;备份页面的例子&#34;&gt;备份页面的例子&lt;/h3&gt;

&lt;p&gt;我们以一个例子来说明备份页面的流程，假设写事务执行时，情况如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当时数据库的页面数量为100，即有100个页面。&lt;/li&gt;
&lt;li&gt;写事务执行时，依次做了如下的修改：

&lt;ul&gt;
&lt;li&gt;修改页面10的一处内容。&lt;/li&gt;
&lt;li&gt;修改页面20的一处内容。&lt;/li&gt;
&lt;li&gt;修改页面10的一处内容，注意这里跟第一次修改属于同一个页面的不同位置。&lt;/li&gt;
&lt;li&gt;新增页面101。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;那么，对照上面的流程，这四次页面修改在调用函数&lt;code&gt;pager_write&lt;/code&gt;时，情况是这样的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;修改页面10的一处内容：由于在备份页面位图中查不到页面编号为10的页面，且页面10小于当前数据库文件的页面数量100，属于修改当前已有页面，于是将这个页面备份到journal文件，完事了之后将这个页面编号10加入位图。&lt;/li&gt;
&lt;li&gt;修改页面20的一处内容：类似的，也是备份了页面20的内容，同时将20加入位图。&lt;/li&gt;
&lt;li&gt;修改页面10的一处内容：这一次虽然也是要修改已有页面，但是由于在位图中找到这个页面编号，说明在这一次事务中已经备份过这个页面了，于是不再需要备份操作，直接返回。&lt;/li&gt;
&lt;li&gt;新增页面101：发现该页面的编号101，大于当前数据库页面数量100，属于新增页面，于是不进行备份，只是加入到脏页面链表中同时标记需要落盘。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;即：在这一次写事务执行的过程中，虽然需要修改4处内容，实际备份文件两次，新增页面一次。&lt;/p&gt;

&lt;h2 id=&#34;何时落盘&#34;&gt;何时落盘&lt;/h2&gt;

&lt;p&gt;前面备份待修改页面的流程中，备份的页面内容只是写到了备份文件里，实际还并没有执行&lt;code&gt;sync&lt;/code&gt;操作强制落盘，只要没有落盘就还是存在备份数据损坏的情况。&lt;/p&gt;

&lt;p&gt;在上一节的（&lt;a href=&#34;https://www.codedump.info/post/20211218-sqlite-btree-2-concurrency-control/&#34;&gt;sqlite3.36版本 btree实现（二）- 并发控制框架&lt;/a&gt;），备份文件内容落盘是放在第七步做的，此时对用户空间的页面内容的修改已经完成了，不清楚这一流程的可以回头再看看上一节的内容。&lt;/p&gt;

&lt;p&gt;具体到journal文件的机制，这一步是放在函数&lt;code&gt;pager_end_transaction&lt;/code&gt;进行的，&lt;code&gt;pager_end_transaction&lt;/code&gt;函数就是上面介绍的：在事务修改完毕用户空间的页面之后，被调用。&lt;/p&gt;

&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;

&lt;p&gt;本节讲解了journal文件的实现机制，从最早的sqlite btree实现时，备份页面的机制就一直使用journal机制，从这里的分析可以看到，这种机制很“朴素”，性能也并不好，所以后续在3.7版本的sqlite中引入了更优的WAL实现机制。&lt;/p&gt;

&lt;p&gt;本节也并没有把所有journal文件实现机制都详细描述，只是把最核心的文件结构以及备份流程做了讲解，因为并不想在这个性能不高的机制上着墨更多，有兴趣的读者可以自行阅读相关代码。&lt;/p&gt;

&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sqlite.org/fileformat.html&#34;&gt;Database File Format&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>sqlite3.36版本 btree实现（二）- 并发控制框架</title>
      <link>https://www.codedump.info/post/20211218-sqlite-btree-2-concurrency-control/</link>
      <pubDate>Sat, 18 Dec 2021 15:25:05 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20211218-sqlite-btree-2-concurrency-control/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;按照之前起步阶段对sqlite btree整体架构的分析，“页面管理模块”分为以下几个子模块：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;页面缓存管理。&lt;/li&gt;
&lt;li&gt;崩溃恢复，又分为以下两种实现：

&lt;ul&gt;
&lt;li&gt;journal文件。&lt;/li&gt;
&lt;li&gt;WAL文件。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;页面管理模块。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前面一节讲完了“页面缓存管理”的实现，按照自下往上的顺序，就应该到“崩溃恢复”了。“崩溃恢复”核心的工作是：在真正修改页面内容之前，将还未修改的页面内容备份，这样一旦系统在事务过程中宕机崩溃，就可以用这部分内容回滚还未落盘的事务修改，让系统回到一个正确的状态。&lt;/p&gt;

&lt;p&gt;“崩溃恢复”有两种实现方式，在早期使用的journal文件，这种方式性能不高；在3.7版本之后，sqlite引入了WAL文件来保存页面内容，这样做的效率更高。&lt;/p&gt;

&lt;p&gt;本节就讲解这部分内容，在对这部分内容有一个总体的了解之后，继续讲解崩溃恢复的总体流程。后面的章节再具体分析journal以及WAL的实现。&lt;/p&gt;

&lt;h1 id=&#34;写事务的流程&#34;&gt;写事务的流程&lt;/h1&gt;

&lt;p&gt;（以下流程分析，按照sqlite官网中的文档&lt;a href=&#34;https://sqlite.org/atomiccommit.html&#34;&gt;Atomic Commit In SQLite&lt;/a&gt;进行讲解，图例也全部引用自官网。）&lt;/p&gt;

&lt;p&gt;sqlite的写事务，分为以下几个流程：&lt;/p&gt;

&lt;h2 id=&#34;1-初始化阶段-initial-state&#34;&gt;1、初始化阶段（Initial State）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-0.gif&#34; alt=&#34;初始化&#34; title=&#34;初始化&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;如上图中，从右到左即是系统的磁盘、操作系统缓冲区、用户空间三部分，其中磁盘和操作系统缓冲区有划分为多块的空间，每一块在sqlite里被称为一个&lt;code&gt;sector&lt;/code&gt;，蓝色部分表示是修改之前的数据。&lt;/p&gt;

&lt;p&gt;这是系统初始时的样子。&lt;/p&gt;

&lt;h2 id=&#34;2-拿到读锁-acquiring-a-read-lock&#34;&gt;2、拿到读锁（Acquiring A Read Lock）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-1.gif&#34; alt=&#34;拿到读锁&#34; title=&#34;拿到读锁&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;在开始进行写操作之前，sqlite必须先把待修改的页面加载内存中（这就是上一节“页面缓存管理器”做的事情），后续的修改其实也是首先修改这部分加载到内存中的页面内容，因为可能一次提交会修改同一个页面中的多处内容，最后才把页面内容落盘。&lt;/p&gt;

&lt;p&gt;所以，这一步所要做的，是首先拿到数据库文件的读锁（shared lock），需要说明的是，这个读锁是数据库级别的锁。同一时间，系统中可以存在多个读锁，但是只要系统中还存在读锁，就不再允许分配出新的写锁（write lock）。&lt;/p&gt;

&lt;h2 id=&#34;3-读出页面的内容到页面缓存&#34;&gt;3、读出页面的内容到页面缓存&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-2.gif&#34; alt=&#34;读出页面内容&#34; title=&#34;读出页面内容&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;拿到读锁之后，就可以把需要进行修改的页面读出来到用户空间的页面缓存了。从上图来看，读了三个页面的内容出来，也就是例子中的写操作要修改三个页面的内容。&lt;/p&gt;

&lt;h2 id=&#34;4-拿到保留锁-obtaining-a-reserved-lock&#34;&gt;4、拿到保留锁（Obtaining A Reserved Lock）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-3.gif&#34; alt=&#34;拿到保留锁&#34; title=&#34;拿到保留锁&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;在进行修改之前，还需要首先将前面拿到的读锁（shared lock）升级为保留锁（reserved lock）。同一时间，系统中保留锁可以和多个读锁并存，但是只能存在最多一个保留锁。这个机制，保证了同一时间只能有一个进程对数据库进行写操作。&lt;/p&gt;

&lt;p&gt;需要说明的是，拿到保留锁的进程，还并没有真正进行数据的修改操作，只是用这个锁，挡住了其它打算进行写操作的进程。&lt;/p&gt;

&lt;h2 id=&#34;5-创建回滚用的备份文件-creating-a-rollback-journal-file&#34;&gt;5、创建回滚用的备份文件（Creating A Rollback Journal File）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-4.gif&#34; alt=&#34;创建回滚用的备份文件&#34; title=&#34;创建回滚用的备份文件&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;到了这一步，首先将待修改的页面内容备份。官网原文写的是备份到回滚用的journal文件中，我们上面提到备份机制除了journal文件还有wal文件，所以这里的“journal文件”应该更泛化的理解为“保存到备份文件中”，这种备份文件可能是journal文件，也可能是wal文件，视机制而定。&lt;/p&gt;

&lt;p&gt;上图中，用户空间的页面写入到了备份文件中，注意到备份文件上面有一小块绿色的部分，理解为备份文件的meta信息即可。&lt;/p&gt;

&lt;p&gt;另外还需要特别说明的是，从上图中可以看到，备份工作也仅仅到了操作系统缓冲区，即图中的中间部分，而磁盘部分还是空的。即到了这一步，即便是备份页面的内容，也还并没有sync到磁盘中，即只进行了备份的写操作，并没有强制落盘。&lt;/p&gt;

&lt;h2 id=&#34;6-修改用户空间的页面内容-changing-database-pages-in-user-space&#34;&gt;6、修改用户空间的页面内容（Changing Database Pages In User Space）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-5.gif&#34; alt=&#34;修改用户空间的页面内容&#34; title=&#34;修改用户空间的页面内容&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;到了这一步，修改进程用户空间的页面内容，即上图中的橙色部分，就是修改后的用户空间数据。由于每个进程都有自己的用户空间（即便是同一个进程下的不同线程，对sqlite而言，只要使用的是不同的连接（connection），那么连接背后的页面缓冲区就不一样），所以这些修改并不被其它进程所见。这样，写进程做自己的修改，其它读进程读到的还是修改之前的页面数据。&lt;/p&gt;

&lt;h2 id=&#34;7-将备份文件的内容落盘-flushing-the-rollback-journal-file-to-mass-storage&#34;&gt;7、将备份文件的内容落盘（Flushing The Rollback Journal File To Mass Storage）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-6.gif&#34; alt=&#34;将备份文件的内容落盘&#34; title=&#34;将备份文件的内容落盘&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;上面的第5步提到，当时还只是写页面内容到备份文件中，这一步接在修改页面内容之后，将修改之前的页面内容sync到磁盘中。&lt;/p&gt;

&lt;h2 id=&#34;8-拿到排他锁-obtaining-an-exclusive-lock&#34;&gt;8、拿到排他锁（Obtaining An Exclusive Lock）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-7.gif&#34; alt=&#34;拿到排他锁&#34; title=&#34;拿到排他锁&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;前面的步骤做完，达到了这样的效果：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对于待修改页面，修改之前的内容已经保存到了备份文件中。&lt;/li&gt;
&lt;li&gt;需要修改的内容，已经体现在了进程的用户空间的页面缓存里。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此时，需要将页面修改的内容写到数据库文件中。在修改数据库文件之前，还需要首先拿到排他锁（exclusive lock）。拿到排他锁，又分为两步：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先拿到悬锁（pending lock）。&lt;/li&gt;
&lt;li&gt;将悬锁升级为排他锁。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为什么要首先拿到悬锁？同一时间内，悬锁和前面的保留锁一样，只能存在最多一个；但是不同的是，悬锁不允许再分配新的读锁（shared lock），而保留锁没有这样的机制。换言之，在悬锁之前的所有读锁，可以继续读操作，悬锁会等待它们完成，再升级为排他锁；同时，只要系统中有悬锁，就不再允许有新的读操作，必须等待修改数据库完成才可以有新的读操作。&lt;/p&gt;

&lt;p&gt;这样的机制，避免了读操作时，读到了未提交的事务写到一半的数据。&lt;/p&gt;

&lt;h2 id=&#34;9-保存修改到数据库文件中-writing-changes-to-the-database-file&#34;&gt;9、保存修改到数据库文件中（Writing Changes To The Database File）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-8.gif&#34; alt=&#34;拿到排他锁&#34; title=&#34;拿到排他锁&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;拿到了排他锁之后，意味着此时系统中没有读操作、没有其他写操作，这时候可以放心将页面缓存中的内容落盘到数据库文件中了。&lt;/p&gt;

&lt;p&gt;同样需要注意的是，这一步的修改，还还只是到了操作系统的缓冲区，并不保证落盘到数据库文件中。&lt;/p&gt;

&lt;h2 id=&#34;10-落盘数据库文件修改-flushing-changes-to-mass-storage&#34;&gt;10、落盘数据库文件修改（Flushing Changes To Mass Storage）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-9.gif&#34; alt=&#34;落盘数据库文件修改&#34; title=&#34;落盘数据库文件修改&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;这一步，将对数据库文件的修改落盘。&lt;/p&gt;

&lt;h2 id=&#34;11-删除备份文件-deleting-the-rollback-journal&#34;&gt;11、删除备份文件（Deleting The Rollback Journal）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-A.gif&#34; alt=&#34;删除备份文件&#34; title=&#34;删除备份文件&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;至此，这一次写操作已经落盘到了数据库文件中，前面保存到备份文件中的数据可以清除了。清除备份文件内容，是一个比较费时的操作，具体实现由不同的机制去优化，后面讲到journal文件以及wal的实现时再展开描述。&lt;/p&gt;

&lt;h2 id=&#34;12-释放锁-releasing-the-lock&#34;&gt;12、释放锁（Releasing The Lock）&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/commit-B.gif&#34; alt=&#34;释放锁&#34; title=&#34;释放锁&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;写操作全部完成，备份文件也清除了，到了这一步就可以释放锁，以便后面其他的读写操作进来。&lt;/p&gt;

&lt;h1 id=&#34;写事务中涉及到的锁&#34;&gt;写事务中涉及到的锁&lt;/h1&gt;

&lt;p&gt;上面写事务流程中，依次会拿到以下类型的锁，下图中做一个简单的总结：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211218-sqlite-btree-2-concurrency-control/write_lock.png&#34; alt=&#34;写操作中涉及到的锁&#34; title=&#34;写操作中涉及到的锁&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h1 id=&#34;崩溃恢复流程&#34;&gt;崩溃恢复流程&lt;/h1&gt;

&lt;p&gt;上面的流程中，随时都可能因为系统崩溃而导致数据错乱的，因此一个写事务如果还未完成，重启时存储引擎需要识别出来，将还没有完成的事务进行回滚操作（rollback）。&lt;/p&gt;

&lt;p&gt;分为以下几种情况来处理：&lt;/p&gt;

&lt;h2 id=&#34;写备份数据之前失败&#34;&gt;写备份数据之前失败&lt;/h2&gt;

&lt;p&gt;如果系统在落盘备份数据之前失败，即前面的流程7之前失败，按照上面的流程来看，情况是这样的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;写事务的数据还停留在用户空间的页面缓存中，未落盘到数据库文件上（流程6）。&lt;/li&gt;
&lt;li&gt;在流程5，只是将数据写到备份文件，还没有强制刷盘，所以这时候崩溃，可能备份文件中的数据是损坏的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以在这种情况下重启，面对的是这样的情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据库文件：还在写事务之前的状态，因为写事务还未落盘。&lt;/li&gt;
&lt;li&gt;备份文件：可能损坏。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;于是，启动之后将校验备份文件是否完整，如果完整将重放一遍备份文件中的页面到数据库文件中；否则，只是简单的删除备份文件中的数据即可。&lt;/p&gt;

&lt;h2 id=&#34;写数据库文件时失败&#34;&gt;写数据库文件时失败&lt;/h2&gt;

&lt;p&gt;如果已经过了流程7，而在将页面缓存中的修改落盘到数据库文件的过程中，系统崩溃了，那么面临的是这样的情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据库文件肯定损坏了。&lt;/li&gt;
&lt;li&gt;写事务中被修改页面之前的内容，已经落盘到备份文件中了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;于是，启动恢复的时候，只需要将备份文件中的页面重放一遍到数据库文件即可将数据库文件恢复到写事务修改前的状态了。&lt;/p&gt;

&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;

&lt;p&gt;以上，就是sqlite中写事务的总体流程，以及重启恢复的流程，这里还并没有涉及到具体的代码细节，有了对总体流程的理解，后面再来分析具体的两种备份机制：journal以及wal的实现。&lt;/p&gt;

&lt;p&gt;另外，需要看到的是：sqlite中锁的粒度，都还是数据库级别的，现在我还不知道其它更高效的数据库所谓行锁的实现，留待以后吧。&lt;/p&gt;

&lt;h1 id=&#34;参考文档&#34;&gt;参考文档&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://sqlite.org/atomiccommit.html&#34;&gt;Atomic Commit In SQLite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sqlite.org/lockingv3.html&#34;&gt;File Locking And Concurrency In SQLite Version 3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>sqlite3.36版本 btree实现（一）- 管理页面缓存</title>
      <link>https://www.codedump.info/post/20211217-sqlite-btree-1-pagecache/</link>
      <pubDate>Fri, 17 Dec 2021 14:22:06 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20211217-sqlite-btree-1-pagecache/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;页面管理&lt;/code&gt;模块中，很重要的一个功能是缓存页面的内容在内存中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读页面：如果页面已经在内存，就不需要到文件中读出页面内容。&lt;/li&gt;
&lt;li&gt;写页面：如果页面已经在内存，那么对页面的修改就只需要修改页面在内存中的数据即可，被修改了但是还没有落盘的页面，被称为“脏页面（dirty page）“。这样，多次对某个页面的修改，可能最后只需要一次落盘即可。当然，对页面的修改，如果在还没有落盘之前，系统就崩溃了，这种情况下应该如何处理，这就是“崩溃恢复”模块做的事情了。本节中，将专注在“页面缓存”这个子模块的实现。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;既然要将页面缓存在内存中，就会涉及到几个功能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如何知道哪些页面已经被缓存在内存里了？&lt;/li&gt;
&lt;li&gt;缓存在内存中的页面如何组织管理？&lt;/li&gt;
&lt;li&gt;缓存页面使用的内存不够用时，应该如何处理？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们首先来了解一下“页面缓存”模块的总体划分：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211217-sqlite-btree-1-pagecache/pagecache.png&#34; alt=&#34;页面缓存功能的模块划分&#34; title=&#34;页面缓存功能的模块划分&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;按照上图的划分，页面缓存模块分为以下几部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;页面缓存管理器：实现了页面缓存的总体算法流程，以及提供对外的接口，但是具体到“页面缓存算法”的实现，则有赖于下面这个可用户定制的&lt;code&gt;sqlite3_pcache_methods2&lt;/code&gt;。这部分功能在代码&lt;code&gt;pcache.c&lt;/code&gt;中。&lt;/li&gt;
&lt;li&gt;页面缓存算法：用户可自己定制，只要实现&lt;code&gt;sqlite3_pcache_methods2&lt;/code&gt;结构体中的接口即可。系统中的默认实现，在文件&lt;code&gt;pcache1.c&lt;/code&gt;中。&lt;/li&gt;
&lt;li&gt;除此以外，还需要快速根据页面编号就能知道哪些页面已经被缓存的功能，这部分sqlite使用位图数据结构来实现，在文件&lt;code&gt;bitvec.c&lt;/code&gt;中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;页面缓存管理器，核心功能就是维护脏页面链表，缓存页面的管理，诸如根据页面编号查找页面、淘汰页面算法等，都由“页面缓存算法”来维护。可以这样来简单的理解上面的功能划分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;“页面缓存管理器”：定义了管理页面缓存的接口、总体流程，维护管理目前在用的脏页面。&lt;/li&gt;
&lt;li&gt;“页面缓存算法”：维护其它不在使用但还在内存中的页面，负责其淘汰、回收等实现。由“sqlite3_pcache_methods2”结构体实现，用户可以定制自己实现的“sqlite3_pcache_methods2”，系统也提供默认的实现。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211217-sqlite-btree-1-pagecache/page_cache_memory.png&#34; alt=&#34;两种页面的划分&#34; title=&#34;两种页面的划分&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;简而言之，如果把当前在内存中的页面划分为以下两类，那么：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当前在使用的页面：即与页面编号对应的页面，由“页面缓存管理器”维护。&lt;/li&gt;
&lt;li&gt;当前还未使用、但也在内存中的页面：即随时准备拿出来存储从磁盘中读出来的数据的页面，由“页面缓存算法”维护，比如淘汰、回收、复用等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面，就开始“页面缓存”这几部分功能的具体讲解。&lt;/p&gt;

&lt;h1 id=&#34;管理页面&#34;&gt;管理页面&lt;/h1&gt;

&lt;h2 id=&#34;页面相关的数据数据结构&#34;&gt;页面相关的数据数据结构&lt;/h2&gt;

&lt;p&gt;首先来看页面相关的数据结构，sqlite中使用&lt;code&gt;PgHdr&lt;/code&gt;结构体来在内存中描述一个页面：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
** Every page in the cache is controlled by an instance of the following
** structure.
*/
struct PgHdr {
  sqlite3_pcache_page *pPage;    /* Pcache object page handle */
  void *pData;                   /* Page data */
  void *pExtra;                  /* Extra content */
  PCache *pCache;                /* PRIVATE: Cache that owns this page */
  PgHdr *pDirty;                 /* Transient list of dirty sorted by pgno */
  Pager *pPager;                 /* The pager this page is part of */
  Pgno pgno;                     /* Page number for this page */
#ifdef SQLITE_CHECK_PAGES
  u32 pageHash;                  /* Hash of page content */
#endif
  u16 flags;                     /* PGHDR flags defined below */

  /**********************************************************************
  ** Elements above, except pCache, are public.  All that follow are 
  ** private to pcache.c and should not be accessed by other modules.
  ** pCache is grouped with the public elements for efficiency.
  */
  i16 nRef;                      /* Number of users of this page */
  PgHdr *pDirtyNext;             /* Next element in list of dirty pages */
  PgHdr *pDirtyPrev;             /* Previous element in list of dirty pages */
                          /* NB: pDirtyNext and pDirtyPrev are undefined if the
                          ** PgHdr object is not dirty */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的信息，大部分在注释中已经自解释：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;pPage：这个字段稍显复杂，后面展开详细解释。&lt;/li&gt;
&lt;li&gt;pData，pExtra：pData指向了页面实际的内容，pExtra指向页面额外数据，大部分时候，后者的内容可以忽视。&lt;/li&gt;
&lt;li&gt;pCache：页面缓存管理器对象指针。&lt;/li&gt;
&lt;li&gt;pDirty：脏页面链表指针。&lt;/li&gt;
&lt;li&gt;pPager：页面管理器对象指针。（注意和pCache进行区分，pCache是“页面缓存管理器”）。&lt;/li&gt;
&lt;li&gt;pgno：存储该页面的页面编号。&lt;/li&gt;
&lt;li&gt;flags：页面标志位，有如下几种，可以通过位操作来加上多个标志位：

&lt;ul&gt;
&lt;li&gt;PGHDR_CLEAN：干净的页面。&lt;/li&gt;
&lt;li&gt;PGHDR_DIRTY：脏页面。&lt;/li&gt;
&lt;li&gt;PGHDR_WRITEABLE：已经记录下来修改之前的页面内容，所以此时可以对内存中的页面内容进行修改了。&lt;/li&gt;
&lt;li&gt;PGHDR_NEED_SYNC：将该页面内容写入数据库文件之前，需要sync journal文件中的页面内容。&lt;/li&gt;
&lt;li&gt;PGHDR_DONT_WRITE：不需要写页面内容到磁盘。&lt;/li&gt;
&lt;li&gt;PGHDR_MMAP：该页面内容是通过mmap到内存中的。&lt;/li&gt;
&lt;li&gt;PGHDR_WAL_APPEND：页面内容已经添加到WAL文件中了。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;nRef：页面引用计数。&lt;/li&gt;
&lt;li&gt;pDirtyNext、pDirtyPrev：存储脏页面链表中前、后页面指针，如果该页面不是脏页面，则这两个字段未定义。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以简略的总结该结构体中的内容，最重要的莫过于以下几项：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;pData存储的页面内容，所谓的读、写页面内容实际上操作的是这个成员指向的内容。&lt;/li&gt;
&lt;li&gt;pDirty、pDirtyNext、pDirtyPrev这几个成员维护的脏页面相关的指针。&lt;/li&gt;
&lt;li&gt;flags维护的页面标志位，通过这些标志位来区分应该对页面进行什么操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211217-sqlite-btree-1-pagecache/PgHdr.png&#34; alt=&#34;内存中脏页面的组织&#34; title=&#34;内存中脏页面的组织&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;sqlite3-pcache-page数据结构&#34;&gt;sqlite3_pcache_page数据结构&lt;/h3&gt;

&lt;p&gt;上面的&lt;code&gt;PgHdr&lt;/code&gt;结构体中，还有第一个成员，即&lt;code&gt;sqlite3_pcache_page&lt;/code&gt;类型的pPage指针没有讲解，这里展开解释。&lt;/p&gt;

&lt;p&gt;前面概述部分提到，“页面缓存算法”的实现，是可以交给用户自定义的，这就带来一个问题：每个自定义的实现，内部实现的管理页面的结构体可能并不相同。于是，就要类似C++中的面向对象机制一样，先声明一个“页面”的基类，基类中定义最基础的成员变量，这样做之后有这样的好处：页面管理模块，所有的操作都能针对这个基类来进行，而不需要管具体实现中的差异。&lt;/p&gt;

&lt;p&gt;在这里，这个基类就是成员&lt;code&gt;sqlite3_pcache_page&lt;/code&gt;，其定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct sqlite3_pcache_page sqlite3_pcache_page;
struct sqlite3_pcache_page {
  void *pBuf;        /* The content of the page */
  void *pExtra;      /* Extra information associated with the page */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;成员中的用途，注释中也写得挺清楚了：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;pBuf：指向页面内容。&lt;/li&gt;
&lt;li&gt;pExtra：保存页面的额外信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;既然是“基类”，就要求每个子类都要有该基类的信息，实际上也是这样做的，比如“页面缓存算法”的默认实现中，其管理页面的结构体是&lt;code&gt;PgHdr1&lt;/code&gt;（后面会展开解释这个结构体），其初始定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct PgHdr1 {
  sqlite3_pcache_page page;      /* Base class. Must be first. pBuf &amp;amp; pExtra */
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从注释可以看到，sqlite中要求所有实现页面缓存算法中管理页面的数据结构体，都要以&lt;code&gt;sqlite3_pcache_page&lt;/code&gt;结构体开始做为第一个成员。&lt;/p&gt;

&lt;p&gt;实际上，&lt;code&gt;sqlite3_pcache_page&lt;/code&gt;结构体中，&lt;code&gt;pExtra&lt;/code&gt;成员包括如下两部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;额外内容：由系统指定&lt;code&gt;szExtra&lt;/code&gt;大小来指定这部分内容大小，简单起见，目前可以认为这部分为0。&lt;/li&gt;
&lt;li&gt;PgHdr结构体：即前面讲解的&lt;code&gt;页面缓存模块&lt;/code&gt;中描述一个页面的结构体大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;读到这里，有可能把读者绕晕了，我们以代码和图示为引子详细看一下。&lt;/p&gt;

&lt;p&gt;首先，创建一个“页面缓存算法”模块时，要调用&lt;code&gt;sqlite3_pcache_methods2&lt;/code&gt;结构体中定义的&lt;code&gt;xCreate&lt;/code&gt;函数指针来完成，其函数定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sqlite3_pcache *(*xCreate)(int szPage, int szExtra, int bPurgeable);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;传入的第二个参数&lt;code&gt;szExtra&lt;/code&gt;需要指定额外部分的内容大小，实际在调用时，这个参数的大小就是我们上面说的&lt;code&gt;szExtra&lt;/code&gt;和PgHdr结构体大小之和（做了8字节对齐）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    sqlite3_pcache *pNew;
    pNew = sqlite3GlobalConfig.pcache2.xCreate(
                szPage, pCache-&amp;gt;szExtra + ROUND8(sizeof(PgHdr)),
                pCache-&amp;gt;bPurgeable
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;于是，“页面缓存模块”中要获取一个页面时，是通过&lt;code&gt;sqlite3_pcache_methods2&lt;/code&gt;结构体中定义的&lt;code&gt;xFetch&lt;/code&gt;函数指针来完成的，这个函数指针的定义是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sqlite3_pcache_page *(*xFetch)(sqlite3_pcache*, unsigned key, int createFlag);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，这里返回的就是上面说的“基类”，即&lt;code&gt;sqlite3_pcache_page&lt;/code&gt;结构体指针。而在内部的默认实现中，其实返回的是&lt;code&gt;PgHdr1&lt;/code&gt;指针进行强制转换之后的结果，即&lt;code&gt;sqlite3_pcache_page&lt;/code&gt;这一基类的子类，之所以能够做，完全是因为在&lt;code&gt;PgHdr1&lt;/code&gt;结构体定义时，把&lt;code&gt;sqlite3_pcache_page&lt;/code&gt;结构体成员放在第一个成员：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct PgHdr1 {
  sqlite3_pcache_page page;      /* Base class. Must be first. pBuf &amp;amp; pExtra */
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;得到返回的&lt;code&gt;sqlite3_pcache_page&lt;/code&gt;指针之后，就能通过其中的&lt;code&gt;pExtra&lt;/code&gt;指针拿到&lt;code&gt;PgHdr&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PgHdr *sqlite3PcacheFetchFinish(
  PCache *pCache,             /* Obtain the page from this cache */
  Pgno pgno,                  /* Page number obtained */
  sqlite3_pcache_page *pPage  /* Page obtained by prior PcacheFetch() call */
){
  PgHdr *pPgHdr;

  pPgHdr = (PgHdr *)pPage-&amp;gt;pExtra;
  // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;总结起来，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211217-sqlite-btree-1-pagecache/sqlite3_pcache_page.png&#34; alt=&#34;sqlite3_pcache_page&#34; title=&#34;sqlite3_pcache_page&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;页面所在的数据结构&#34;&gt;页面所在的数据结构&lt;/h2&gt;

&lt;p&gt;缓存中的页面，可能存在于以下三种数据结构中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;脏页面链表：该链表维护所有当前在使用的页面，由“页面缓存管理器”维护。&lt;/li&gt;
&lt;li&gt;hash数组：作用是以页面编号为键来查询页面，由默认的“页面缓存算法”来维护。&lt;/li&gt;
&lt;li&gt;LRU链表：越是常被访问的页面，在LRU链表中就越往前，从LRU链表中淘汰数据都是从链表尾部开始的，也是由默认的“页面缓存算法”来维护。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211217-sqlite-btree-1-pagecache/page_ds.png&#34; alt=&#34;页面所在的三种数据结构&#34; title=&#34;页面所在的三种数据结构&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;脏页面链表&#34;&gt;脏页面链表&lt;/h3&gt;

&lt;p&gt;这个页面链表叫“脏页面（dirty page）链表”实际上并不十分准确，这会让人误以为这个链表上的页面全都是脏页面，实际上是可能存在干净的页面的。更准确的说法，是当前系统在使用的页面，都维护在这个页面链表中。&lt;/p&gt;

&lt;p&gt;操作这个链表的入口函数是&lt;code&gt;pcacheManageDirtyList&lt;/code&gt;，其传入的参数一个是&lt;code&gt;PgHdr&lt;/code&gt;类型的指针，另一个用于指定行为，有以下三种：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#define PCACHE_DIRTYLIST_REMOVE   1    /* Remove pPage from dirty list */
#define PCACHE_DIRTYLIST_ADD      2    /* Add pPage to the dirty list */
#define PCACHE_DIRTYLIST_FRONT    3    /* Move pPage to the front of the list */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;pcacheManageDirtyList&lt;/code&gt;函数实现中，也是根据这个参数进行与操作判断来做不同的行为的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pcacheManageDirtyList实现：
  如果 addRemove &amp;amp; PCACHE_DIRTYLIST_REMOVE:
    从链表上删除
  如果 addRemove &amp;amp; PCACHE_DIRTYLIST_ADD：
    添加到链表头
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里需要注意的是，参数&lt;code&gt;PCACHE_DIRTYLIST_FRONT&lt;/code&gt;为3，而另外两个参数一个是1（删除）一个是2，所以当传入&lt;code&gt;PCACHE_DIRTYLIST_FRONT&lt;/code&gt;的时候，按照上面的流程，就是首先从链表上删除，再放到链表头。&lt;/p&gt;

&lt;p&gt;由于脏页面链表是由“页面缓存管理器”来管理的，所以描述页面的结构体与这个链表相关的数据结构，都在&lt;code&gt;PgHdr&lt;/code&gt;上：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct PgHdr {
  ...
  PgHdr *pDirtyNext;             /* Next element in list of dirty pages */
  PgHdr *pDirtyPrev;             /* Previous element in list of dirty pages */
                          /* NB: pDirtyNext and pDirtyPrev are undefined if the
                          ** PgHdr object is not dirty */
}; 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;hash数组&#34;&gt;hash数组&lt;/h3&gt;

&lt;p&gt;为了快速根据页面编号，查找到该编号的页面是否已经加载到页面中，每个页面的数据还存在于一个hash数组中。&lt;/p&gt;

&lt;p&gt;如前所述，这个数据结构由默认的“页面缓存算法”维护，所以与之相关的数据结构，都在结构体&lt;code&gt;PgHdr1&lt;/code&gt;上：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct PgHdr1 {
  ...
  PgHdr1 *pNext;                 /* Next in hash table chain */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;hash数组的实现，与一般的实现并没有太大区别，这里就不展开说了。&lt;/p&gt;

&lt;h3 id=&#34;lru链表&#34;&gt;LRU链表&lt;/h3&gt;

&lt;p&gt;当需要加载当前还不在内存中的页面时，需要首先分配出一块空间，用于保存从文件中加载的页面数据。如前所述，“页面缓存管理器”管理的是还在使用的页面，而“页面缓存算法”管理的是当前没有被使用的页面，所以这部分功能也是由默认的“页面缓存算法”来实现的，与之相关的数据结构，和hash数组的实现一样，也在结构体&lt;code&gt;PgHdr1&lt;/code&gt;上：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct PgHdr1 {
  ...
  PgHdr1 *pLruNext;              /* Next in LRU list of unpinned pages */
  PgHdr1 *pLruPrev;              /* Previous in LRU list of unpinned pages */
                                 /* NB: pLruPrev is only valid if pLruNext!=0 */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当需要从“没有被使用的页面”中，分配出来一个页面数据用于保存加载的页面时，就涉及到淘汰问题：如果一个页面虽然当前没有被使用，但是由于经常被访问，所以不应该淘汰这个页面，因为很有可能它马上又会被访问到，应该首先淘汰那些不常被访问的页面，用来加载页面数据。&lt;/p&gt;

&lt;p&gt;维护这些信息的数据结构，就是LRU链表：在链表中越往前的数据，意味着被访问的越频繁；反之，淘汰都是从链表尾部开始。&lt;/p&gt;

&lt;h3 id=&#34;pin和unpin操作&#34;&gt;pin和unpin操作&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;pin&lt;/code&gt;和&lt;code&gt;unpin&lt;/code&gt;操作，在默认的缓存算法中，是针对LRU链表而言的：一个页面数据，如果执行了&lt;code&gt;pin&lt;/code&gt;操作，就是将这个页面从LRU链表上摘下来。而&lt;code&gt;unpin&lt;/code&gt;操作则反之，将页面放入LRU链表。&lt;/p&gt;

&lt;p&gt;为什么需要这两个操作？&lt;/p&gt;

&lt;p&gt;再复习一下前面提到的分工：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;页面缓存管理器：负责维护在使用的页面。&lt;/li&gt;
&lt;li&gt;页面缓存算法：负责维护未使用的页面。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;假设一个页面编号为N的页面，被访问时需要加载到内存，此时就会由“页面缓存管理器”加载到内存中，放入脏页面链表；而一旦访问完成，就会调用页面缓存算法的&lt;code&gt;xUnpin&lt;/code&gt;函数指针执行&lt;code&gt;unpin&lt;/code&gt;操作（实现页面缓存算法的&lt;code&gt;sqlite3_pcache_methods2&lt;/code&gt;结构体在后面解释）。&lt;/p&gt;

&lt;p&gt;在默认的缓存算法中，执行&lt;code&gt;unpin&lt;/code&gt;操作，就是将页面放入LRU链表，并不会将页面从hash数组中删除，也就是说：&lt;code&gt;unpin&lt;/code&gt;操作，并不妨碍这个能够以页面编号从hash数组中再次查到该页面的数据。&lt;/p&gt;

&lt;p&gt;换言之，&lt;code&gt;unpin&lt;/code&gt;操作是在“页面缓存算法”使用完毕某个页面时执行的，只是用来通知“页面缓存算法”：这个页面我已经用不上了，后续怎么处理，可以由“页面缓存算法”自行决定。&lt;/p&gt;

&lt;p&gt;于是，对于那些经常被访问的页面，即便当前没有被使用，真正到需要它的时候，只要没有被淘汰出去分配给其他页面，就不再需要再次从文件中加载出来。&lt;/p&gt;

&lt;h2 id=&#34;页面缓存管理器&#34;&gt;页面缓存管理器&lt;/h2&gt;

&lt;h3 id=&#34;页面缓存管理器的数据结构&#34;&gt;页面缓存管理器的数据结构&lt;/h3&gt;

&lt;p&gt;页面缓存管理器，核心功能就是维护脏页面链表，页面缓存管理器的数据结构中最重要的莫过于以下几个成员：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct PCache {
  PgHdr *pDirty, *pDirtyTail;         /* List of dirty pages in LRU order */
  PgHdr *pSynced;                     /* Last synced page in dirty page list */
  ...

  int (*xStress)(void*,PgHdr*);       /* Call to try make a page clean */
  void *pStress;                      /* Argument to xStress */
  sqlite3_pcache *pCache;             /* Pluggable cache module */
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，有两个维护页面链表相关的指针：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;脏页面链表：由成员pDirty, pDirtyTail指向该链表的一头一尾。脏页面链表中，页面是按照LRU的顺序进行排列的，即：越靠近链表尾的页面最可能被淘汰。&lt;/li&gt;
&lt;li&gt;最后进行sync的页面指针：在脏页面链表中，pSynced始终指向最后一个已经进行sync操作的页面。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为什么需要多一个&lt;code&gt;pSynced&lt;/code&gt;指针？因为在页面缓存紧张的时候，需要快速知道哪些页面已经sync了，这样的页面淘汰的代价最低，具体可以看函数&lt;code&gt;sqlite3PcacheFetchStress&lt;/code&gt;的实现，该函数的大体流程是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;分为两步寻找可以淘汰的页面：
  首先在pSynced指针开始往前找不需要sync且引用计数为0的页面
  如果找不到就继续在脏页面链表中寻找引用计数为0的页面
  找到之后，调用注册的xStress进行淘汰操作
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;除了这几个和脏页面链表相关的数据结构之外，上面还列举出来了其他几个成员：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;xStress和pStress：在页面缓存出现压力时，需要将页面淘汰同时进行清理，清理页面的操作最终由&lt;code&gt;xStress&lt;/code&gt;函数指针来完成。&lt;/li&gt;
&lt;li&gt;sqlite3_pcache：下面会提到，实现“页面缓存算法”的&lt;code&gt;sqlite3_pcache_methods2&lt;/code&gt;结构体，其内部的&lt;code&gt;xCreate&lt;/code&gt;函数指针最终会创建出一个&lt;code&gt;sqlite3_pcache&lt;/code&gt;返回，后续调用&lt;code&gt;页面缓存算法&lt;/code&gt;时，传入的都是这个返回的指针。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;页面缓存算法结构体&#34;&gt;页面缓存算法结构体&lt;/h2&gt;

&lt;p&gt;页面缓存算法，需要实现&lt;code&gt;sqlite3_pcache_methods2&lt;/code&gt;接口并且注册到系统中，来看&lt;code&gt;sqlite3_pcache_methods2&lt;/code&gt;的定义：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct sqlite3_pcache_methods2 sqlite3_pcache_methods2;
struct sqlite3_pcache_methods2 {
  int iVersion;
  void *pArg;
  int (*xInit)(void*);
  void (*xShutdown)(void*);
  sqlite3_pcache *(*xCreate)(int szPage, int szExtra, int bPurgeable);
  void (*xCachesize)(sqlite3_pcache*, int nCachesize);
  int (*xPagecount)(sqlite3_pcache*);
  sqlite3_pcache_page *(*xFetch)(sqlite3_pcache*, unsigned key, int createFlag);
  void (*xUnpin)(sqlite3_pcache*, sqlite3_pcache_page*, int discard);
  void (*xRekey)(sqlite3_pcache*, sqlite3_pcache_page*, 
      unsigned oldKey, unsigned newKey);
  void (*xTruncate)(sqlite3_pcache*, unsigned iLimit);
  void (*xDestroy)(sqlite3_pcache*);
  void (*xShrink)(sqlite3_pcache*);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;逐个解释：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;iVersion：版本号。&lt;/li&gt;
&lt;li&gt;pArg：参数。&lt;/li&gt;
&lt;li&gt;xInit：初始化模块的函数指针，这在模块初始化时一次性调用即可。&lt;/li&gt;
&lt;li&gt;xShutdown：停止模块的函数指针。&lt;/li&gt;
&lt;li&gt;xCreate：创建一个“页面缓存算法”的指针&lt;code&gt;sqlite3_pcache&lt;/code&gt;返回，注意这个函数里传入了页面大小、额外空间大小，这些都在上面有说明。后续的其他函数指针，传入的第一个参数都是这里返回的&lt;code&gt;sqlite3_pcache&lt;/code&gt;指针。&lt;/li&gt;
&lt;li&gt;xCachesize：返回当前cache大小。&lt;/li&gt;
&lt;li&gt;xPagecount：返回页面数量。&lt;/li&gt;
&lt;li&gt;xFetch：核心函数，根据传入的&lt;code&gt;key&lt;/code&gt;在缓存中查找页面，如果没有找到则按照&lt;code&gt;createFlag&lt;/code&gt;参数来决定后面的行为。&lt;/li&gt;
&lt;li&gt;xUnpin：页面的引用计数为0时就会调用这个函数。&lt;/li&gt;
&lt;li&gt;xRekey：表示把页面的key进行修改，这里key其实就是页面编号。&lt;/li&gt;
&lt;li&gt;xTruncate：将所有页面编号&amp;gt;=iLimit的页面都释放，回收内存。&lt;/li&gt;
&lt;li&gt;xDestroy：销毁前面&lt;code&gt;xCreate&lt;/code&gt;函数返回的&lt;code&gt;sqlite3_pcache&lt;/code&gt;指针。&lt;/li&gt;
&lt;li&gt;xShrink：尽可能的回收内存。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要说明的是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;xInit函数：完成初始化这个模块的工作。&lt;/li&gt;
&lt;li&gt;xCreate：返回创建一个“页面缓存算法”的指针&lt;code&gt;sqlite3_pcache&lt;/code&gt;，后续的所有操作，都使用这个指针。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而sqlite中，其实并没有定义&lt;code&gt;sqlite3_pcache&lt;/code&gt;的具体结构，仅仅只是声明了这个类型，可以理解为是一个类似于&lt;code&gt;void*&lt;/code&gt;这样的泛型指针：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
** CAPI3REF: Custom Page Cache Object
**
** The sqlite3_pcache type is opaque.  It is implemented by
** the pluggable module.  The SQLite core has no knowledge of
** its size or internal structure and never deals with the
** sqlite3_pcache object except by holding and passing pointers
** to the object.
**
** See [sqlite3_pcache_methods2] for additional information.
*/
typedef struct sqlite3_pcache sqlite3_pcache;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>sqlite3.36版本 btree实现（零）- 起步及概述</title>
      <link>https://www.codedump.info/post/20211217-sqlite-btree-0/</link>
      <pubDate>Fri, 17 Dec 2021 10:19:05 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20211217-sqlite-btree-0/</guid>
      <description>

&lt;h1 id=&#34;起步&#34;&gt;起步&lt;/h1&gt;

&lt;p&gt;在去年大体把btree以及b+tree算法流程研究了之后，我写了两篇博客：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200609-btree-1/&#34;&gt;B树、B+树索引算法原理（上） - codedump的网络日志&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20200615-btree-2/&#34;&gt;B树、B+树索引算法原理（下） - codedump的网络日志&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;（鉴于b+tree只是btree的一个特例，下面描述将仅使用“btree”，不再严格区分两者。）&lt;/p&gt;

&lt;p&gt;但是，这两篇文章仅仅只是让我懂得了最基本的原理。懂得原理，只是能做出toy级别的实现，拿btree类的存储引擎来说，要做到生产级产品，至少还有以下几个问题我当时不知道怎么做的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如何处理不同大小的数据的存储？&lt;/li&gt;
&lt;li&gt;删除一个数据之后，如何复用其留下的空间？&lt;/li&gt;
&lt;li&gt;错误、崩溃恢复怎么做？&lt;/li&gt;
&lt;li&gt;跟磁盘文件是如何交互的？&lt;/li&gt;
&lt;li&gt;页面缓存模块如何实现？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;等等等等，还有太多我还没有弄清楚的实现细节。&lt;/p&gt;

&lt;p&gt;（我甚至还在微博上发问，得到了两个质量很高的回答，见本文最后的&lt;a href=&#34;https://www.codedump.info/post/20211217-sqlite-btree-0/#%E5%BD%A9%E8%9B%8B&#34;&gt;彩蛋部分&lt;/a&gt;。）&lt;/p&gt;

&lt;p&gt;对LSM类存储引擎有了解的人都知道，Leveldb这个项目在LSM领域属于入门级别的生产级实现，即这个领域最精简、但是又能放心在某些要求不高的场景下用于生产的项目。在这之后，我一直在找那种btree领域的“leveldb”，很遗憾一直都没有找到，我分别看了目前WiredTiger、innodb、sqlite的对应实现，都太复杂了，看不下去。&lt;/p&gt;

&lt;p&gt;直到有一天，无意间发现了这个项目：&lt;a href=&#34;https://github.com/madushadhanushka/simple-sqlite&#34;&gt;madushadhanushka/simple-sqlite: Code reading for sqlite backend&lt;/a&gt;，看介绍，作者把sqlite2.5里b-tree相关的部分代码抽取出来了，我编译运行了一下用例都能正常跑，代码量不过几千行，我只花了几天就看完了。&lt;/p&gt;

&lt;p&gt;虽然按照&lt;a href=&#34;https://www.sqlite.org/changes.html&#34;&gt;Release History Of SQLite&lt;/a&gt;上的记载，sqlite 2.5版本是2002年的版本了，但是这个版本还是某种程度回答了我在上面的疑问。&lt;/p&gt;

&lt;p&gt;趁热打铁，我又找来更新一些的sqlite 3.6.10代码继续看这部分的实现，这次花了更多的时间才看完，但是又增强了我的信心。由于这个版本的sqlite，还未实现btree的wal，还只是用了journal文件来做崩溃恢复（无论wal还是journal，都会在后面文章展开详细讨论），所以在有足够的信心之后，我接下来又继续看当时（2021.10月份）最新的sqlite 3.36版本的实现，这部分的实现对比3.6.10来说，在btree部分最大的变化就是多了wal的实现，在已经清楚3.6.10的前提下，再增加了解这部分的实现，也并不是什么难事了。&lt;/p&gt;

&lt;p&gt;以上，简单描述了我探索一个生产级btree实现的初过程，btree类存储引擎的实现博大精深，更复杂者还有很多（WiredTiger、innodb、tokudb&amp;hellip;），但是无疑从低版本sqlite开始的探索流程，终于让我打开了走上这条路的一扇大门。&lt;/p&gt;

&lt;p&gt;本系列文章就sqlite 3.36版本的btree实现展开描述，希望对那些和我一样对“生产级btree类存储引擎实现”有好奇心的人有一点帮助。&lt;/p&gt;

&lt;p&gt;当然，如果你还是觉得吃力，可以先从&lt;a href=&#34;https://github.com/madushadhanushka/simple-sqlite&#34;&gt;madushadhanushka/simple-sqlite: Code reading for sqlite backend&lt;/a&gt;这里看起。这里并不建议对btree原理没有了解的人直接上手sqlite的实现，如果需要了解原理请参考相关文章或者我上面给出的我写的两篇博客。这系列文章中，将不再对btree原理做过多描述，将假设读者已经了解这部分内容。&lt;/p&gt;

&lt;h1 id=&#34;sqlite的btree架构概述&#34;&gt;sqlite的btree架构概述&lt;/h1&gt;

&lt;p&gt;下面简单描述一下sqlite的btree架构，从高往低大体分为以下几个部分：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211217-sqlite-btree-0/btree-arch.png&#34; alt=&#34;btree架构&#34; title=&#34;btree架构&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;这三部分架构，由下往上依次是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;系统级API的实现：因为sqlite是一个可以在多个平台编译运行的数据库，所以系统级API这一层，需要解决平台相关的文件IO、锁等问题。这部分实现，将不在这系列文章中介绍，因为并不属于数据库实现时的核心问题。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;页面管理模块：btree存储引擎，其操作文件的最基本单位就是页面。页面管理模块解决以下的问题：对上层的btree模块，暴露针对页面读、写的接口，内部会缓存页面的内容，何时将修改的页面（所谓脏页面，dirty page）落盘到磁盘，是否需要sync修改，崩溃或者重启时的数据恢复，这些都不需要上层的btree模块关心。为了达到这些效果，内部还有几个子模块：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;页面缓存模块：用于缓存页面的内存有限，何时淘汰缓存中的页面、何时将缓存中的脏页面落盘，等等都由这个模块负责。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;页面备份：从上面的描述可以看到，因为页面的修改并不一定马上落盘，而是可能只是修改了缓存中的页面，这样在系统发生崩溃的时候，需要做恢复操作，一些没有完成的事务需要回滚，等等。这部分页面管理模块由两种不同的实现：&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;journal文件：这是早期，但是效率并不高的实现。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;WAL文件：这是从3.7之后引入的更高效的方式。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;事务：事务处理也放在了页面管理中。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;btree：基于页面管理模块之上，实现了可以存储可变数据的btree模块。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以这样来简单区别理解“页面管理”模块和btree模块的功能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;页面管理：顾名思义，页面管理模块的最基本单位是”页面“，页面的读、写、缓存、落盘、恢复、回滚等，都由页面模块负责。上一层依赖页面管理模块的btree模块，不需要关心一个页面何时缓存、何时落盘等细节。即：&lt;strong&gt;页面模块负责页面的物理级别的操作&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;btree：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;负责按照btree算法，来组织页面，即负责的是页面之间逻辑关系维护。&lt;/li&gt;
&lt;li&gt;除此以外，一个页面内部的数据的物理、逻辑组织，也是btree模块来负责的。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;即：&lt;strong&gt;btree负责维护页面间的逻辑关系，以及一个页面内数据的组织。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211217-sqlite-btree-0/page-module.png&#34; alt=&#34;以页面物理、逻辑关系的维护看模块划分&#34; title=&#34;以页面物理、逻辑关系的维护看模块划分&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;从上面的分析可以看出来，“页面管理模块”无疑是这里最大最复杂的部分，Andy Pavlo在CMU 15445课程中提到过：任何用&lt;code&gt;mmap&lt;/code&gt;来做页面管理的做法都是很糟糕的做法（如boltdb、LMDB等）。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211217-sqlite-btree-0/mmap.jpeg&#34; alt=&#34;mmap&#34; title=&#34;mmap&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;这系列的文章，也将按照这个顺序，从下往上逐层分析sqlite的3.36版本的btree实现。&lt;/p&gt;

&lt;h1 id=&#34;彩蛋&#34;&gt;彩蛋&lt;/h1&gt;

&lt;p&gt;2021年9月5日，我在微博上就处理崩溃恢复的实现，提了一个问题：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;那些很成熟的存储引擎，都是怎么处理崩溃恢复问题的呢，比如写数据落盘到一半，进程崩了，该如何恢复呢？求资料和指点。 ​&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;（见：&lt;a href=&#34;https://weibo.com/1642628345/KwKqNgScT&#34;&gt;那些很成熟的存储引擎&amp;hellip; - @玩家老C的微博 - 微博&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;得到了两个很不错的指点回复：&lt;/p&gt;

&lt;h2 id=&#34;ba0tiao的回复&#34;&gt;ba0tiao的回复&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;做InnoDB 这块挺久了, 我试试说说 InnoDB 是怎么做的吧..&lt;/p&gt;

&lt;p&gt;其实你这里应该细分成两个问题&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;16kb 的page 写入的原子性该如何保证&lt;/li&gt;
&lt;li&gt;Btree 结构的完整性如何保证, 也就是你说的修改了n个页面以后如果修改了父子, 兄弟关系以后, 如果解决中间的crash 的问题&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;问题1 是通过double write buffer 来解决的, 因为InnoDB 的page 大小是16kb, 很多文件系统只能保证4kb 大小写入的原子性, 因此需要写入前先将page 的内容写入到double write buffer 来保证, 如果写入失败也不会将原有page 的内容覆盖.&lt;/p&gt;

&lt;p&gt;问题2 是通过redo log + mtr(mini transaction) 进行保证.&lt;/p&gt;

&lt;p&gt;InnoDB 里面的redo log 是由mtr 组成, mtr 是修改btree 的最小单位. 每次写入redo log 的时候必须是一个完整的mtr 的内容, 具体实现方式是mtr 会有MULTI_REC_END 标记, 在crash recovery 的时候, 如果读取到mtr 的内容没有MULTI_REC_END 标记, 那么则会认为这个mtr 不完整, 就会把这段mtr 抛弃.&lt;/p&gt;

&lt;p&gt;那么是不是一次insert 操作产生的redo log 都包含在一个mtr 里面呢?&lt;/p&gt;

&lt;p&gt;不是的.&lt;/p&gt;

&lt;p&gt;我们知道在btree 里面对page 的修改都需要对page 加锁, 从fsp 模块分配一个new page 也需要对root page 进行加锁等等. 所以InnoDB 的mtr 里面自然就包含对锁的操作, 因此要修改某一个page 的时候, mtr begin 的时候会对该page 加锁, 然后写入修改的内容, 然后mtr commit 的时候, 对于修改的page 的锁就可以释放了.&lt;/p&gt;

&lt;p&gt;如果整个insert 的过程都放在一个mtr 里面做, 那也是可以的, 也就是对于所有page 的latch 都是一开始持有, 最后的时候在释放, 就算后续这个page 已经不再修改了, 也依然要一直持有. 很容易理解这样并发自然就降低下来的, 因此在InnoDB 设计里面, mtr 的粒度是尽可能小的. 修改完page 就应该尽快的commit, 然后将page lock 释放. 但是又需要保证每一次的mtr 操作前和操作后btree 的完整性.&lt;/p&gt;

&lt;p&gt;体现具体的例子就是, InnoDB里面对于一个简单的insert 操作, 其实是有非常多个mtr 组成, 尽可能减少持有锁的时间.&lt;/p&gt;

&lt;p&gt;但是在做btree 分裂操作的时候, 分配新的page, 将之前page一半的数据迁移到new page 是在一个mtr 里面完成, 但是后续具体的insert 操作是在另外一个mtr 里面完成的. 那么如果在做分裂操作过程中crash, 那么这个分裂操作是不会完成的, 如果在分裂操作完成以后, insert 之前crash, 那么btree 是已经分裂过的, 只是数据没有插入了.&lt;/p&gt;

&lt;p&gt;当然这里会有你说的更复杂的设计的父节点 and 父节点的父节点的分裂, 那么自然持有锁的时间就更长了, 但是在我们在这里是做的一些优化.&lt;/p&gt;

&lt;p&gt;还有一些比如InnoDB redo log 是&amp;rdquo;physical to a page, logical within a page&amp;rdquo; 就是解决我们上面说的如果分裂操作成功了, 但是这个事务要回滚, 这个时候该如何处理等等..&lt;/p&gt;

&lt;p&gt;具体的内容其实这些文章里面都有&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;C. Mohan, Don Handerle. ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging.&lt;/li&gt;
&lt;li&gt;C. Mohan, Frank Levine. ARIES/lM: An Efficient and High Concurrency index Management Method Using Write-Ahead Logging.&lt;/li&gt;
&lt;li&gt;Goetz Graefe. A Survey of B-Tree Logging and Recovery Techniques.&lt;/li&gt;
&lt;li&gt;Goetz Graefe. A Survey of B-Tree Locking Techniques.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对了Goetz Graefe 号称Btree 守护神&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;（见：&lt;a href=&#34;https://weibo.com/1832563813/KwRpIxunM&#34;&gt;做InnoDB 这块&amp;hellip; - @ba0tiao的微博 - 微博&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;注：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ba0tiao&lt;/code&gt;应该是阿里云负责PolarDB开发的资深开发。&lt;/li&gt;
&lt;li&gt;他的博客是：&lt;a href=&#34;http://baotiao.github.io/&#34;&gt;baotiao&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;知乎专栏：&lt;a href=&#34;https://www.zhihu.com/column/360infra&#34;&gt;MySQL内核揭秘 - 知乎&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;bohutang的回复&#34;&gt;BohuTANG的回复&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;可以深入一点：如果每次写的log都在，怎么做到基于这些log做回放的问题？其实就是redo-log +checkpoint+ LSM的机制。redo解决数据不丢，checkpoint解决recovery的时候扫描的redo尽量少，LSM解决每次写入后新的page不会覆盖老的数据，这类实现是比较简单可行，也是目前的主流做法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;（见：&lt;a href=&#34;https://weibo.com/1691468715/KwT2GdDfu&#34;&gt;可以深入一点：如果每&amp;hellip; - @BohuTANG的微博 - 微博&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;以及：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;目前大部分理论都参考于这篇 ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging – Mohan et al. 1992&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;（见：&lt;a href=&#34;https://weibo.com/1691468715/Kx3yAhFKj&#34;&gt;目前大部分理论都参考&amp;hellip; - @BohuTANG的微博 - 微博&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;注：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;BohuTANG已经在数据库领域沉浸多年，前阿里云数据库内核组早期成员、前青云数据库团队负责人。现在数据库领域创业，公司的项目是：&lt;a href=&#34;https://github.com/datafuselabs/databend&#34;&gt;datafuselabs/databend&lt;/a&gt;，欢迎围观。&lt;/li&gt;
&lt;li&gt;博客地址：&lt;a href=&#34;https://bohutang.me/&#34;&gt;[ 虎哥的博客 ]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>为什么Raft协议不能提交之前任期的日志？</title>
      <link>https://www.codedump.info/post/20211011-raft-propose-prev-term/</link>
      <pubDate>Mon, 11 Oct 2021 23:14:01 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20211011-raft-propose-prev-term/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;在Raft大论文中3.6.2中，有一个细节“不允许提交之前任期的日志”，之前看了几次都理解的不够准确，把这部分内容展开阐述一下。&lt;/p&gt;

&lt;h1 id=&#34;问题&#34;&gt;问题&lt;/h1&gt;

&lt;p&gt;还是先从论文的图例开始解释，如下图：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20211011-raft-propose-prev-term/propose-prev-term.png&#34; alt=&#34;论文截图&#34; title=&#34;论文截图&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;需要特别说明的是，图例中演示的是&lt;strong&gt;“如果允许提交之前任期的日志，将导致什么问题”&lt;/strong&gt;，这是大前提，这个前提条件后面会反复强调。&lt;/p&gt;

&lt;p&gt;有了这个前提，下面展开图中的步骤讨论：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(a) ：S1 是leader，将黄色的日志2同步到了S2，然后S1崩溃。&lt;/li&gt;
&lt;li&gt;(b) ：S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，将蓝色日志3存储到本地，然后崩溃了。&lt;/li&gt;
&lt;li&gt;(c)：S1重新启动，选举成功。注意在这时，&lt;strong&gt;如果允许“提交之前任期的日志”&lt;/strong&gt;，将首先开始同步过往任期的日志，即将S1上的本地黄色的日志2同步到了S3。这时黄色的节点2已经同步到了集群多数节点，然后S1写了一条新日志4，然后S1又崩溃了。&lt;/li&gt;
&lt;li&gt;接下来，就可能出现两种不同的情况：

&lt;ul&gt;
&lt;li&gt;（d1）：S5重新当选，&lt;strong&gt;如果允许“提交之前任期的日志”&lt;/strong&gt;，就开始同步往期日志，将本地的蓝色日志3同步到所有的节点。结果已经被同步到半数以上节点的黄色日志2被覆盖了。这说明，如果允许“提交之前任期的日志”，会可能出现即便已经同步到半数以上节点的日志被覆盖，这是不允许的。&lt;/li&gt;
&lt;li&gt;（d2）：反之，如果在崩溃之前，S1不去同步往期的日志，而是首先同步自己任期内的日志4到所有节点，就不会导致黄色日志2被覆盖。因为leader同步日志的流程中，会通过不断的向后重试的方式，将日志同步到其他所有follower，只要日志4被复制成功，在它之前的日志2就会被复制成功。（d2）是想说明：不能直接提交过往任期的日志，即便已经被多数通过，但是可以先同步一条自己任内的日志，如果这条日志通过，就能带着前面的日志一起通过，这是（c）和（d2）两个图的区别。图（c）中，S1先去提交过往任期的日志2，图（d2）中，S1先去提交自己任内的日志4。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;再次强调，这里图示想演示的是&lt;strong&gt;“如果允许提交之前任期的日志，将导致什么问题”&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;我们可以看到的是，如果允许这么做，那么：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(c)中，S1恢复之后，又再次提交在任期2中的黄色日志2。但是，从后面可以看到，即便这个之前任期中的黄色日志2，提交到大部分节点，如果允许“提交之前任期的日志”，仍然存在被覆盖的可能性，因为：&lt;/li&gt;
&lt;li&gt;(d1)中，S5恢复之后，也会提交在自己本地上保存的之前任期3的蓝色日志，这会导致覆盖了前面已经到半数以上节点的黄色日志2。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以，“如果允许提交之前任期的日志”，即如同(c)和(d1)演示的那样：重新当选之后，马上提交自己本地保存的、之前任期的日志，就会&lt;strong&gt;可能导致即便已经同步到半数以上节点的日志，被覆盖的情况&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;而“已同步到半数以上节点的日志”，一定在新当选leader上（否则这个节点不可能成为新leader）且达成了一致可提交，即不允许被覆盖。&lt;/p&gt;

&lt;p&gt;这就是矛盾的地方，即允许“提交之前任期的日志”，最终导致了违反协议规则的情况。&lt;/p&gt;

&lt;p&gt;那么，如何确保新当选的leader节点，其本地的未提交日志被正确提交呢？图(d2)展示了正常的情况：即当选之后，不要首先提交本地已有的黄色日志2，而是首先提交一条新日志4，如果这条新日志被提交成功，那么按照Raft日志的匹配规则（log matching property）：日志4如果能提交，它前面的日志也提交了。&lt;/p&gt;

&lt;p&gt;可是，新的问题又出现了，如果在(d2)中，S1重新当选之后，客户端写入没有这条新的日志4，那么前面的日志2是不是永远无法提交了？为了解决这个问题，raft要求每个leader新当选之后，马上写入一条只有任期号和索引、而没有内容的所谓“no-op”日志，以这条日志来驱动在它之前的日志达成一致。&lt;/p&gt;

&lt;p&gt;这就是论文中这部分内容想要表达的。这部分内容之所以比较难理解，是因为经常忽略了这个图示展示的是错误的情况，允许“提交之前任期的日志”可能导致的问题。&lt;/p&gt;

&lt;h1 id=&#34;其他疑问&#34;&gt;其他疑问&lt;/h1&gt;

&lt;h2 id=&#34;c-和-d2-有什么区别&#34;&gt;(c)和(d2) 有什么区别？&lt;/h2&gt;

&lt;p&gt;看起来，(c)和(d2)一样，S1当选后都提交了日志1、2、4，那么两者的区别在哪里？&lt;/p&gt;

&lt;p&gt;虽然两个场景中，提交的日志都是一样的，但是日志达成一致的顺序并不一致：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(c)：S1成为leader之后，先提交过往任期、本地的日志2，再提交日志4。这就是“提交之前任期日志”的情况。&lt;/li&gt;
&lt;li&gt;(d2)：S1成为leader之后，先提交本次任期的日志4，如果日志4能提交成功，那么它前面的日志2就能提交成功了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关于(d2)的这个场景，有可能又存在着下一个疑问：&lt;/p&gt;

&lt;h2 id=&#34;如何理解-d2-中-本任期的日志4提交成功-那么它前面的日志2也能提交成功了&#34;&gt;如何理解(d2)中，“本任期的日志4提交成功，那么它前面的日志2也能提交成功了”？&lt;/h2&gt;

&lt;p&gt;这是由raft日志的&lt;code&gt;Log Matching Property&lt;/code&gt;决定的:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If two entries in different logs have the same index and term, then they store the same command.
If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.&lt;/li&gt;
&lt;li&gt;If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第一条性质，说明的是在不同节点上的已提交的日志，如果任期号、索引一样，那么它们的内容肯定一样。这是由leader节点的安全性和leader上的日志只能添加不能覆盖来保证的，这样leader就永远不会在同一个任期，创建两个相同索引的日志。&lt;/p&gt;

&lt;p&gt;第二条性质，说明的是在不同节点上的日志中，如果其中有同样的一条日志（即相同任期和索引）已经达成了一致，那么在这不同节点上在这条日志之前的所有日志都是一样的。&lt;/p&gt;

&lt;p&gt;第二条性质是由leader节点向follower节点上根据&lt;code&gt;AppendEntries&lt;/code&gt;消息同步日志上保证的。leader在&lt;code&gt;AppendEntries&lt;/code&gt;消息中会携带新的新添加entries之前日志的term和index，follower会判断在log中是否存在拥有此term和index的消息，如果没有就会拒绝。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;leader为每一个follower维护一个nextIndex，表示待发送的下一个日志的index。初始化为日志长度。&lt;/li&gt;
&lt;li&gt;leader在follower拒绝&lt;code&gt;AppendEntries&lt;/code&gt;之后会对nextIndex减一，然后继续重试AppendEntries直到两者一致。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;于是，回到我们开始的问题，(d2)场景中，在添加本任期日志4的时候，会发现有一些节点上并不存在过往任期的日志2，这时候就会相应地计算不同节点的nextIndex索引，来驱动同步日志2到这些节点上。&lt;/p&gt;

&lt;p&gt;总而言之，根据日志的性质，只要本任期的日志4能达成一致，上一条日志2就能达成一致。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Memcached的存储原理解析（续）</title>
      <link>https://www.codedump.info/post/20210812-memcached/</link>
      <pubDate>Thu, 12 Aug 2021 08:40:04 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20210812-memcached/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;在前面的&lt;a href=&#34;https://www.codedump.info/post/20210701-memcached/&#34;&gt;Memcached的存储原理解析&lt;/a&gt;一文中，简单分析了memcached的存储原理，但是最近在照搬memcached的实现原理到项目中时，发现前面的梳理还不够细致，有一些细节没有谈及，因此重新整理一篇文章。&lt;/p&gt;

&lt;h1 id=&#34;slab&#34;&gt;slab&lt;/h1&gt;

&lt;p&gt;memcached是根据slab为基础单位来管理空闲空间的。slab的大体原理如下图：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210812-memcached/slabclass.png&#34; alt=&#34;slabclass的分级存储&#34; title=&#34;slabclass的分级存储&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;slabs.c中定义了类型为&lt;code&gt;slabclass_t&lt;/code&gt;、大小为&lt;code&gt;MAX_NUMBER_OF_SLAB_CLASSES&lt;/code&gt;的数组&lt;code&gt;slabclass&lt;/code&gt;，用于分级存储。&lt;/p&gt;

&lt;p&gt;数组中的每个&lt;code&gt;slabclass_t&lt;/code&gt;元素，其能分配出去的内存大小递增，由如下的规则决定：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个数组可分配的内存大小都要8字节对齐（&lt;code&gt;CHUNK_ALIGN_BYTES&lt;/code&gt;）,这个大小保存在&lt;code&gt;slabclass_t&lt;/code&gt;的&lt;code&gt;size&lt;/code&gt;成员中。&lt;/li&gt;
&lt;li&gt;数组的第一个&lt;code&gt;slabclass_t&lt;/code&gt;元素的可分配内存大小为&lt;code&gt;sizeof(item) + settings.chunk_size&lt;/code&gt;。这之后的&lt;code&gt;slabclass_t&lt;/code&gt;可分配内存大小，都在上一个的元素的基础上放大&lt;code&gt;factor&lt;/code&gt;倍，同时还要8字节对齐。&lt;/li&gt;
&lt;li&gt;每次分配一个页面的大小由配置项&lt;code&gt;settings.slab_page_size&lt;/code&gt;来决定，因此每一个&lt;code&gt;slabclass_t&lt;/code&gt;元素的一个页面能容纳的&lt;code&gt;item&lt;/code&gt;数量为&lt;code&gt;settings.slab_page_size / slabclass[i].size&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上图为例，假设第一级存储的item大小不超过56字节，每个slab之间的增长因子是1.2，那么下一个slab存储的item内存大小就是56*1.2=72字节。&lt;/p&gt;

&lt;p&gt;在当前还有空闲可用内存的情况下，每一次分配新的空间，都是以page（page=1MB）为单位的，然后再根据该slab的item大小划分为多个空闲可用item。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;slabclass_t&lt;/code&gt;类型中最重要的是以下两个成员：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;slab_list：保存已经分配出去的page数组，分配一个page的内存之后，需要将page根据该slab的size划分成多个空闲的item，挂载到下面提到的slots链表中。当最后需要回收分配出去的内存时，直接遍历slab_list中的成员回收内存即可。&lt;/li&gt;
&lt;li&gt;slots：保存空闲item链表。空闲item来源有两部分，一部分是从page中分配但是还未使用的item，还有一部分是曾经被使用后来释放回来的item，上图中使用了不同的颜色进行了区分。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当需要分配一块大小的内存时，首先需要根据其大小，计算出该尺寸最终对应到上面的哪个元素，这个数组索引在Memcached中被称为&lt;code&gt;clsid&lt;/code&gt;，这个计算索引的过程参见函数&lt;code&gt;slabs_clsid&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;比如：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;slabclass[0].size = 56，fator参数为1.2，那么slabclass[1].size = (56 * 1.25)向上对齐8位 = 72，以此类推。&lt;/li&gt;
&lt;li&gt;假设需要分配的内存大小为60，就会去找&lt;code&gt;slabclass_t.size &amp;gt;= 60&lt;/code&gt;的第一个slabclass，在这个例子中返回的&lt;code&gt;clsid&lt;/code&gt;是1，也就是&lt;code&gt;slabclass[1]&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;内存分配时根据大小向上取满足条件的第一个slab的做法，优点在于方便了内存的分配管理，缺陷是会浪费掉部分空间，比如上面的例子中，将大小为72的slab用于60的内存，那么12字节的空间就被浪费掉了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从上面可以看到，&lt;code&gt;slabclass_t&lt;/code&gt;用于管理空闲内存，当需要分配新item时，会依次做如下的检查：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果&lt;code&gt;slots&lt;/code&gt;链表中还有空闲item，直接摘下来使用；&lt;/li&gt;
&lt;li&gt;否则，如果当前还没有达到内存分配的阈值，就分配一个新的page出来，将page按照该slab的大小划分为多个item，这些新分配出来的item都挂载到&lt;code&gt;slots&lt;/code&gt;链表中。&lt;/li&gt;
&lt;li&gt;如果以上两步都不满足了，说明当前已经没有可用的内存和空闲item，需要进行淘汰了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;讲到item的淘汰，就涉及到下面的LRU算法了。&lt;/p&gt;

&lt;h1 id=&#34;lru算法&#34;&gt;LRU算法&lt;/h1&gt;

&lt;h2 id=&#34;旧的lru算法及其问题&#34;&gt;旧的LRU算法及其问题&lt;/h2&gt;

&lt;p&gt;以往的LRU算法，基本做法都是这样的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建一个LRU链表，每次新加入的元素都放在链表头。&lt;/li&gt;
&lt;li&gt;如果元素被访问了一次，同样从当前链表中摘除放到链表头。&lt;/li&gt;
&lt;li&gt;需要淘汰元素时，从链表尾开始找可以淘汰的元素出来淘汰。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个算法有如下几个问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;元素被访问一次就会被放到LRU链表的头部，这样即便这个元素可以被淘汰，也会需要很久才会淘汰掉这个元素。&lt;/li&gt;
&lt;li&gt;由于上面的原因，从链表尾部开始找可以淘汰的元素时，实际可能访问到的是一些虽然不常被访问，但是还没到淘汰时间（即有效时间TTL还未过期）的数据，这样会一直沿着链表往前找很久才能找到适合淘汰的元素。由于这个查找被淘汰元素的过程是需要加锁保护的，加锁时间一长影响了系统的并发。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210701-memcached/old-lru-list.png&#34; alt=&#34;经典的LRU链表实现&#34; title=&#34;经典的LRU链表实现&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;综上，经典的LRU链表问题的核心在于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;只需要一次被访问就能让元素远离被淘汰的地方。&lt;/li&gt;
&lt;li&gt;以及如何高效定位到更可能被淘汰的元素。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从Memcached 1.5版本开始，引入了所谓的分段LRU算法（Segmented LRU）来解决这些问题。&lt;/p&gt;

&lt;h2 id=&#34;改进的分段lru算法-segmented-lru&#34;&gt;改进的分段LRU算法（Segmented LRU）&lt;/h2&gt;

&lt;p&gt;分段LRU算法中将LRU链表根据&lt;code&gt;活跃度&lt;/code&gt;分成了三类：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HOT_LRU：存储热数据的LRU链表。&lt;/li&gt;
&lt;li&gt;WARM_LRU：存储温数据（即活跃度不如热数据）的LRU链表。&lt;/li&gt;
&lt;li&gt;COLD_LRU：存储冷数据的LRU链表。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要说明的是：热（参数&lt;code&gt;settings.hot_lru_pct&lt;/code&gt;）和暖（参数&lt;code&gt;settings.warm_lru_pct&lt;/code&gt;）数据的占总体内存的比例有限制，而冷数据则无限。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;#define HOT_LRU 0
#define WARM_LRU 64
#define COLD_LRU 128
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时，使用了&lt;code&gt;heads&lt;/code&gt;和&lt;code&gt;tails&lt;/code&gt;两个数组用来保存LRU链表：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;#define POWER_LARGEST  256 /* actual cap is 255 */

#define LARGEST_ID POWER_LARGEST

static item *heads[LARGEST_ID];
static item *tails[LARGEST_ID];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面分析&lt;code&gt;slabclass&lt;/code&gt;的时候提到过，首先会根据被分配内存大小计算出来一个&lt;code&gt;slabclass&lt;/code&gt;数组的索引。在需要从LRU链表中淘汰数据时，由于LRU链表分为了上面三类，那么就还需要再进行一次&lt;code&gt;slabid | lru id&lt;/code&gt;计算（其实就是&lt;code&gt;slabid + lru id&lt;/code&gt;），到对应的LRU链表中查找元素：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210701-memcached/slabclass-lru.png&#34; alt=&#34;将slabclass数组索引映射到LRU队列数组&#34; title=&#34;将slabclass数组索引映射到LRU队列数组&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;有了这三种LRU队列的初步印象，可以接下来解释这个分段LRU算法了。&lt;/p&gt;

&lt;p&gt;前面提到，原有LRU算法最大的问题是：只要元素被访问过一次，就马上会被移动到LRU链表的前面，影响了后面对这个元素的淘汰。&lt;/p&gt;

&lt;p&gt;首先，改进的算法中，加入了一个机制：只有当元素被访问两次以后，才会标记成&lt;code&gt;活跃&lt;/code&gt;元素。&lt;/p&gt;

&lt;p&gt;代码中引入了两个标志位，其置位的规则如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ITEM_FETCHED：第一次被访问时置位该标志位。&lt;/li&gt;
&lt;li&gt;ITEM_ACTIVE：第二次被访问时（即&lt;code&gt;it-&amp;gt;it_flags &amp;amp; ITEM_FETCHED&lt;/code&gt;为true的情况下）置位该标志位。&lt;/li&gt;
&lt;li&gt;INACTIVE：不活跃状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ITEM_ACTIVE标志位清除的规则如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果从链表尾遍历到某一个LRU链表时，该元素是链表的最后一个元素，则认为是不活跃的元素，即可以清除ITEM_ACTIVE标志位；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这样，有效避免了只访问一次就变成&lt;code&gt;活跃&lt;/code&gt;元素的问题（见函数&lt;code&gt;do_item_bump&lt;/code&gt;）。&lt;/p&gt;

&lt;p&gt;以下的讨论中，元素变成&lt;code&gt;活跃&lt;/code&gt;就意指“至少被访问两次以上”。&lt;/p&gt;

&lt;p&gt;其次，由于从链表尾部往前查找可以淘汰的元素，中间可能会经历很多不能被淘汰的元素，影响了淘汰的速度，因此前面的分级LRU链表就能帮助程序快速识别出哪些元素可以被淘汰。三个分级的LRU链表之间的转换规则如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HOT_LRU：在HOT LRU队列中的数据绝不会到HOT_LRU队列的前面，只会往更冷的队列中放。规则是：如果元素变得活跃，就放到WARM队列中；否则如果不活跃，就直接放到COLD队列中。&lt;/li&gt;
&lt;li&gt;WARM_LRU：如果WARM队列的元素变的&lt;code&gt;活跃&lt;/code&gt;，就会移动到WARM队列头；否则往COLD队列移动。&lt;/li&gt;
&lt;li&gt;COLD_LRU：从上面可知，COLD队列中的元素，都是不太活跃的了，所以当需要淘汰元素时都会首先到COLD LRU队列中找可以淘汰的数据。当一个在COLD队列的元素重新变成&lt;code&gt;活跃&lt;/code&gt;元素时，并不会移动到COLD队列的头部，而是直接移动回去WARM队列。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上需要注意的是：任何操作都不能将一个元素从WARM和COLD队列中移动回去HOT队列了，也就是从HOT队列中移动元素出去的操作是单向操作。&lt;/p&gt;

&lt;p&gt;上述算法的状态机转换过程，可以参考下图。使用了这些规则来维护着三个队列之后，基本能保证COLD队列中的元素是不活跃的，这样查找起被淘汰元素也更快了。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210701-memcached/lru.png&#34; alt=&#34;三级LRU队列转换状态图&#34; title=&#34;三级LRU队列转换状态图&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;综述起来，改进的分段LRU算法做了如下的优化：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需要至少两次被访问，才能变成&lt;code&gt;活跃&lt;/code&gt;元素。&lt;/li&gt;
&lt;li&gt;将元素按照被访问频率的&lt;code&gt;冷热程度&lt;/code&gt;，划分为三种LRU链表来分段管理，加速了查找被淘汰元素的流程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;读写操作的实现&#34;&gt;读写操作的实现&lt;/h1&gt;

&lt;p&gt;从以上的分析里，可以看出memcached中主要有这么几种数据结构：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;item：存储一个KV数据的基本单位。&lt;/li&gt;
&lt;li&gt;slabclass：存储空闲item的数据结构。&lt;/li&gt;
&lt;li&gt;lru链表：根据访问的冷热程度存储当前在使用中的item。&lt;/li&gt;
&lt;li&gt;hash表：这部分没有在上面描述，用于根据key查询item的数据结构。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个item，必然处于空闲和在使用这两种互斥状态之一，即：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;空闲的item：保存在slabclass的slots空闲链表中，这一点已经在上面slab的图示中描述过了。&lt;/li&gt;
&lt;li&gt;在使用中的item：保存在lru链表中，用于数据回收之用；同时还保存在hash表中，用于数据访问时使用。如下图所示：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210812-memcached/in-use-item.png&#34; alt=&#34;使用中的item数据组织结构&#34; title=&#34;使用中的item数据组织结构&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;对item的数据组织有了大体的概念之后，下面展开来说读写操作的具体实现。&lt;/p&gt;

&lt;h2 id=&#34;读操作&#34;&gt;读操作&lt;/h2&gt;

&lt;p&gt;由于被使用数据存储在hash表中，所以查询操作相对简单，其伪代码是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;读操作：
  加锁
    在hash表中查询数据
  释放锁

  返回查询的结果
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;虽然简单，但是其中有一个值得注意的细节。这里的加锁操作，并不是一个全局锁，否则系统的并发性会大大折扣；同时，也不是给hash数组中的某一个hash桶进行加锁，实际上hash表本身并不存在锁操作。&lt;/p&gt;

&lt;p&gt;在这里，加的锁是首先根据所查询数据的键进行hash计算，再得到对应的锁，在memcached里被称为“item lock”（见全局变量&lt;code&gt;static pthread_mutex_t *item_locks&lt;/code&gt;）。这个锁虽然与数据的键值相关，但是如果hash数组数量与item_locks不相等，那么就不是一一对应的关系，所以才说不是针对hash桶进行加锁。如果hash桶的数量大于item lock的数量，那么这就是一对多的关系，也就是对一个item lock加锁之后，获得锁的线程可以访问多个hash桶。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210812-memcached/item-lock.png&#34; alt=&#34;item锁与hash桶的对应关系&#34; title=&#34;item锁与hash桶的对应关系&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;上图中，索引为N的item锁，管理着索引为M、P这两个hash桶，因此拿到该item锁的线程可以同时访问这两个hash桶。&lt;/p&gt;

&lt;p&gt;因此，上面的读操作更准确的描述应该是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;读操作：
  根据查询键值加item锁
    在hash表中查询数据
  根据查询键值释放item锁

  返回查询的结果
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;写操作&#34;&gt;写操作&lt;/h2&gt;

&lt;p&gt;与前面非常简单的读操作相比，写操作会更加复杂，因为当内存不足时需要淘汰在LRU数组中的item。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;写操作：  
  根据查询键值加item锁

    分配足够内存的item，写入新的数据
    向hash表中写入数据

  根据查询键值释放item锁
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在上面的步骤中，&lt;code&gt;分配足够内存的item&lt;/code&gt;这一步，暂不考虑分析内存足够下的情况，因为这种情况相对简单，只分析内存不足时需要淘汰的情况。将这部分代码展开来讨论，则伪代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;写操作：  
  1:根据查询键值加item锁

    2:内存不足情况下分配足够内存的item，写入新的数据：

      2.1:计算满足所需内存所在的LRU数组元素，对该LRU链表加锁
      2.2:从后往前遍历所要求内存的LRU数组：
        2.2.1:找到一个item，如果尝试对该item的键值进行加锁失败，则继续尝试下一个item
        2.2.3:否则，对该item的键值进行加锁成功，如果符合回收条件：
          2.2.4:从item所在的hash表中删除item
        2.2.5:释放2.2.1中加的item锁
      
      2.3:对该LRU链表解锁

    3:向hash表中写入数据

  4:根据查询键值释放item锁
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要注意的是，步骤2.2.1中，是尝试对当前item的键值所在的item锁加锁，这一步是可能失败的，因为在第一步中已经加上了item锁，两者有可能相同，如果这里不是尝试而是直接等待解锁，则可能造成死锁。&lt;/p&gt;

&lt;p&gt;但是仅有上面的步骤仍然是不够的，因为即便找到了一个可以被回收的item，也要确定该item没有被其他线程引用，判断的标准是根据item中的引用计数：首先将引用计数加1，如果为2的情况下（使用中的item默认引用计数为1）说明当前只有本线程引用了这个item，后面就可以安全的回收该item。&lt;/p&gt;

&lt;p&gt;在memcached代码中，如果上一步增加引用计数之后不为2时，有可能是item泄露了，如果打开tail_repair_time开关且满足时间的情况下，可以进行强制回收，但是作者也提醒了这样可能会造成程序core掉，也就是出现上面提到的被引用的item被释放的情况：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;int lru_pull_tail(const int orig_id, const int cur_lru,
        const uint64_t total_bytes, const uint8_t flags, const rel_time_t max_age,
        struct lru_pull_tail_return *ret_it) {
        
        // ...

        if (refcount_incr(search) != 2) {
            /* Note pathological case with ref&#39;ed items in tail.
             * Can still unlink the item, but it won&#39;t be reusable yet */
            itemstats[id].lrutail_reflocked++;
            /* In case of refcount leaks, enable for quick workaround. */
            /* WARNING: This can cause terrible corruption */
            if (settings.tail_repair_time &amp;amp;&amp;amp;
                    search-&amp;gt;time + settings.tail_repair_time &amp;lt; current_time) {
                itemstats[id].tailrepairs++;
                search-&amp;gt;refcount = 1;
                /* This will call item_remove -&amp;gt; item_free since refcnt is 1 */
                STORAGE_delete(ext_storage, search);
                do_item_unlink_nolock(search, hv);
                item_trylock_unlock(hold_lock);
                continue;
            }
        }

        // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;步骤2，内存不足情况下分配足够内存的item，其完整实现在函数&lt;code&gt;lru_pull_tail&lt;/code&gt;中，读者可以自行结合上面的伪代码以及前面提及的LRU算法自行分析。&lt;/p&gt;

&lt;p&gt;以上的整个流程如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210812-memcached/item-recycle.png&#34; alt=&#34;需淘汰item时的写入数据流程图&#34; title=&#34;需淘汰item时的写入数据流程图&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;解释完毕了读写操作流程之后，需要回答这个问题：为什么针对键值的锁加在了item锁上，而不是hash桶？&lt;/p&gt;

&lt;p&gt;原因在于：当写入的元素过多时，hash表需要进行扩容操作，即可以认为hash桶的数量是有可能发生变化的。因此，如果锁在hash桶上，在容量发生变化的时候就难以处理。而item锁数组，其大小则是固定的，不存在这个问题。&lt;/p&gt;

&lt;h1 id=&#34;hash数组的扩容操作&#34;&gt;hash数组的扩容操作&lt;/h1&gt;

&lt;p&gt;hash数组的数量必须是2的次方，每次存储的数据总量超过数组数量的1.5倍时，就需要扩容一倍，最多到2^32。&lt;/p&gt;

&lt;p&gt;扩容流程示意图如下：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210812-memcached/expand-hashtable.png&#34; alt=&#34;hashtable扩容示意图&#34; title=&#34;hashtable扩容示意图&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;扩容步骤为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;按照新的大小分配出来新的hash数组保存到primary_hashtable中，原hash数组命名为old_hashtable，另外有扩容索引值expand_bucket，在该索引之前的数据，表示已经从old_hashtable中转移到新的hash数组了。&lt;/li&gt;
&lt;li&gt;每次操作一个hash桶元素，需要对该hash桶对应的item锁进行加锁之后才能开始转移。&lt;/li&gt;
&lt;li&gt;期间如果有数据访问，首先按照旧的hash桶数量进行计算，如果计算出来的索引值不小于expand_bucket，说明这个数据还在旧的桶里，到old_hashtable中查找；否则说明在新的hash数组里了，按照新的hash桶数量计算器索引值，然后再到primary_hashtable中操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;综述&#34;&gt;综述&lt;/h1&gt;

&lt;p&gt;从以上分析可以看出，实现一个完备的LRU cache库，需要考虑的细节问题其实不少的，尤其memcached需要应对的是多线程情况下cache的读写，比之redis单进程单线程的情况还是要复杂不少，主要包括以下方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如何有效、快速的分配、利用内存（slab算法与数据结构）。&lt;/li&gt;
&lt;li&gt;更合理的LRU算法，不至于一次访问就导致该数据难以被回收（分段LRU算法）。&lt;/li&gt;
&lt;li&gt;细粒度加锁操作，而不是全局锁，保证读写操作的并发。不把针对键值的锁放在hash桶上，因为可能会因为容量扩充导致hash桶数组变化，而是使用了一个固定大小的锁数组。&lt;/li&gt;
&lt;li&gt;除了上述的锁之外，还需要不要回收正在被使用的内存（item引用计数）。&lt;/li&gt;
&lt;li&gt;hash数组扩容时如何尽量减少数据访问的冲突。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://memcached.org/blog/modern-lru/&#34;&gt;Replacing the cache replacement algorithm in memcached&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/memcached/memcached/blob/master/doc/new_lru.txt&#34;&gt;memcached/new_lru.txt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>选择的维度</title>
      <link>https://www.codedump.info/post/20210803-choice-dimension/</link>
      <pubDate>Tue, 03 Aug 2021 12:10:01 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20210803-choice-dimension/</guid>
      <description>&lt;p&gt;工作这些年之后，我将一份工作中满意度的指标大体划分到三个维度里面：钱、事情和人。一份工作，如果有两个维度都能较好的满足自己标准的，就算是一份不错的工作了；反之，只有一个维度满意，这时毫不犹豫就应该换一份工作；三个维度都能很好的工作，可遇而不可求。&lt;/p&gt;

&lt;p&gt;虽然工作满意度指标可以划分为这三个维度，但是具体到个人身上，每个维度的权重又不尽相同。比如有的人家里条件不错，可能就不会把钱这个维度看的太过重要；另外，每个人对每个维度的满意程度标准又是不一样的。这些，都需要具体情况具体分析，但是将你工作中最在意的部分划分到这三个维度来反问自己对工作的满意程度，是一切的开始。&lt;/p&gt;

&lt;p&gt;我在年初换了一份工作，本来还有过一些犹豫和迟疑，但是当我把这份工作的各种指标映射到这三个维度时，发现事情和人这两个维度都不能让我满意，这时候，“换工作”这个决定就清晰和坚决起来。&lt;/p&gt;

&lt;p&gt;由此我还想到的是，在我们做一些选择的时候，往往考虑的维度过多，顾此失彼、没有重点。我的建议也是将维度缩小，只考虑最重要的三个（最多不超过五个）维度，按照上面的算法进行维度的排序和权重计算，以此来指导我们做出选择。&lt;/p&gt;

&lt;p&gt;要牢记的是：一个选择的维度很多，常人如我们不可能什么都想要都能要，所以要有个取舍只选择对我们来说最重要的维度；即便是最重要的维度，也不可能面面俱到，需要根据自身的情况进行估算，最终做出符合自身条件利益最大化的选择。&lt;/p&gt;

&lt;p&gt;我最近帮一个朋友的孩子做高考志愿选择。一个高考志愿在我看来，涉及的最重要的三个维度是：学校、城市、专业。小朋友想学计算机，但是分数比较尴尬，勉强能够得着211，如果要稳进211就需要选择一般的学校、城市，甚至放弃专业（服从调剂）。在了解了最近几年广东高考的分数之后，给他填报的志愿是：武汉理工大学计算机专业（不服从调剂）、南京邮电大学。南邮虽不属于211，但是胜在专业较强，南京也是不错的城市。最终，如我意料的那样，武汉理工因为不服从调剂未被录取，录取进入南邮的电子信息工程专业。&lt;/p&gt;

&lt;p&gt;以上，就是我应用前面划分选择维度、计算最满意维度组合这套方法论的理论和例子。&lt;/p&gt;

&lt;p&gt;无独有偶，系统设计里，也有所谓的&amp;rdquo;CAP不可能三角（&lt;a href=&#34;https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86&#34;&gt;CAP定理 - 维基百科，自由的百科全书&lt;/a&gt;）&amp;rdquo;：即系统设计时，只能在一致性（Consistency）、可用性（Availability）、分区容忍性（Partition tolerance）选择两者。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210803-choice-dimension/Visualization-of-CAP-theorem.png&#34; alt=&#34;CAP不可能三角&#34; title=&#34;CAP不可能三角&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Memcached的存储原理解析</title>
      <link>https://www.codedump.info/post/20210701-memcached/</link>
      <pubDate>Thu, 01 Jul 2021 14:00:22 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20210701-memcached/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;最近工作上的需要，需要做一个LRU形式管理内存的分配器，首先想到的就是Memcached这个项目。早些年粗略的看过一些，有个大体的了解，这一次看下来发现其LRU算法做了不少的改动。&lt;/p&gt;

&lt;p&gt;本文解析Memcached内存管理这部分的内容，基于Memcached 1.6.9版本。&lt;/p&gt;

&lt;p&gt;Memcached将单个KV数据的存储，都放在&lt;code&gt;item&lt;/code&gt;这个结构体中，每个&lt;code&gt;item&lt;/code&gt;数据同时存在于这几个数据结构之中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;slabclass_t：以分级存储机制来提供内存的数据结构（下面展开详细讨论slabclass）。&lt;/li&gt;
&lt;li&gt;链表：当&lt;code&gt;item&lt;/code&gt;被使用时，存储在LRU链表中（下面详细讨论LRU链表）；当&lt;code&gt;item&lt;/code&gt;被释放之后，空闲的&lt;code&gt;item&lt;/code&gt;形成一个链表以备再次使用。&lt;/li&gt;
&lt;li&gt;hash表：用于根据键值查找数据的数据结构。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;hash表自不必多说，Memcached中将&lt;code&gt;item&lt;/code&gt;组织成一个名为&lt;code&gt;primary_hashtable&lt;/code&gt;的hash数组，根据键值查找元素时，首先计算出键值的hash值，再到对应的数组元素中遍历查找数据。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;slabclass_t&lt;/code&gt;结构体以分级的方式分配内存给&lt;code&gt;item&lt;/code&gt;，这样做有以下几个好处：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;统一了内存的管理，避免了内存的碎片化。&lt;/li&gt;
&lt;li&gt;分配、释放内存时都能到对应的slab中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;slabclass-t&#34;&gt;slabclass_t&lt;/h1&gt;

&lt;h2 id=&#34;定义&#34;&gt;定义&lt;/h2&gt;

&lt;p&gt;slabs.c中定义了类型为&lt;code&gt;slabclass_t&lt;/code&gt;、大小为&lt;code&gt;MAX_NUMBER_OF_SLAB_CLASSES&lt;/code&gt;的数组&lt;code&gt;slabclass&lt;/code&gt;，用于分级存储。&lt;/p&gt;

&lt;p&gt;数组中的每个&lt;code&gt;slabclass_t&lt;/code&gt;元素，其能分配出去的内存大小递增，由如下的规则决定：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个数组可分配的内存大小都要8字节对齐（&lt;code&gt;CHUNK_ALIGN_BYTES&lt;/code&gt;）,这个大小保存在&lt;code&gt;slabclass_t&lt;/code&gt;的&lt;code&gt;size&lt;/code&gt;成员中。&lt;/li&gt;
&lt;li&gt;数组的第一个&lt;code&gt;slabclass_t&lt;/code&gt;元素的可分配内存大小为&lt;code&gt;sizeof(item) + settings.chunk_size&lt;/code&gt;。这之后的&lt;code&gt;slabclass_t&lt;/code&gt;可分配内存大小，都在上一个的元素的基础上放大&lt;code&gt;factor&lt;/code&gt;倍，同时还要8字节对齐。&lt;/li&gt;
&lt;li&gt;每次分配一个页面的大小由配置项&lt;code&gt;settings.slab_page_size&lt;/code&gt;来决定，因此每一个&lt;code&gt;slabclass_t&lt;/code&gt;元素的一个页面能容纳的&lt;code&gt;item&lt;/code&gt;数量为&lt;code&gt;settings.slab_page_size / slabclass[i].size&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210701-memcached/slabclass.png&#34; alt=&#34;slabclass的分级存储&#34; title=&#34;slabclass的分级存储&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;当需要分配一块大小的内存时，首先需要根据其大小，计算出该尺寸最终对应到上面的哪个元素，这个数组索引在Memcached中被称为&lt;code&gt;clsid&lt;/code&gt;，这个计算索引的过程参见函数&lt;code&gt;slabs_clsid&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;比如：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;slabclass[0].size = 56，fator参数为1.2，那么slabclass[1].size = (56 * 1.25)向上对齐8位 = 72，以此类推。&lt;/li&gt;
&lt;li&gt;假设需要分配的内存大小为60，就会去找&lt;code&gt;slabclass_t.size &amp;gt;= 60&lt;/code&gt;的第一个slabclass，在这个例子中返回的&lt;code&gt;clsid&lt;/code&gt;是1，也就是&lt;code&gt;slabclass[1]&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;内存分配时根据大小向上取满足条件的第一个slab的做法，优点在于方便了内存的分配管理，缺陷是会浪费掉部分空间，比如上面的例子中，将大小为72的slab用于60的内存，那么12字节的空间就被浪费掉了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每一个slab中，需要维持两类空间：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;按照页面大小来分配的一整页空间，每个页面又按照该slab的大小划分成了多个不同的chunk。&lt;/li&gt;
&lt;li&gt;管理使用已被释放的item。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在&lt;code&gt;slabclass_t&lt;/code&gt;结构体中，以下几个成员用来维护该class的内存信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;slab_list：保存页面的数组，其大小保存在&lt;code&gt;slabs&lt;/code&gt;成员中。&lt;/li&gt;
&lt;li&gt;sl_curr：可用的&lt;code&gt;item&lt;/code&gt;数量。&lt;/li&gt;
&lt;li&gt;slots：保存在该&lt;code&gt;slabclass_t&lt;/code&gt;中空闲&lt;code&gt;item&lt;/code&gt;的链表头。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210701-memcached/slabclass-structure.png&#34; alt=&#34;slabclass结构体示意图&#34; title=&#34;slabclass结构体示意图&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;即：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在Memcached的这一套内存管理体系中，一个页面被称为一个&lt;code&gt;slab&lt;/code&gt;，其大小为&lt;code&gt;settings.slab_page_size&lt;/code&gt;；页面中可以分割成多个&lt;code&gt;slot&lt;/code&gt;用来分配内存，一个&lt;code&gt;slot&lt;/code&gt;的大小由该&lt;code&gt;slabclass&lt;/code&gt;的初始大小及&lt;code&gt;factor&lt;/code&gt;来决定，但是需要向上补齐为8位对齐的大小。&lt;/li&gt;
&lt;li&gt;一个&lt;code&gt;slabclass&lt;/code&gt;中，有预分配好的页面数组，也有被回收的元素组成的空闲slot链表，分配元素时优先从空闲链表中分配（见函数&lt;code&gt;do_slabs_alloc&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;内存分配&#34;&gt;内存分配&lt;/h2&gt;

&lt;p&gt;既然Memcached是一个LRU形式的内存分配器，所以其内存是有限制的，系统中定义了如下几个全局变量来保存当前系统的内存分配信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;static size_t mem_limit：内存分配的上限。&lt;/li&gt;
&lt;li&gt;static size_t mem_malloced：当前分配的内存大小。&lt;/li&gt;
&lt;li&gt;static void *mem_base：保存内存的起始地址。&lt;/li&gt;
&lt;li&gt;static void *mem_current：保存内存分配的当前地址。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在初始化时，系统首先会根据&lt;code&gt;mem_limit&lt;/code&gt;分配一大块内存出来。&lt;/p&gt;

&lt;p&gt;后续各个&lt;code&gt;slabclass&lt;/code&gt;需要内存时，如下操作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;就从这一大块内存中每次分配一个页面（大小为&lt;code&gt;settings.slab_page_size&lt;/code&gt;）出去用。&lt;/li&gt;
&lt;li&gt;将分配好的内存按照每个slab中容纳的&lt;code&gt;slot&lt;/code&gt;大小切分成多个&lt;code&gt;slot&lt;/code&gt;。（见函数&lt;code&gt;split_slab_page_into_freelist&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;lru算法&#34;&gt;LRU算法&lt;/h1&gt;

&lt;h2 id=&#34;旧的lru算法及其问题&#34;&gt;旧的LRU算法及其问题&lt;/h2&gt;

&lt;p&gt;以往的LRU算法，基本做法都是这样的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建一个LRU链表，每次新加入的元素都放在链表头。&lt;/li&gt;
&lt;li&gt;如果元素被访问了一次，同样从当前链表中摘除放到链表头。&lt;/li&gt;
&lt;li&gt;需要淘汰元素时，从链表尾开始找可以淘汰的元素出来淘汰。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个算法有如下几个问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;元素被访问一次就会被放到LRU链表的头部，这样即便这个元素可以被淘汰，也会需要很久才会淘汰掉这个元素。&lt;/li&gt;
&lt;li&gt;由于上面的原因，从链表尾部开始找可以淘汰的元素时，实际可能访问到的是一些虽然不常被访问，但是还没到淘汰时间（即有效时间TTL还未过期）的数据，这样会一直沿着链表往前找很久才能找到适合淘汰的元素。由于这个查找被淘汰元素的过程是需要加锁保护的，加锁时间一长影响了系统的并发。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210701-memcached/old-lru-list.png&#34; alt=&#34;经典的LRU链表实现&#34; title=&#34;经典的LRU链表实现&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;综上，经典的LRU链表问题的核心在于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;只需要一次被访问就能让元素远离被淘汰的地方。&lt;/li&gt;
&lt;li&gt;以及如何高效定位到更可能被淘汰的元素。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从Memcached 1.5版本开始，引入了所谓的分段LRU算法（Segmented LRU）来解决这些问题。&lt;/p&gt;

&lt;h2 id=&#34;改进的分段lru算法-segmented-lru&#34;&gt;改进的分段LRU算法（Segmented LRU）&lt;/h2&gt;

&lt;p&gt;分段LRU算法中将LRU链表根据&lt;code&gt;活跃度&lt;/code&gt;分成了三类：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HOT_LRU：存储热数据的LRU链表。&lt;/li&gt;
&lt;li&gt;WARM_LRU：存储温数据（即活跃度不如热数据）的LRU链表。&lt;/li&gt;
&lt;li&gt;COLD_LRU：存储冷数据的LRU链表。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要说明的是：热（参数&lt;code&gt;settings.hot_lru_pct&lt;/code&gt;）和暖（参数&lt;code&gt;settings.warm_lru_pct&lt;/code&gt;）数据的占总体内存的比例有限制，而冷数据则无限。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;#define HOT_LRU 0
#define WARM_LRU 64
#define COLD_LRU 128
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时，使用了&lt;code&gt;heads&lt;/code&gt;和&lt;code&gt;tails&lt;/code&gt;两个数组用来保存LRU链表：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;#define POWER_LARGEST  256 /* actual cap is 255 */

#define LARGEST_ID POWER_LARGEST

static item *heads[LARGEST_ID];
static item *tails[LARGEST_ID];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面分析&lt;code&gt;slabclass&lt;/code&gt;的时候提到过，首先会根据被分配内存大小计算出来一个&lt;code&gt;slabclass&lt;/code&gt;数组的索引。在需要从LRU链表中淘汰数据时，由于LRU链表分为了上面三类，那么就还需要再进行一次&lt;code&gt;slabid | lru id&lt;/code&gt;计算（其实就是&lt;code&gt;slabid + lru id&lt;/code&gt;），到对应的LRU链表中查找元素：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210701-memcached/slabclass-lru.png&#34; alt=&#34;将slabclass数组索引映射到LRU队列数组&#34; title=&#34;将slabclass数组索引映射到LRU队列数组&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;有了这三种LRU队列的初步印象，可以接下来解释这个分段LRU算法了。&lt;/p&gt;

&lt;p&gt;前面提到，原有LRU算法最大的问题是：只要元素被访问过一次，就马上会被移动到LRU链表的前面，影响了后面对这个元素的淘汰。&lt;/p&gt;

&lt;p&gt;首先，改进的算法中，加入了一个机制：只有当元素被访问两次以后，才会标记成&lt;code&gt;活跃&lt;/code&gt;元素。&lt;/p&gt;

&lt;p&gt;代码中引入了两个标志位，其置位的规则如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ITEM_FETCHED：第一次被访问时置位该标志位。&lt;/li&gt;
&lt;li&gt;ITEM_ACTIVE：第二次被访问时（即&lt;code&gt;it-&amp;gt;it_flags &amp;amp; ITEM_FETCHED&lt;/code&gt;为true的情况下）置位该标志位。&lt;/li&gt;
&lt;li&gt;INACTIVE：不活跃状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ITEM_ACTIVE标志位清除的规则如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果从链表尾遍历到某一个LRU链表时，该元素是链表的最后一个元素，则认为是不活跃的元素，即可以清除ITEM_ACTIVE标志位；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这样，有效避免了只访问一次就变成&lt;code&gt;活跃&lt;/code&gt;元素的问题（见函数&lt;code&gt;do_item_bump&lt;/code&gt;）。&lt;/p&gt;

&lt;p&gt;以下的讨论中，元素变成&lt;code&gt;活跃&lt;/code&gt;就意指“至少被访问两次以上”。&lt;/p&gt;

&lt;p&gt;其次，由于从链表尾部往前查找可以淘汰的元素，中间可能会经历很多不能被淘汰的元素，影响了淘汰的速度，因此前面的分级LRU链表就能帮助程序快速识别出哪些元素可以被淘汰。三个分级的LRU链表之间的转换规则如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HOT_LRU：在HOT LRU队列中的数据绝不会到HOT_LRU队列的前面，只会往更冷的队列中放。规则是：如果元素变得活跃，就放到WARM队列中；否则如果不活跃，就直接放到COLD队列中。&lt;/li&gt;
&lt;li&gt;WARM_LRU：如果WARM队列的元素变的&lt;code&gt;活跃&lt;/code&gt;，就会移动到WARM队列头；否则往COLD队列移动。&lt;/li&gt;
&lt;li&gt;COLD_LRU：从上面可知，COLD队列中的元素，都是不太活跃的了，所以当需要淘汰元素时都会首先到COLD LRU队列中找可以淘汰的数据。当一个在COLD队列的元素重新变成&lt;code&gt;活跃&lt;/code&gt;元素时，并不会移动到COLD队列的头部，而是直接移动回去WARM队列。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上需要注意的是：任何操作都不能将一个元素从WARM和COLD队列中移动回去HOT队列了，也就是从HOT队列中移动元素出去的操作是单向操作。&lt;/p&gt;

&lt;p&gt;上述算法的状态机转换过程，可以参考下图。使用了这些规则来维护着三个队列之后，基本能保证COLD队列中的元素是不活跃的，这样查找起被淘汰元素也更快了。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210701-memcached/lru.png&#34; alt=&#34;三级LRU队列转换状态图&#34; title=&#34;三级LRU队列转换状态图&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;综述起来，改进的分段LRU算法做了如下的优化：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;需要至少两次被访问，才能变成&lt;code&gt;活跃&lt;/code&gt;元素。&lt;/li&gt;
&lt;li&gt;将元素按照被访问频率的&lt;code&gt;冷热程度&lt;/code&gt;，划分为三种LRU链表来分段管理，加速了查找被淘汰元素的流程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://memcached.org/blog/modern-lru/&#34;&gt;Replacing the cache replacement algorithm in memcached&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/memcached/memcached/blob/master/doc/new_lru.txt&#34;&gt;memcached/new_lru.txt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Etcd Raft库的日志存储</title>
      <link>https://www.codedump.info/post/20210628-etcd-wal/</link>
      <pubDate>Mon, 28 Jun 2021 17:01:53 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20210628-etcd-wal/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;之前看etcd raft实现的时候，由于wal以及日志的落盘存储部分，没有放在raft模块中，对这部分没有扣的特别细致。而且，以前我的观点认为etcd raft把WAL这部分留给了上层的应用去实现，自身通过&lt;code&gt;Ready&lt;/code&gt;结构体来通知应用层落盘的数据，这个观点也有失偏颇，etcd只是没有把这部分代码放在raft模块中，属于代码组织的范畴问题，并不是需要应用层自己来实现。&lt;/p&gt;

&lt;p&gt;于是，决定专门写一篇文章把这部分内容给讲解一下，主要涉及以下内容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;日志（包括快照）文件的格式。&lt;/li&gt;
&lt;li&gt;日志（包括快照）内容的落盘、恢复。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以前的系列文章可以在下面的链接中找到，本文不打算过多重复原理性的内容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180921-raft/&#34;&gt;Raft算法原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180922-etcd-raft/&#34;&gt;etcd Raft库解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20181125-etcd-server/&#34;&gt;Etcd存储的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20210515-raft/&#34;&gt;Etcd Raft库的工程化实现 - codedump的网络日志&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;wal及快照文件格式&#34;&gt;WAL及快照文件格式&lt;/h1&gt;

&lt;p&gt;首先来讲解这两种文件的格式，了解了格式才能继续展开下面的讲述。&lt;/p&gt;

&lt;h2 id=&#34;wal文件格式&#34;&gt;WAL文件格式&lt;/h2&gt;

&lt;p&gt;wal文件的文件名格式为：seq-index.wal（见函数&lt;code&gt;walName&lt;/code&gt;）。其中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;seq：序列号，从0开始递增。&lt;/li&gt;
&lt;li&gt;index：该wal文件存储的第一条日志数据的索引。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，如果将一个目录下的所有wal文件按照名称排序之后，给定一个日志索引，很快就能知道该索引的日志落在哪个wal文件之中的。&lt;/p&gt;

&lt;p&gt;WAL文件中每条记录的格式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;message Record {
	optional int64 type  = 1 [(gogoproto.nullable) = false];
	optional uint32 crc  = 2 [(gogoproto.nullable) = false];
	optional bytes data  = 3;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;type：记录的类型，下面解释。&lt;/li&gt;
&lt;li&gt;crc：后面data部分数据的crc32校验值。&lt;/li&gt;
&lt;li&gt;data：数据部分，根据类型的不同有不同格式的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;记录数据的类型如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;const (
	// 以下是WAL存放的数据类型
	// 元数据
	metadataType int64 = iota + 1
	// 日志数据
	entryType
	// 状态数据
	stateType
	// 校验初始值
	crcType
	// 快照数据
	snapshotType
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面展开解释。&lt;/p&gt;

&lt;h3 id=&#34;元数据&#34;&gt;元数据&lt;/h3&gt;

&lt;p&gt;元数据就是应用层自定义的数据，需要注意的是，一个服务中如果有多个wal文件，且这些文件中有多份元数据，那么这些元数据都必须一致，否则报错。&lt;/p&gt;

&lt;p&gt;对于etcd这个服务而言，存储的元数据就是节点ID以及集群ID：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	metadata := pbutil.MustMarshal(
		&amp;amp;pb.Metadata{
			NodeID:    uint64(member.ID),
			ClusterID: uint64(cl.ID()),
		},
	)
	if w, err = wal.Create(cfg.WALDir(), metadata); err != nil {
		plog.Fatalf(&amp;quot;create wal error: %v&amp;quot;, err)
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;日志数据&#34;&gt;日志数据&lt;/h3&gt;

&lt;p&gt;日志数据的格式，就是&lt;code&gt;raft.proto&lt;/code&gt;中&lt;code&gt;Entry&lt;/code&gt;的格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;message Entry {
	optional uint64     Term  = 2 [(gogoproto.nullable) = false]; // must be 64-bit aligned for atomic operations
	optional uint64     Index = 3 [(gogoproto.nullable) = false]; // must be 64-bit aligned for atomic operations
	optional EntryType  Type  = 1 [(gogoproto.nullable) = false];
	optional bytes      Data  = 4;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;状态数据&#34;&gt;状态数据&lt;/h3&gt;

&lt;p&gt;保存当前“硬状态（HardState）”的记录，HardState包括：当前任期号、当前给哪个节点ID投票、当前提交的最大日志索引。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;message HardState {
	optional uint64 term   = 1 [(gogoproto.nullable) = false];
	optional uint64 vote   = 2 [(gogoproto.nullable) = false];
	optional uint64 commit = 3 [(gogoproto.nullable) = false];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;校验初始值&#34;&gt;校验初始值&lt;/h3&gt;

&lt;p&gt;校验数据这一块，挺有意思的，可以展开好好说一下。&lt;/p&gt;

&lt;p&gt;使用CRC算法来计算数据的校验值，除了需要原始数据之外，还需要一个校验初始值（即校验种子seed），在每个wal文件中，类型为&lt;code&gt;校验初始值&lt;/code&gt;的记录就用于存储这个值。其值和使用方式有以下几点需要注意：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个wal文件必须有&lt;code&gt;校验初始值&lt;/code&gt;类型的数据，后续所有写入该wal文件的记录，都使用该初始值来计算CRC校验值。&lt;/li&gt;
&lt;li&gt;第一个wal文件，即序列号为0的wal文件，其校验初始值为0（见wal.go的Create函数）。&lt;/li&gt;
&lt;li&gt;当生成下一个wal文件时，以上一个wal文件的最后一条日志数据的CRC校验码来做为该文件的校验初始值，这样就要求类型为&lt;code&gt;校验初始值&lt;/code&gt;的记录，必须存储在同一个wal文件中第一条日志数据的前面，否则计算出来该日志数据的crc校验码就不准。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/wal-crc.png&#34; alt=&#34;wal文件的校验初始值&#34; title=&#34;wal文件的校验初始值&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;可以看到，通过这个机制，将多个连续的wal文件“串联”了起来：使用上一个wal文件的最后一个日志数据的crc校验值，来做为下一个wal文件的校验初始值，可以有效的校验同一个项目中wal文件的正确性。&lt;/p&gt;

&lt;h3 id=&#34;快照数据&#34;&gt;快照数据&lt;/h3&gt;

&lt;p&gt;在wal文件中存储的快照数据类型的记录，其中仅存储了当前快照的索引和任期号，而快照的详细数据都放到快照数据文件中存储，下面讲到数据恢复时再展开讨论这部分内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;message Snapshot {
	optional uint64 index = 1 [(gogoproto.nullable) = false];
	optional uint64 term  = 2 [(gogoproto.nullable) = false];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;快照文件格式&#34;&gt;快照文件格式&lt;/h2&gt;

&lt;p&gt;快照文件的文件名格式为：任期号-索引号.snap（见函数&lt;code&gt;Snapshotter::save&lt;/code&gt;）。每次来一个快照数据，都新建一个快照文件，文件中存储快照数据的格式为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;message snapshot {
	optional uint32 crc  = 1 [(gogoproto.nullable) = false];
	optional bytes data  = 2;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即：只存储快照数据及其校验值，数据的具体格式由存储快照数据的使用方来解释。在etcd这个服务里，这份快照数据的格式就是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-proto&#34;&gt;message Snapshot {
	optional bytes            data     = 1;
	optional SnapshotMetadata metadata = 2 [(gogoproto.nullable) = false];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;数据恢复流程&#34;&gt;数据恢复流程&lt;/h1&gt;

&lt;p&gt;日志、快照数据的落盘，都是为了重启时恢复数据，了解了上面wal以及快照文件的格式，可以来看看数据的恢复流程。&lt;/p&gt;

&lt;p&gt;其大体流程如下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;到快照目录中取出最新的一份无错的快照文件，首先取出这个文件中存储的快照数据。（见函数&lt;code&gt;Snapshotter::Load&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;此时，从快照数据中可以反序列化出：快照数据、对应的任期号、索引号。&lt;/li&gt;
&lt;li&gt;根据第二步拿到的快照数据，到wal目录中拿到日志索引号在快照数据索引号之后的日志，遍历满足条件的记录进行数据恢复。（见函数&lt;code&gt;WAL::ReadAll&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面具体来看每种wal记录格式数据在进行数据恢复时的流程：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;日志数据：由于还可能存在一小部分小于快照索引的日志，所以恢复时会忽略掉这部分数据。&lt;/li&gt;
&lt;li&gt;状态数据：每一条状态数据都会反序列化出来，以最后一条状态数据为准。&lt;/li&gt;
&lt;li&gt;元数据：前面提到过，同一个服务的元数据必须一致，所以这里会校验元数据前后是否一致，不一致将报错退出数据恢复流程。&lt;/li&gt;
&lt;li&gt;校验初始值数据：可以参见前面关于该类型数据的讲解。&lt;/li&gt;
&lt;li&gt;快照数据：下面详细解释。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;举一个例子来描述前面根据快照文件和WAL文件恢复数据的流程：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/wal-snap.png&#34; alt=&#34;WAL与快照文件关系&#34; title=&#34;WAL与快照文件关系&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;如上图中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;快照文件集合为&lt;code&gt;[1-50.snap,1-150.snap]&lt;/code&gt;，取最新的快照文件，即&lt;code&gt;1-150.snap&lt;/code&gt;，而&lt;code&gt;1-50.snap&lt;/code&gt;文件的数据为过期数据。&lt;/li&gt;
&lt;li&gt;由于快照文件中存储的日志索引到150，即在此之前的日志已经全部被压缩到了快照文件中，因此wal文件集合中：

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;0-100.wal&lt;/code&gt;中的数据已经全部被压缩。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;1-200.wal&lt;/code&gt;中的数据部分被压缩，恢复数据时要忽略日志索引小于150的日志数据。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;3-300.wal&lt;/code&gt;中的数据都没有被压缩，恢复数据时要如实全部重放该文件的数据。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前面分析快照数据类型的时候，提到过这个类型的数据在wal文件中的记录，只会存储：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当前快照时对应的任期号。&lt;/li&gt;
&lt;li&gt;当前快照时对应的索引号。&lt;/li&gt;
&lt;li&gt;而具体的快照数据内容存储在快照文件中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;也就是说，当生成一份新的快照数据时，将会把这份快照数据相关的以上三部分内容存储到wal和快照文件中。&lt;/p&gt;

&lt;p&gt;所以当恢复数据的时候，此时已经反序列化出快照数据了，这时拿着快照数据读wal文件时，如果读到了快照类型的数据，就会去对比起任期号和索引号是否一致，不一致报错停止恢复流程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;		case snapshotType: // 快照数据
			var snap walpb.Snapshot
			pbutil.MustUnmarshal(&amp;amp;snap, rec.Data)
			if snap.Index == w.start.Index { // 两者的索引相同
				if snap.Term != w.start.Term { // 但是任期号不同
					state.Reset()
					// 返回ErrSnapshotMismatch错误
					return nil, state, nil, ErrSnapshotMismatch
				}
				// 保存快照数据匹配的标志位
				match = true
			}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上，解释清楚了wal、快照文件的格式，以及数据恢复的流程。&lt;/p&gt;

&lt;p&gt;因为wal文件和快照文件的读写，都与磁盘读写相关，所以在etcd服务中，将这两个结构体，统一到&lt;code&gt;etcdserver/storage.go&lt;/code&gt;的&lt;code&gt;storage&lt;/code&gt;结构体中：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type storage struct {
	*wal.WAL
	*snap.Snapshotter
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由&lt;code&gt;storage&lt;/code&gt;结构体统一对外提供wal、快照文件的读写接口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Storage interface {
	// Save function saves ents and state to the underlying stable storage.
	// Save MUST block until st and ents are on stable storage.
	Save(st raftpb.HardState, ents []raftpb.Entry) error
	// SaveSnap function saves snapshot to the underlying stable storage.
	SaveSnap(snap raftpb.Snapshot) error
	// DBFilePath returns the file path of database snapshot saved with given
	// id.
	DBFilePath(id uint64) (string, error)
	// Close closes the Storage and performs finalization.
	Close() error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面，解释一下写wal文件中需要注意的一些细节。&lt;/p&gt;

&lt;h1 id=&#34;写优化问题&#34;&gt;写优化问题&lt;/h1&gt;

&lt;h2 id=&#34;数据对齐&#34;&gt;数据对齐&lt;/h2&gt;

&lt;p&gt;每条写入wal的记录，都会将其大小向上8字节对齐，多出来的部分填零：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func encodeFrameSize(dataBytes int) (lenField uint64, padBytes int) {
	lenField = uint64(dataBytes)
	// force 8 byte alignment so length never gets a torn write
	padBytes = (8 - (dataBytes % 8)) % 8
	if padBytes != 0 {
		lenField |= uint64(0x80|padBytes) &amp;lt;&amp;lt; 56
	}
	return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/record.png&#34; alt=&#34;WAL记录数据需8字节对齐&#34; title=&#34;WAL记录数据需8字节对齐&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;写缓冲区&#34;&gt;写缓冲区&lt;/h2&gt;

&lt;p&gt;另外，为了缓解写文件的IO负担，etcd做了一个写优化：落盘的数据首先写到一个内存缓冲区中，只有每次填满了一个page的数据才会进行落盘操作。&lt;/p&gt;

&lt;p&gt;etcd中定义了几个常量：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;const minSectorSize = 512&lt;/li&gt;
&lt;li&gt;const walPageBytes = 8 * minSectorSize&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中：&lt;code&gt;minSectorSize&lt;/code&gt;表示一个sector的大小，而&lt;code&gt;walPageBytes&lt;/code&gt;必须为&lt;code&gt;minSectorSize&lt;/code&gt;的整数倍。&lt;/p&gt;

&lt;p&gt;etcd中定义了一个&lt;code&gt;PageWriter&lt;/code&gt;结构体，用于实现写入日志的操作，内部定义了一个循环缓冲区，只有填满一个&lt;code&gt;walPageBytes&lt;/code&gt;大小的数据才会进行落盘。&lt;/p&gt;

&lt;p&gt;下图是写入数据落盘后循环缓冲区的变化的示意图：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/cyclic-buffer.png&#34; alt=&#34;写入数据落盘后循环缓冲区的变化&#34; title=&#34;写入数据落盘后循环缓冲区的变化&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;黄色方块表示一个page的空闲空间，绿色方块表示待写入数据，红色方块表示当前已经写入数据的缓冲区。&lt;/li&gt;
&lt;li&gt;刚开始，第一个page已经有部分数据写入，还剩余一部分空闲空间。因此，当写入数据时，只会把写入数据凑齐一个页面大小来落盘。&lt;/li&gt;
&lt;li&gt;落盘完毕之后，第一个page重新变成黄色，即空闲页面，而第二个页面存储了写入数据中没有落盘的部分。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;代码流程见函数&lt;code&gt;PageWriter::Write&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;从上面的写入落盘流程可以看到，一次写入的数据可能会有一部分落盘，一部分还在内存中，这样当系统发生宕机这部分数据就是被损坏（corruption）的数据。&lt;/p&gt;

&lt;p&gt;因此，etcd中还需要有办法来识别和恢复数据。&lt;/p&gt;

&lt;h2 id=&#34;识别部分写入-partial-write-数据&#34;&gt;识别部分写入（partial write）数据&lt;/h2&gt;

&lt;p&gt;函数&lt;code&gt;decoder::isTornEntry&lt;/code&gt;用于判断一条记录是否为部分写的损坏数据。&lt;/p&gt;

&lt;p&gt;其原理是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每次新创建用于写入记录的wal文件，都会将剩余文件清零。&lt;/li&gt;
&lt;li&gt;读入记录的数据之后，将数据根据不大于每个chunk为&lt;code&gt;minSectorSize&lt;/code&gt;大小的方式，存入chunk数组中。&lt;/li&gt;
&lt;li&gt;遍历这些chunk，如果有一个chunk的数据全部是零，则认为这块数据是部分写入的损坏数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个地方要跟前面落盘流程来对照看：因为每次落盘都是以一个page为单位落盘，而page大小又是&lt;code&gt;minSectorSize&lt;/code&gt;的整数倍，因此以&lt;code&gt;minSectorSize&lt;/code&gt;为一个chunk的大小来判断是否损坏。&lt;/p&gt;

&lt;h2 id=&#34;修复wal文件流程&#34;&gt;修复wal文件流程&lt;/h2&gt;

&lt;p&gt;当进行数据恢复时，可能会出现前面的部分写导致数据损坏问题，etcd会进行如下的修复操作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;部分写导致数据损坏都只会出现在最后一个wal文件，因此打开最后一个wal文件进行处理（见函数&lt;code&gt;openLast&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;出现部分写导致损坏的记录，解析过程中都会返回&lt;code&gt;ErrUnexpectedEOF&lt;/code&gt;错误，对于这样的文件：

&lt;ul&gt;
&lt;li&gt;将损坏的文件重命名为&lt;code&gt;原文件名.broken&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;记录下来最后一个无损记录的偏移量，将损坏之后的数据都截断（Truncate）。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;只读和只写文件的区别&#34;&gt;只读和只写文件的区别&lt;/h2&gt;

&lt;p&gt;在etcd中，wal文件有两种并不能同时共存的模式：对于同一个wal文件而言，要么处于只读模式，要么处于append写模式，这两种模式不能同时存在。见&lt;code&gt;WAL&lt;/code&gt;结构体的注释：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// WAL is a logical representation of the stable storage.
// WAL is either in read mode or append mode but not both.
// A newly created WAL is in append mode, and ready for appending records.
// A just opened WAL is in read mode, and ready for reading records.
// The WAL will be ready for appending after reading out all the previous records.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据上面可能使用缓冲区优化写操作可知，两种模式下在读记录时能容忍的错误级别也不一样：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读模式：读模式下可能读到部分写的数据，所以可以容忍这种错误。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;写模式：写模式下，不能容忍读到部分写的数据。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	switch w.tail() {
	case nil:
		// We do not have to read out all entries in read mode.
		// The last record maybe a partial written one, so
		// ErrunexpectedEOF might be returned.
		// 在只读模式下，可能没有读完全部的记录。最后一条记录可能是只写了一部分，此时就会返回ErrunexpectedEOF错误
		if err != io.EOF &amp;amp;&amp;amp; err != io.ErrUnexpectedEOF { // 如果不是EOF以及ErrunexpectedEOF错误的情况就返回错误
			state.Reset()
			return nil, state, nil, err
		}
	default:
		// 写模式下必须读完全部的记录
		// We must read all of the entries if WAL is opened in write mode.
		if err != io.EOF { // 如果不是EOF错误，说明没有读完数据就报错了，这种情况也是返回错误
			state.Reset()
			return nil, state, nil, err
		}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;数据落盘的全流程&#34;&gt;数据落盘的全流程&lt;/h1&gt;

&lt;p&gt;以上了解了wal、快照文件的格式，以及写入流程，这里把之前写的不够好的数据落盘流程重新梳理一下。&lt;/p&gt;

&lt;p&gt;在 &lt;a href=&#34;https://www.codedump.info/post/20180922-etcd-raft/#%E8%BE%93%E5%85%A5%E5%8F%8A%E8%BE%93%E5%87%BA&#34;&gt;etcd Raft库解析 - codedump的网络日志&lt;/a&gt;中，曾经指出etcd raft库是通过&lt;code&gt;Ready&lt;/code&gt;结构体，来通知应用层的当前的数据的，不清楚的话可以回看一下之前的内容。在这里，只解释该结构体中与数据落盘相关的几个成员的数据走向流程，即日志数据（成员&lt;code&gt;Entries&lt;/code&gt;）、快照数据（&lt;code&gt;Snapshot&lt;/code&gt;）、已提交日志（&lt;code&gt;CommittedEntries&lt;/code&gt;）。&lt;/p&gt;

&lt;h2 id=&#34;日志数据-1&#34;&gt;日志数据&lt;/h2&gt;

&lt;p&gt;日志数据从客户端提交到落盘的走向是这样的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;由客户端提交给服务器（注：只有leader节点才能接收客户端提交的日志数据，其他节点需转发给leader）。&lt;/li&gt;
&lt;li&gt;服务器收到之后，首先调用&lt;code&gt;raftLog.append&lt;/code&gt;函数保存到&lt;code&gt;unstable_log&lt;/code&gt;中，此时日志还是在内存中的，并未落地。&lt;/li&gt;
&lt;li&gt;通过&lt;code&gt;newReady&lt;/code&gt;函数构建&lt;code&gt;Ready&lt;/code&gt;结构体时，将上一步保存下来的日志数据保存到&lt;code&gt;Ready&lt;/code&gt;结构体的&lt;code&gt;Entries&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;应用层收到&lt;code&gt;Ready&lt;/code&gt;结构体之后，调用wal的&lt;code&gt;WAL.Save&lt;/code&gt;接口保存日志数据。这一步做完之后，可以认为日志数据已经落盘了。&lt;/li&gt;
&lt;li&gt;由于数据已经落盘到WAL日志中，所以在应用层通过&lt;code&gt;Node.Advance&lt;/code&gt;接口回调通知raft库时，暂存在&lt;code&gt;unstable_log&lt;/code&gt;中的日志就可以通过函数&lt;code&gt;raftLog.stableTo&lt;/code&gt;删除了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/log-flow.png&#34; alt=&#34;日志数据从提交到落盘的走向&#34; title=&#34;日志数据从提交到落盘的走向&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;已提交日志&#34;&gt;已提交日志&lt;/h2&gt;

&lt;p&gt;raft日志中，需要保存两个日志索引：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;appliedIndex：通知到应用层目前为止最大的日志索引；&lt;/li&gt;
&lt;li&gt;commitIndex：当前已提交日志的最大索引。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这里，总有&lt;code&gt;appliedIndex &amp;lt;= commitIndex&lt;/code&gt;条件成立，即日志总是先被提交成功（即达成一致），才会通知给应用层。&lt;/p&gt;

&lt;p&gt;通知应用层已提交日志的流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用&lt;code&gt;raftLog.nextEnts()&lt;/code&gt;函数获得当前满足&lt;code&gt;appliedIndex &amp;lt;= commitIndex&lt;/code&gt;条件的日志，存入到&lt;code&gt;Ready.CommittedEntries&lt;/code&gt;通知应用层。&lt;/li&gt;
&lt;li&gt;应用层处理这部分已提交日志。&lt;/li&gt;
&lt;li&gt;调用&lt;code&gt;raftLog.appliedTo()&lt;/code&gt;函数，这里会修改&lt;code&gt;appliedIndex = commitIndex&lt;/code&gt;，即所有日志都已通知应用层。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/appliedIndex.png&#34; alt=&#34;通知应用层已提交日志流程&#34; title=&#34;通知应用层已提交日志流程&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;快照数据-1&#34;&gt;快照数据&lt;/h2&gt;

&lt;p&gt;快照数据由应用层生成，然后将生成的快照数据、当前appliedIndex、配置状态一起交给存储层，保存之后就可以把在该快照之前的数据给删除了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (rc *raftNode) maybeTriggerSnapshot() {
	// 生成快照数据
	data, err := rc.getSnapshot()

	// 通知存储层快照数据
	rc.raftStorage.CreateSnapshot(rc.appliedIndex, &amp;amp;rc.confState, data)

	// 保存快照数据
	rc.saveSnap(snap)

	// 将快照之前的数据压缩
	compactIndex := uint64(1)
	rc.raftStorage.Compact(compactIndex)

	// 更新快照数据索引，以便下一次生成新的快照数据
	rc.snapshotIndex = rc.appliedIndex
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;数据的修复&#34;&gt;数据的修复&lt;/h2&gt;

&lt;p&gt;从上面的分析中可以看到，日志数据是在客户端提交之后，就马上落盘到WAL文件中的，不会等到日志在集群中达成一致。&lt;/p&gt;

&lt;p&gt;这样会带来一个问题，比如：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;节点A认为自己还是集群的leader节点，此时收到客户端日志之后，将数据落盘到WAL文件中。&lt;/li&gt;
&lt;li&gt;落盘之后，节点A将日志同步给集群的其它节点，但是发现自己已经不再是集群的leader节点了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这种情况下，显然第一步已经落盘的日志是无效的，需要进行修复，这时候是怎么操作的呢？&lt;/p&gt;

&lt;p&gt;etcd raft的做法是不回退日志，继续走正常的流程，用新的、正确的日志添加在错误的日志后面，这样回放数据的时候恢复数据。&lt;/p&gt;

&lt;p&gt;继续以上面的例子为例：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;节点A在认为自己是leader的情况下落盘日志到本地WAL中，落盘完毕之后同步给集群内其他节点。&lt;/li&gt;
&lt;li&gt;同步到集群其他节点的过程中，才发现节点A已经不是集群的leader，此时节点A降级为follower节点，并开始从正确的集群节点那里同步日志。&lt;/li&gt;
&lt;li&gt;同步日志的流程中，节点A将收到来自leader节点的正确日志，这些日志也将落盘到节点A的WAL中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第二步中同步日志的流程可以参见 &lt;a href=&#34;https://www.codedump.info/post/20180921-raft/#%E6%96%B0leader%E4%B8%8Efollower%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE&#34;&gt;Raft算法原理 - codedump的网络日志&lt;/a&gt;，这里不再阐述。&lt;/p&gt;

&lt;p&gt;上面的流程之后，节点A的WAL中将存在：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;认为自己是leader时已落盘的日志；&lt;/li&gt;
&lt;li&gt;集群leader纠正节点A同步过来的日志。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这样，当重启恢复时，会一并将这些日志重放，应用层只要按顺序回放日志即可。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/wal-failback.png&#34; alt=&#34;WAL日志的纠错机制&#34; title=&#34;WAL日志的纠错机制&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;如上图中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;节点认为自己是leader节点时，落盘到WAL文件中的日志是&lt;code&gt;[(1,10),(1,11)]&lt;/code&gt;，列表中的二元组数据中，第一个元素是任期号，第二个元素是日志索引号。&lt;/li&gt;
&lt;li&gt;在落盘日志之后，节点将数据广播到集群，才发现自己已经不是集群的leader节点，此时集群的leader节点发现从日志10开始，该节点的数据就是不对的，开始同步正确的日志给节点，于是把正确的日志&lt;code&gt;[(2,10),(2,11)]&lt;/code&gt;同步给了节点，这部分日志会添加到前面错误的日志之后。&lt;/li&gt;
&lt;li&gt;假设节点重启恢复，那么会依次重放前面这四条日志，其中前两条日志是错误的日志，但是由于有后面的两条正确日志，最终节点的状态还是会恢复正确状态。&lt;/li&gt;
&lt;li&gt;随着后面日志数据压缩成快照文件，冗余的错误日志的磁盘占用将被解决。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;读者不妨在这里就着这个流程多思考一个问题：做为follower的节点，是什么时候将日志落盘到WAL文件中，是在收到leader节点同步过来的日志时，还是在leader节点通知某个日志已经在集群达成一致？为什么以及流程是怎样的？&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;etcd的wal模块，虽然并没有和raft模块放在一起，但并不是说这一部分就需要应用者来自己实现，这两部分其实是一起打包做为整个etcd raft算法库提供给使用者的。可以认为raft模块提供算法，wal和快照模块提供日志存储读写的接口。&lt;/li&gt;
&lt;li&gt;日志落盘部分，包括wal文件以及快照文件读写这两部分内容，etcd将这两部分统一到&lt;code&gt;Storage&lt;/code&gt;接口统一对外服务。&lt;/li&gt;
&lt;li&gt;raft算法是在收到客户端日志之后就理解落盘日志到wal文件中保存的，如果后面发现出错，就走正常的同步正确日志的流程，将正确的日志添加到后面，这样恢复时重放整个日志，最终节点达成一致的正确状态。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Etcd Raft库的工程化实现</title>
      <link>https://www.codedump.info/post/20210515-raft/</link>
      <pubDate>Sat, 15 May 2021 13:52:08 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20210515-raft/</guid>
      <description>

&lt;p&gt;最近回顾前几年写的Raft、etcd raft的实现文章，以及重新阅读Raft论文、etcd raft代码，发现之前有些理解不够准确、深刻，但是不打算在原文上做修正，于是写这篇补充的文章做一些另外角度的解释，以前的系列文章可以在下面的链接中找到，本文不打算过多重复原理性的内容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180921-raft/&#34;&gt;Raft算法原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180922-etcd-raft/&#34;&gt;etcd Raft库解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20181125-etcd-server/&#34;&gt;Etcd存储的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;在开始展开讨论前，先介绍这个Raft论文中的示意图，我认为能理解这幅图才能对一致性算法有个全貌的了解：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/statemachine.jpeg&#34; alt=&#34;Etcd Raft与应用层的交互&#34; title=&#34;Etcd Raft与应用层的交互&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;图中分为两种进程：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;server进程：server进程中运行着一致性算法模块、持久化保存的日志、以及按照日志提交的顺序来进行顺序操作的状态机。&lt;/li&gt;
&lt;li&gt;client进程：用于向server提交日志的进程。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要说明的是，两种进程都用叠加的矩形来表示，意指系统中这两类进程不止一个。&lt;/p&gt;

&lt;p&gt;一个日志要被正确的提交，图中划分了几步：&lt;/p&gt;

&lt;p&gt;1、client进程提交数据到server进程，server进程将收到的日志数据灌入一致性模块。&lt;/p&gt;

&lt;p&gt;2、一致性模块将日志写入本地WAL，然后同步给集群中其他server进程。&lt;/p&gt;

&lt;p&gt;3、多个节点对某条日志达成一致之后，将修改本地的提交日志索引（commit index）；落盘后的日志按照顺序灌入状态机，只要保证所有server进程上的日志顺序，那么最后状态机的状态肯定就是一致的了。&lt;/p&gt;

&lt;p&gt;4、灌入状态机之后，server进程可以应答客户端。&lt;/p&gt;

&lt;p&gt;所以，本质上，一个使用了一致性算法的库，划分了成了两个不同的模块：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一致性算法库，这里泛指Raft、Paxos、Zab等一致性协议。这类一致性算法库主要做如下的事情：

&lt;ul&gt;
&lt;li&gt;用户输入库中日志（log），由库根据各自的算法来检测日志的正确性，并且通知上层的应用层。&lt;/li&gt;
&lt;li&gt;输入到库中的日志维护和管理，算法库中需要知道哪些日志提交、提交成功、以及上层的应用层已经applied过的。当发生错误的时候，某些日志还会进行回滚（rollback）操作。&lt;/li&gt;
&lt;li&gt;日志的网络收发，这部分属于可选功能。有一些库，比如braft把这个事情也揽过来自己做了，优点是使用者不需要关注这部分功能，缺点是braft和它自带的网络库brpc耦合的很紧密，不可能拆开来使用；另一些raft实现，比如这里重点提到etcd raft实现，并不自己完成网络数据收发的工作，而是通知应用层，由应用层自己实现。&lt;/li&gt;
&lt;li&gt;日志的持久化存储：这部分也属于可选功能。前面说过，一致性算法库中维护了未达成一致的日志缓冲区，达成一致的日志才通知应用层，因此在这里不同的算法库又有了分歧，braft也是自己完成了日志持久化的工作，etcd raft则是将这部分工作交给了应用层。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;应用层：即工作在一致性算法之上的库使用者，这个就比上图中的“状态机”：只有达成一致并且落盘的数据才灌入应用层，只要保证灌入应用层的日志顺序一致那么最后的状态就是一致的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体来看，一个一致性算法库有以下必选和可选功能：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;输入日志进行处理的算法（必选）。&lt;/li&gt;
&lt;li&gt;日志的维护和管理（必选）。&lt;/li&gt;
&lt;li&gt;日志（包括快照）数据的网络收发（可选）。&lt;/li&gt;
&lt;li&gt;日志（包括快照）的持久化存储（可选）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要特别说明的是，即便是后面两个工作是可选的，但是可选还是必选的区别在于，这部分工作是一致性算法库自己完成，还是由算法库通知给上面的应用层去完成，并不代表这部分工作可以完全不做。&lt;/p&gt;

&lt;p&gt;在下表中列列举了etcd raft和braft在这几个特性之间的区别：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;th&gt;etcd raft&lt;/th&gt;
&lt;th&gt;braft&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;raft一致性算法&lt;/td&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;日志的维护和管理&lt;/td&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;日志数据的网络收发&lt;/td&gt;
&lt;td&gt;交由应用层&lt;/td&gt;
&lt;td&gt;自己实现&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;日志数据的持久化存储&lt;/td&gt;
&lt;td&gt;交由应用层&lt;/td&gt;
&lt;td&gt;自己实现&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;优缺点&lt;/td&gt;
&lt;td&gt;松耦合，易于验证、测试；需要应用者做更多的事情&lt;/td&gt;
&lt;td&gt;与其rpc库紧耦合，难拆分；应用层做的事情不多，易于用来做服务&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;两种实现各有自己的优缺点，braft类实现更适合提供一个需要集成raft的服务时，可以直接用来实现服务；etcd raft类的实现，由于与网络、存储层耦合不紧密，易于进行测试，更适合拿来做为库使用。&lt;/p&gt;

&lt;p&gt;如果把前面的一致性算法的几个特性做一个抽象，我认为一致性算法库本质上就是一个“维护操作日志的算法库，只要大家都按照相同的顺序将日志灌入应用层”就好，其工作原理大体如下图：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/co-algo.png&#34; alt=&#34;一致性算法的本质&#34; title=&#34;一致性算法的本质&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;如果把问题抽象成这样的话，那么本质上，所谓的“一致性算法库”跟一个经常看到的tcp、kcp甚至是一个应用层的协议栈也就没有什么区别了：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;大家都要维护一个数据区：只有确认过正确的，才会抛给上一层。以TCP协议算法来说，比如发送但未确认的数据由协议栈的缓冲区维护，如果超时还未等到对端的确认，将发起超时重传等，这些都是每种协议算法的具体细节，但是本质上这些协议都要维护一个未确认数据的缓冲区。一致性算法在数据的维护上会更复杂一些，一是参与确认的节点不止通信的C/S两端，需要集群中半数以上节点的确认；同时，在未确认之前日志需要首先落盘，在提交成功之后再抛给应用层。&lt;/li&gt;
&lt;li&gt;只要保证所有参与的节点，都以相同的数据灌入日志给应用层，那么得到的结果将最终一致。&lt;/li&gt;
&lt;li&gt;确认的流程是可以pipeline异步化的，提交日志的进程并不需要一直等待日志被提交成功，而是提交之后等待。不妨以下面的流程来做解释：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/pipeline.png&#34; alt=&#34;流水线异步化的日志提交流程&#34; title=&#34;流水线异步化的日志提交流程&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;其中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;clientA和clientB分别提交了两条日志数据，但是并没有阻塞等待日志提交成功，而是提交之后就继续别的操作了。&lt;/li&gt;
&lt;li&gt;server将两条日志数据同步出去，达成一致之后再分别通知两个client日志提交成功。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这里，client上通知日志提交成功的机制可以有很多，以etcd来说，会给每个提交的日志对应一个channel，提交成功之后会通过这个channel进行通知，也会给这个日志加一个定时器，超过时间仍未收到通知则认为提交失败。&lt;/p&gt;

&lt;h1 id=&#34;etcd-raft的实现&#34;&gt;etcd raft的实现&lt;/h1&gt;

&lt;p&gt;有了上面对一致性算法库的大体了解，下面可以详细看看etcd raft的实现了。&lt;/p&gt;

&lt;h2 id=&#34;概述-1&#34;&gt;概述&lt;/h2&gt;

&lt;p&gt;前面提到过，etcd raft库的实现中，并不自己实现网络数据收发、提交成功的数据持久化等工作，这些工作留给了应用层来自己实现，所以需要一个机制来通知应用层。etcd raft中将需要通知给应用层的数据封装在&lt;code&gt;Ready&lt;/code&gt;结构体中，其中包括如下的成员：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;成员名称&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;类型&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;SoftState&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;SoftState&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;软状态，软状态易变且不需要保存在WAL日志中的状态数据，包括：集群leader、节点的当前状态&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;HardState&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;HardState&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;硬状态，与软状态相反，需要写入持久化存储中，包括：节点当前Term、Vote、Commit&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ReadStates&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;[]ReadStates&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;用于读一致性的数据，后续会详细介绍&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Entries&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;[]pb.Entry&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;在向其他集群发送消息之前需要先写入持久化存储的日志数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Snapshot&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;pb.Snapshot&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;需要写入持久化存储中的快照数据&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;CommittedEntries&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;[]pb.Entry&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;需要输入到状态机中的数据，这些数据之前已经被保存到持久化存储中了&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Messages&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;[]pb.Message&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;需要发送出去的数据&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;有了数据，还需要raft线程与上面的应用层线程交互的机制，这部分封装在&lt;code&gt;node&lt;/code&gt;结构体中。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;node&lt;/code&gt;结构体实现&lt;code&gt;Node&lt;/code&gt;接口，该接口用于表示Raft集群中的一个节点。在&lt;code&gt;node&lt;/code&gt;结构体中，实现了以下几个核心的channel，由于与外界进行通信：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;propc chan pb.Message：用于本地提交日志数据的channel。&lt;/li&gt;
&lt;li&gt;recvc chan pb.Message：用于接收来自集群中其他节点日志数据的channel。&lt;/li&gt;
&lt;li&gt;readyc chan Ready：用于本地Raft库通知应用层哪些数据已经准备好了，因此应用层需要关注readyc这个channel才能获得从Raft线程中提交的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;去掉一些不太重要的接口，&lt;code&gt;Node&lt;/code&gt;接口中有如下的核心函数：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tick()：应用层每次tick时需要调用该函数，将会由这里驱动raft的一些操作比如选举等，至于tick的单位是多少由应用层自己决定，只要保证是恒定时间都会来调用一次就好了。&lt;/li&gt;
&lt;li&gt;Propose(ctx context.Context, data []byte) error：提议写入数据到日志中，可能会返回错误。&lt;/li&gt;
&lt;li&gt;Step(ctx context.Context, msg pb.Message) error：将消息msg灌入状态机。&lt;/li&gt;
&lt;li&gt;Ready() &amp;lt;-chan Ready：返回通知&lt;code&gt;Ready&lt;/code&gt;结构体变更的channel，应用层需要关注这个channel，当发生变更时将其中的数据进行操作。&lt;/li&gt;
&lt;li&gt;Advance()：Advance函数是当使用者已经将上一次Ready数据处理之后，调用该函数告诉raft库可以进行下一步的操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在&lt;code&gt;node&lt;/code&gt;结构体的实现中，无论是通过&lt;code&gt;Propose&lt;/code&gt;函数还是&lt;code&gt;Step&lt;/code&gt;函数提交到Raft算法库的消息，最终都是调用内部的&lt;code&gt;step&lt;/code&gt;函数的。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/etcd-raft.png&#34; alt=&#34;Etcd Raft与应用层的交互&#34; title=&#34;Etcd Raft与应用层的交互&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;以上图来说明应用层与raft之间的交互流程，注意：etcd的实现中，raft是一个独立的线程，与应用层之间通过上面介绍的几个channel进行交互。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先看最中间的部分，本地提交的数据通过&lt;code&gt;propc&lt;/code&gt;channel通知raft线程，而应用层从外部网络接收到的日志数据通过&lt;code&gt;recvc&lt;/code&gt;通知raft线程。但是不管是哪个channel，最终都是通过上面提到的&lt;code&gt;step&lt;/code&gt;函数将日志数据灌入raft线程中。&lt;/li&gt;
&lt;li&gt;最右边是raft线程通知应用线程有哪些日志数据已经确认提交完毕等（&lt;code&gt;Ready&lt;/code&gt;结构体中不限于确认提交数据，该类型数据在上面已经列举出来），应用层可以通过&lt;code&gt;Ready&lt;/code&gt;数据来持久化数据等操作。&lt;/li&gt;
&lt;li&gt;最左边表示应用层线程要通过&lt;code&gt;Advance&lt;/code&gt;函数通知raft线程自己已经持久化了某些数据，这时候可以推动raft线程库中的日志缓冲区的变更。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以一个简单的消息流程来继续解释上面的流程：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;应用层收到索引为N的消息，此时通过&lt;code&gt;recvc&lt;/code&gt;channel提交给Raft线程。&lt;/li&gt;
&lt;li&gt;Raft线程验证消息是正确的，于是需要广播给集群中的其他节点，此时会：

&lt;ul&gt;
&lt;li&gt;首先在Raft的日志缓冲区中保存下来这个消息，因为这个日志还未提交成功。&lt;/li&gt;
&lt;li&gt;将日志消息放入&lt;code&gt;Ready&lt;/code&gt;结构体的&lt;code&gt;Messages&lt;/code&gt;成员中，通知应用层，这样应用层就将该成员中的消息转发给集群中的其他节点。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Raft线程继续获得从应用层下发下来的消息，当发现下发的消息中，索引为N的消息已经被集群中半数以上的节点确认过，此时就可以认为该消息能被持久化了，将日志消息放入&lt;code&gt;Ready&lt;/code&gt;结构体的&lt;code&gt;CommittedEntries&lt;/code&gt;成员中，以通知应用层该消息可以被持久化了。&lt;/li&gt;
&lt;li&gt;每次应用层持久化了某些消息之后，都会通过&lt;code&gt;Advance&lt;/code&gt;函数通知Raft线程，这样Raft线程可以将这部分已经被持久化的消息从消息缓冲区中删除，因为前面提到过消息缓冲区仅仅是用来保存还未持久化的消息的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个工作流程是pipeline化，即应用层某一次提交了索引为N的消息，并不需要一直等待该消息提交成功，而是可以返回继续做别的事情，当raft线程判断消息可以被提交时，再通过&lt;code&gt;Ready&lt;/code&gt;结构体来通知应用层。&lt;/p&gt;

&lt;p&gt;以上大体描述了etcd中，应用层线程与raft线程的交互流程，下面详细看看raft线程的实现。&lt;/p&gt;

&lt;h2 id=&#34;raft算法&#34;&gt;Raft算法&lt;/h2&gt;

&lt;p&gt;raft算法中，有不同的角色存在：candidate、follower、leader，本质上Raft算法是输入日志数据进行处理，而每种角色对不同类型的日志数据需要有不同的处理。&lt;/p&gt;

&lt;p&gt;所以，etcd raft的实现中，针对三种不同的角色，通过修改函数指针的方式在切换了不同角色时的处理，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/role-algo.png&#34; alt=&#34;不同角色的Raft算法处理&#34; title=&#34;不同角色的Raft算法处理&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;具体的算法细节，不打算在本文中展开，可以回头上上面给出来的几篇文章。&lt;/p&gt;

&lt;h2 id=&#34;数据管理&#34;&gt;数据管理&lt;/h2&gt;

&lt;p&gt;数据管理分为以下几部分阐述：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;未持久化数据缓冲区&lt;/li&gt;
&lt;li&gt;持久化数据内存映像&lt;/li&gt;
&lt;li&gt;数据的持久化&lt;/li&gt;
&lt;li&gt;数据流动的全流程&lt;/li&gt;
&lt;li&gt;节点进度的管理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面一一展开。&lt;/p&gt;

&lt;h3 id=&#34;未持久化数据缓冲区&#34;&gt;未持久化数据缓冲区&lt;/h3&gt;

&lt;p&gt;前面提到过，Raft算法中还必须要做的是维护未确认数据的缓冲区数据，每当其中的一部分数据被确认，缓冲区的窗口随之发生移动，这就类似TCP协议算法中的滑动窗口。&lt;/p&gt;

&lt;p&gt;etcd raft中，管理未确认数据放在了&lt;code&gt;unstable&lt;/code&gt;结构体（log_unstable.go）中，其内部维护三个成员：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;snapshot *pb.Snapshot：保存还没有持久化的快照数据&lt;/li&gt;
&lt;li&gt;entries []pb.Entry：保存还未持久化的日志数据。&lt;/li&gt;
&lt;li&gt;offset uint64：保存快照和日志数组的分界线。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以看到，未持久化数据分为两部分：一部分是快照数据snapshot，另一部分就是日志数据数组。两者不会同时存在，快照数据只会在启动时进行快照数据恢复时存在，当应用层使用快照数据进行恢复之后，raft切换为可以接收日志数据的状态，后续的日志数据都会写到&lt;code&gt;entrise&lt;/code&gt;数组中了，而两者的分界线就是&lt;code&gt;offset&lt;/code&gt;变量。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/unstable.png&#34; alt=&#34;未持久化数据&#34; title=&#34;未持久化数据&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;由于是”未持久化数据的缓冲区“，因此这其中的数据可能会发生回滚（rollback）现象，因此&lt;code&gt;unstable&lt;/code&gt;结构体需要支持能回滚的操作，见函数&lt;code&gt;truncateAndAppend&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (u *unstable) truncateAndAppend(ents []pb.Entry) {
	// 先拿到这些数据的第一个索引
	after := ents[0].Index
	switch {
	case after == u.offset+uint64(len(u.entries)):
		// 如果正好是紧接着当前数据的，就直接append
		// after is the next index in the u.entries
		// directly append
		u.entries = append(u.entries, ents...)
	case after &amp;lt;= u.offset:
		u.logger.Infof(&amp;quot;replace the unstable entries from index %d&amp;quot;, after)
		// The log is being truncated to before our current offset
		// portion, so set the offset and replace the entries
		// 如果比当前偏移量小，那用新的数据替换当前数据，需要同时更改offset和entries
		u.offset = after
		u.entries = ents
	default:
		// truncate to after and copy to u.entries
		// then append
		// 到了这里，说明 u.offset &amp;lt; after &amp;lt; u.offset+uint64(len(u.entries))
		// 那么新的entries需要拼接而成
		u.logger.Infof(&amp;quot;truncate the unstable entries before index %d&amp;quot;, after)
		u.entries = append([]pb.Entry{}, u.slice(u.offset, after)...)
		u.entries = append(u.entries, ents...)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数中分为三种情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果传入的日志数据，刚好跟当前数据紧挨着（after == u.offset+uint64(len(u.entries))），就可以直接进行append操作。&lt;/li&gt;
&lt;li&gt;如果传入的日志数据的第一条数据索引不大于当前的offset（after &amp;lt;= u.offset），说明数据发生了回滚，直接用新的数据替换旧的数据。&lt;/li&gt;
&lt;li&gt;其他情况，说明u.offset &amp;lt; after &amp;lt; u.offset+uint64(len(u.entries))，这是新的未持久化数据由这两部分数据各取其中一部分数据拼装而成。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;持久化数据内存映像&#34;&gt;持久化数据内存映像&lt;/h3&gt;

&lt;p&gt;但是，仅仅有未持久化数据还不够，有时候有一些数据已经落盘，但是还需要进行查询、读取等操作。于是，etcd raft又提供了一个&lt;code&gt;Storage&lt;/code&gt;接口，该接口有面对不同的组件有不同的行为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对于Raft库，该接口仅仅只有读操作。（如下图中的黄色函数）&lt;/li&gt;
&lt;li&gt;对于etcd 服务来说，还提供了写操作，包括：增加日志数据、生成快照、压缩数据。（如下图中的蓝色函数）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，这个接口及其默认实现&lt;code&gt;MemoryStorage&lt;/code&gt;，呈现了稍微不太一样的行为，以致于我最开始没有完全理解：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/stable.png&#34; alt=&#34;持久化数据的内存映像&#34; title=&#34;持久化数据的内存映像&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;因为持久化数据的内存映像，提供给Raft库的仅仅只需要读操作，所以&lt;code&gt;Storage&lt;/code&gt;接口就只有读操作，多出来的写操作只会在应用层中才会用到，因此这些写接口并没有放在公用的接口中。&lt;/p&gt;

&lt;p&gt;了解了持久化和未持久化数据的表示之后，etcd raft库将两者统一到&lt;code&gt;raftLog&lt;/code&gt;这个结构体中：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/raftlog.png&#34; alt=&#34;不同视角下的raftlog&#34; title=&#34;不同视角下的raftlog&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;数据的持久化&#34;&gt;数据的持久化&lt;/h3&gt;

&lt;p&gt;以上解释两种缓冲区的作用，数据最终还是需要持久化到磁盘上的，那么，这个持久化数据的时机在哪里？&lt;/p&gt;

&lt;p&gt;答案：当客户端提交数据时，etcd Raft库就通过&lt;code&gt;Ready&lt;/code&gt;结构体的&lt;code&gt;Entries&lt;/code&gt;成员通知应用层，将这些提交的数据进行持久化了。&lt;/p&gt;

&lt;p&gt;有代码为证。&lt;/p&gt;

&lt;p&gt;首先来看&lt;code&gt;raft&lt;/code&gt;中如何生成&lt;code&gt;Ready&lt;/code&gt;数据：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func newReady(r *raft, prevSoftSt *SoftState, prevHardSt pb.HardState) Ready {
	rd := Ready{
		// entries保存的是没有持久化的数据数组
		Entries:          r.raftLog.unstableEntries(),
		// 保存committed但是还没有applied的数据数组
		CommittedEntries: r.raftLog.nextEnts(),
		// 保存待发送的消息
		Messages:         r.msgs,
	}
	// ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，&lt;code&gt;raft&lt;/code&gt;库中将未持久化数据塞到了&lt;code&gt;Entries&lt;/code&gt;数组中，而已经达成一致可以提交的日志数据放入到&lt;code&gt;CommittedEntries&lt;/code&gt;数组中。&lt;/p&gt;

&lt;p&gt;以&lt;code&gt;etcd&lt;/code&gt;代码中自带的&lt;code&gt;raftexample&lt;/code&gt;目录中的例子代码来看应用层在收到&lt;code&gt;Ready&lt;/code&gt;数据后的做法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rc *raftNode) serveChannels() {
		case rd := &amp;lt;-rc.node.Ready():
			// 将HardState，entries写入持久化存储中
			rc.wal.Save(rd.HardState, rd.Entries)
			if !raft.IsEmptySnap(rd.Snapshot) {
				// 如果快照数据不为空，也需要保存快照数据到持久化存储中
				rc.saveSnap(rd.Snapshot)
				rc.raftStorage.ApplySnapshot(rd.Snapshot)
				rc.publishSnapshot(rd.Snapshot)
			}
			rc.raftStorage.Append(rd.Entries)
			rc.transport.Send(rd.Messages)
			if ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok {
				rc.stop()
				return
			}
			rc.maybeTriggerSnapshot()
			rc.node.Advance()
	// ....
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;rc.wal.Save(rd.HardState, rd.Entries)：将客户端提交数据的数据写入wal中。&lt;/li&gt;
&lt;li&gt;rc.raftStorage.Append(rd.Entries)：这里的&lt;code&gt;raftStorage&lt;/code&gt;即前面提到的持久化数据缓冲区的&lt;code&gt;Storage&lt;/code&gt;接口，由&lt;code&gt;MemoryStorage&lt;/code&gt;接口实现，这一步将这些客户端提交的数据也写入持久化缓冲区的内部映像。&lt;/li&gt;
&lt;li&gt;rc.publishEntries(rc.entriesToApply(rd.CommittedEntries))：这个调用分为两步，第一步调用&lt;code&gt;entriesToApply&lt;/code&gt;是要从已达成一致的日志数据中过滤出真正可以进行apply的日志，因为里面的一些日志可能已经被应用层apply过，第二步将第一步过滤出来的日志数据通知给应用层。在&lt;code&gt;raftexample&lt;/code&gt;这个示例代码中，最终这些已经达成一致的数据，会被遍历生成KV内存数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里有一个问题：客户端提交过来的数据，还未达成集群内半数节点的一致，这时候就去做落盘操作，如果提交过程中发现出了问题，实际这条数据并不能最终达成一致，那么已落盘的数据怎么办？&lt;/p&gt;

&lt;p&gt;在这里，&lt;code&gt;etcd&lt;/code&gt;落盘客户端提交的数据时，是写入到WAL文件中的，后面发生了错误，如leader变成了follower时，日志需要进行了回滚操作等，也还是将那些正确的日志继续添加到WAL日志后面，服务如果重启，就是把这些日志按照顺序重放（replay）一遍，这里不可避免的会有一些冗余的操作，但是随着快照文件的产生，这个问题已经不大了。&lt;/p&gt;

&lt;p&gt;其次，不论是前面提到的&lt;code&gt;未持久化数据缓冲区&lt;/code&gt;，还是&lt;code&gt;持久化数据缓冲区&lt;/code&gt;，在往缓冲区中添加日志的函数实现中，都会去判断日志是否发生了回滚，会将当前传入的日志按照正确的日志索引放到缓冲区合适的位置。&lt;code&gt;未持久化数据缓冲区&lt;/code&gt;这部分操作在函数&lt;code&gt;unstable.truncateAndAppend&lt;/code&gt;中，&lt;code&gt;持久化数据缓冲区&lt;/code&gt;这部分操作在函数&lt;code&gt;MemoryStorage.Append&lt;/code&gt;中，感兴趣的可以去看看具体的实现，在这里就不再展开了。&lt;/p&gt;

&lt;h3 id=&#34;数据流动的全流程&#34;&gt;数据流动的全流程&lt;/h3&gt;

&lt;p&gt;以上解释了客户端提交的数据在两个缓冲区、持久化存储、以及最终达成一致之后给应用层的过程，下面以例子分别来解释客户端提交数据的流程以及快照数据恢复的流程。&lt;/p&gt;

&lt;h4 id=&#34;客户端提交数据的流程&#34;&gt;客户端提交数据的流程&lt;/h4&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/wal.png&#34; alt=&#34;客户端提交数据的流动&#34; title=&#34;客户端提交数据的流动&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;1、客户端提交数据给服务器。&lt;/p&gt;

&lt;p&gt;2、接着看这条数据走过的”存储“路径：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、首先，`raft`库会首先将日志数据写入`未持久化数据缓冲区`。

2、由于`未持久化数据缓冲区`中有新增的数据，会通过`Ready`结构体通知给应用层。

3、应用层收到`Ready`结构体之后，将其中的数据写入WAL持久化存储，然后更新这块数据到`已持久化数据缓冲区`。

4.1、持久化完毕后，应用层通过`Advance`接口通知`Raft`库这些数据已经持久化，于是raft库修改`未持久化数据缓冲区`将客户端刚提交的数据从这个缓冲区中删除。

4.2、持久化完毕之后，除了通知删除`未持久化数据缓冲区`，还讲数据通过网络同步给集群中其他节点。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3、集群中半数节点对该提交数据达成了一致，可以应答给客户端了。&lt;/p&gt;

&lt;h4 id=&#34;启动时使用快照数据恢复流程&#34;&gt;启动时使用快照数据恢复流程&lt;/h4&gt;

&lt;p&gt;下面以例子来实际解释etcd raft中数据在未持久化缓存、wal日志、持久化数据内容映像中的流动：&lt;/p&gt;

&lt;p&gt;1、节点N启动，加入到集群中，此时发现N上面没有数据，于是集群中的leader节点会首先通过rpc消息将快照数据发送给节点N。&lt;/p&gt;

&lt;p&gt;2、节点N收到快照数据，首先会保存到未持久化数据缓存中。&lt;/p&gt;

&lt;p&gt;3、Raft通过&lt;code&gt;Ready&lt;/code&gt;结构体通知应用层有快照数据。&lt;/p&gt;

&lt;p&gt;4、应用层（也就是etcdserver）将快照数据写入wal持久化存储中，这一步可以理解为将快照数据落盘。&lt;/p&gt;

&lt;p&gt;5、落盘之后，调用&lt;code&gt;MemoryStorage&lt;/code&gt;结构体的&lt;code&gt;ApplySnapshot&lt;/code&gt;将快照数据保存到持久化数据内存映像中。&lt;/p&gt;

&lt;p&gt;6、（图中未给出）调用Raft库的&lt;code&gt;Advance&lt;/code&gt;接口通知raft库传递过来的&lt;code&gt;Ready&lt;/code&gt;结构体数据已经操作完毕，这时候对应的，raft库就会把第二步中保存到未持久化数据缓存的快照数据给删除了。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/snapshot.png&#34; alt=&#34;快照数据的流动&#34; title=&#34;快照数据的流动&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;以上是快照数据的流动过程，在节点N接收并持久化快照数据后，后面就可以接收正常的日志了，日志数据的流动过程跟快照数据实际是差不多的，就不再阐述了。&lt;/p&gt;

&lt;p&gt;从上面的流程中也可以看出，应用层也就是etcdserver的持久化数据，只有wal日志而已，情况确实是这样的，其接口和实现如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Storage interface {
	// Save function saves ents and state to the underlying stable storage.
	// Save MUST block until st and ents are on stable storage.
	Save(st raftpb.HardState, ents []raftpb.Entry) error
	// SaveSnap function saves snapshot to the underlying stable storage.
	SaveSnap(snap raftpb.Snapshot) error
	// DBFilePath returns the file path of database snapshot saved with given
	// id.
	DBFilePath(id uint64) (string, error)
	// Close closes the Storage and performs finalization.
	Close() error
}

type storage struct {
	*wal.WAL
	*snap.Snapshotter
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Storage&lt;/code&gt;接口是etcdserver持久化数据的接口，其保存的数据有两个接口：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Save(st raftpb.HardState, ents []raftpb.Entry) error：保存日志数据。&lt;/li&gt;
&lt;li&gt;SaveSnap(snap raftpb.Snapshot) error：保存快照数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而&lt;code&gt;Storage&lt;/code&gt;接口由下面的&lt;code&gt;storage&lt;/code&gt;结构体来实现，其又分为两部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;wal：用于实现WAL日志的读写。&lt;/li&gt;
&lt;li&gt;snap：用于实现快照数据的读写。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里就不展开讨论了。&lt;/p&gt;

&lt;h3 id=&#34;节点进度的管理&#34;&gt;节点进度的管理&lt;/h3&gt;

&lt;p&gt;前面提到过，一致性算法与TCP之类的协议，本质上都需要管理未确认数据的缓冲区，但是不同的是，参与一致性算法确认的成员，不会像一般的点对点通信协议那样只有两个，在raft算法中，leader节点除了要维护未持久化缓冲区之外，还需要维护一个数据结构，用于保存集群中其他节点的进度，这部分数据在etcd raft中保存在结构体&lt;code&gt;Progress&lt;/code&gt;中，我将我之前阅读过程中加上的注释一并贴出来：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 该数据结构用于在leader中保存每个follower的状态信息，leader将根据这些信息决定发送给节点的日志
// Progress represents a follower’s progress in the view of the leader. Leader maintains
// progresses of all followers, and sends entries to the follower based on its progress.
type Progress struct {
	// Next保存的是下一次leader发送append消息时传送过来的日志索引
	// 当选举出新的leader时，首先初始化Next为该leader最后一条日志+1
	// 如果向该节点append日志失败，则递减Next回退日志，一直回退到索引匹配为止

	// Match保存在该节点上保存的日志的最大索引，初始化为0
	// 正常情况下，Next = Match + 1
	// 以下情况下不是上面这种情况：
	// 1. 切换到Probe状态时，如果上一个状态是Snapshot状态，即正在接收快照，那么Next = max(pr.Match+1, pendingSnapshot+1)
	// 2. 当该follower不在Replicate状态时，说明不是正常的接收副本状态。
	//    此时当leader与follower同步leader上的日志时，可能出现覆盖的情况，即此时follower上面假设Match为3，但是索引为3的数据会被
	//    leader覆盖，此时Next指针可能会一直回溯到与leader上日志匹配的位置，再开始正常同步日志，此时也会出现Next != Match + 1的情况出现
	Match, Next uint64
	// State defines how the leader should interact with the follower.
	//
	// When in ProgressStateProbe, leader sends at most one replication message
	// per heartbeat interval. It also probes actual progress of the follower.
	//
	// When in ProgressStateReplicate, leader optimistically increases next
	// to the latest entry sent after sending replication message. This is
	// an optimized state for fast replicating log entries to the follower.
	//
	// When in ProgressStateSnapshot, leader should have sent out snapshot
	// before and stops sending any replication message.

	// ProgressStateProbe：在每次heartbeat消息间隔期最多发一条同步日志消息给该节点
	// ProgressStateReplicate：正常的接受副本数据状态。当处于该状态时，leader在发送副本消息之后，
	// 就修改该节点的next索引为发送消息的最大索引+1
	// ProgressStateSnapshot：接收副本状态
	State ProgressStateType
	// Paused is used in ProgressStateProbe.
	// When Paused is true, raft should pause sending replication message to this peer.
	// 在状态切换到Probe状态以后，该follower就标记为Paused，此时将暂停同步日志到该节点
	Paused bool

	// PendingSnapshot is used in ProgressStateSnapshot.
	// If there is a pending snapshot, the pendingSnapshot will be set to the
	// index of the snapshot. If pendingSnapshot is set, the replication process of
	// this Progress will be paused. raft will not resend snapshot until the pending one
	// is reported to be failed.
	// 如果向该节点发送快照消息，PendingSnapshot用于保存快照消息的索引
	// 当PendingSnapshot不为0时，该节点也被标记为暂停状态。
	// raft只有在这个正在进行中的快照同步失败以后，才会重传快照消息
	PendingSnapshot uint64

	// RecentActive is true if the progress is recently active. Receiving any messages
	// from the corresponding follower indicates the progress is active.
	// RecentActive can be reset to false after an election timeout.
	RecentActive bool

	// inflights is a sliding window for the inflight messages.
	// Each inflight message contains one or more log entries.
	// The max number of entries per message is defined in raft config as MaxSizePerMsg.
	// Thus inflight effectively limits both the number of inflight messages
	// and the bandwidth each Progress can use.
	// When inflights is full, no more message should be sent.
	// When a leader sends out a message, the index of the last
	// entry should be added to inflights. The index MUST be added
	// into inflights in order.
	// When a leader receives a reply, the previous inflights should
	// be freed by calling inflights.freeTo with the index of the last
	// received entry.
	// 用于实现滑动窗口，用来做流量控制
	ins *inflights
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;总结来说，&lt;code&gt;Progress&lt;/code&gt;结构体做的工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;维护follower节点的match、next索引，以便知道下一次从哪里开始同步数据。&lt;/li&gt;
&lt;li&gt;维护着follower节点当前的状态。&lt;/li&gt;
&lt;li&gt;同步快照数据的状态。&lt;/li&gt;
&lt;li&gt;流量控制，避免follower节点超载。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;具体的算法细节，就不在这里贴出了。&lt;/p&gt;

&lt;h2 id=&#34;网络数据的收发以及日志的持久化&#34;&gt;网络数据的收发以及日志的持久化&lt;/h2&gt;

&lt;p&gt;网络数据的收发以及日志的持久化，这两部分在etcd raft库中，并不是由raft库来实现，而是通过&lt;code&gt;Ready&lt;/code&gt;结构体来通知应用层，由应用层来完成。&lt;/p&gt;

&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;

&lt;p&gt;这里将上面的几部分总结如下，有了整体的理解才能更好的了解细节：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/summary.png&#34; alt=&#34;Raft算法几要素在etcd raft中的实现&#34; title=&#34;Raft算法几要素在etcd raft中的实现&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Read Code(En Version)</title>
      <link>https://www.codedump.info/post/20210215-how-to-read-code-en/</link>
      <pubDate>Mon, 15 Feb 2021 09:46:47 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20210215-how-to-read-code-en/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;I wrote a document in 2019 &lt;a href=&#34;https://www.codedump.info/post/20190324-how-to-read-code/&#34;&gt;&amp;ldquo;How to read a source code?&amp;rdquo;&lt;/a&gt;, and now looking back, there is room for improvement in this document,so I have reorganized it on top of that.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The ability to read source code is considered to be one of the underlying fundamental programmer skills, and the reason why this ability is important is that&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;inevitably need to read or take over other people&amp;rsquo;s projects. For example, researching an open source project, such as taking over a project from someone else.&lt;/li&gt;
&lt;li&gt;Reading good project source code is one of the important ways to learn from other people&amp;rsquo;s good experience, which I know myself.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reading code and writing code are two not quite the same skills, the reason is that &amp;ldquo;&lt;a href=&#34;https://www.zhihu.com/question/21820752/answer/19427754&#34;&gt;writing code is expressing yourself, reading code is understanding others&lt;/a&gt;&amp;rdquo;. Because of the many projects, the authors of the project have their own style, it takes a lot of energy to understand.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been in the business for years reading the project source code in general and in detail, and have written some code analysis articles one after another, so I&amp;rsquo;ll briefly summarize my approach in this article.&lt;/p&gt;

&lt;h1 id=&#34;the-first-thing-run-it&#34;&gt;the first thing:run it!&lt;/h1&gt;

&lt;p&gt;The first step to start reading a project source code, is to let the project through your own compilation and run smoothly. This is especially important.&lt;/p&gt;

&lt;p&gt;Some projects are complex and depend on many components, so it is not easy to set up a debugging environment, so it is not always possible for all projects to run smoothly. If you can compile and run it yourself, then the scenario analysis, plus debugging code, debugging, and so on will have the basis to unfold.&lt;/p&gt;

&lt;p&gt;In my experience, a project code, whether the debugging environment can be built smoothly, the efficiency is very different.&lt;/p&gt;

&lt;p&gt;After running, and to try to streamline their environment to reduce the debugging process of interference information. For example, Nginx uses multiple processes to process requests. In order to debug the behavior of Nginx, I often set the number of workers to 1, so that when debugging you know which process is to be tracked.&lt;/p&gt;

&lt;p&gt;For example, many projects are compiled with optimization options or without debugging information by default, which can be a problem when debugging, so I modify the makefile to compile to &lt;code&gt;-O0 -g&lt;/code&gt;, which is compiled to generate a version with debugging information and no optimization.&lt;/p&gt;

&lt;p&gt;All in all, the debugging efficiency can be improved a lot after running, but under the premise of running and trying to streamline the environment to exclude the disturbing factors.&lt;/p&gt;

&lt;h1 id=&#34;clearly-define-your-purpose&#34;&gt;Clearly define your purpose&lt;/h1&gt;

&lt;p&gt;Although it is important to read the project source code, not all projects need to be read from start to finish. Before you start reading, you need to be clear about your purpose: whether you need to understand the implementation of one of the modules, the general structure of the framework, the implementation of one of the algorithms, and so on.&lt;/p&gt;

&lt;p&gt;For example, many people look at the code of Nginx, and the project has many modules, including the basic core modules (epoll, network sending and receiving, memory pooling, etc.) and modules that extend a specific function, and not all of these modules need to be understood very clearly.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Understanding the underlying processes at the core of Nginx and the data structures.&lt;/li&gt;
&lt;li&gt;Understanding how Nginx implements a module.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this general understanding of the project, all that remains is to look at the specific code implementation when you encounter a specific problem.&lt;/p&gt;

&lt;p&gt;All in all, it is not recommended to start reading the code of a project without a purpose, as looking at it headlessly will only consume your time and enthusiasm.&lt;/p&gt;

&lt;h1 id=&#34;distinguish-between-main-and-branch-storylines&#34;&gt;Distinguish between main and branch storylines&lt;/h1&gt;

&lt;p&gt;With a clear purpose in mind, you can distinguish between main and subplots in the reading process. For example.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For example, if you want to understand the implementation of a business logic that uses a dictionary to store data in a function, here, &amp;ldquo;how the dictionary data structure is implemented&amp;rdquo; is a side plot, and you don&amp;rsquo;t need to look deeper into its implementation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Guided by this principle, the reader only needs to understand the external interfaces to the code of the stems, such as a class that does not need to understand its implementation, and to understand the entry and exit parameters and the role of these interfaces, treating this part as a &amp;ldquo;black box&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;By the way, in the early years, I saw a way of writing C++ in which the header file contains only the external interface declaration of a class, and the implementation is transferred to the C++ file through an internal impl class, for example.&lt;/p&gt;

&lt;p&gt;Header file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;// test.h
class Test {
public:
  void fun();

private:
  class Impl;
  Impl *impl_;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;C++ file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;void Test::fun() {
  impl_-&amp;gt;fun()
}

class Test::Impl {
public:
  void fun() {
    // Concrete implementation
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This way of writing makes the header file a lot cleaner: there are no private members or functions associated with the implementation, only the exposed interface, so the user can know at a glance what the class offers to the public.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
! &lt;a href=&#34;https://www.codedump.info/media/imgs/20200605-how-to-read-code-v2020/impl.png&#34; title=&#34;impl&#34;&gt;impl&lt;/a&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The &amp;ldquo;main&amp;rdquo; and &amp;ldquo;branch&amp;rdquo; storylines switch frequently throughout the code reading process, requiring the reader to have some experience in knowing which part of the code they are reading is the main storyline.&lt;/p&gt;

&lt;h1 id=&#34;vertical-and-horizontal&#34;&gt;Vertical and horizontal&lt;/h1&gt;

&lt;p&gt;The code reading process is divided into two different directions.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Vertical: Read in the order of the code. Vertical reading is often required when a specific understanding of a process or algorithm is needed.&lt;/li&gt;
&lt;li&gt;Horizontal: Read different modules, and often when you need to first figure out the overall framework, you need to read horizontally.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The two directions of reading, should alternate, which requires the code reader to have some experience and be able to grasp the current direction of code reading. My advice is: the process still puts the whole first, and do not go too deep into a particular detail without understanding the overall premise. Consider a function or data structure as a black box, know their input and output, as long as it does not affect the understanding of the whole, then put it aside and move on.&lt;/p&gt;

&lt;h1 id=&#34;scenario-analysis&#34;&gt;Scenario analysis&lt;/h1&gt;

&lt;p&gt;If you have the previous foundation, you have been able to make the project run smoothly in your own debugging environment, and you have clarified the functions you want to understand, then you can do a scenario analysis of the project code.&lt;/p&gt;

&lt;p&gt;The so-called &amp;ldquo;scenario analysis&amp;rdquo; is to construct some scenarios by yourself, and then analyze the behavior in these scenarios by adding breakpoints and debugging statements.&lt;/p&gt;

&lt;p&gt;For example, when I wrote &lt;a href=&#34;https://book.douban.com/subject/27108476/&#34;&gt;Lua Design and Implementation&lt;/a&gt;, I explained the process of interpreting and executing Lua virtual machine instructions, and needed to analyze each instruction, so I used scenario analysis. I would simulate the Lua script code that uses the instruction, and then breakpoint in the program to debug the behavior in these scenarios.&lt;/p&gt;

&lt;p&gt;My usual approach is to add a breakpoint to an important entry function, then construct debugging code that triggers the scenario, and when the code stops at the breakpoint, observe the behavior of the code by looking at the stack, variable values, and so on.&lt;/p&gt;

&lt;p&gt;For example, in Lua interpreter code, generating Opcode will eventually call the function luaK_code, so I&amp;rsquo;ll add a breakpoint above this function and construct the scene I want to debug, and as soon as I break at the breakpoint, I&amp;rsquo;ll see the complete call flow through the function stack: ``C&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;(lldb) bt
* thread #1: tid = 0xb1dd2, 0x00000001000071b0 lua`luaK_code, queue = &#39;com.apple.main-thread&#39;, stop reason = breakpoint 1.1
* frame #0: 0x00000001000071b0 lua`luaK_code
frame #1: 0x000000010000753e lua`discharge2reg + 238
frame #2: 0x000000010000588f lua`exp2reg + 31
frame #3: 0x000000010000f15b lua`statement + 3131
frame #4: 0x000000010000e0b6 lua`luaY_parser + 182
frame #5: 0x0000000100009de9 lua`f_parser + 89
frame #6: 0x0000000100008ba5 lua`luaD_rawrunprotected + 85
frame #7: 0x0000000100009bf4 lua`luaD_pcall + 68
frame #8: 0x0000000100009d65 lua`luaD_protectedparser + 69
frame #9: 0x00000001000047e1 lua`lua_load + 65
frame #10: 0x0000000100018071 lua`luaL_loadfile + 433
frame #11: 0x0000000100000eb9 lua`pmain + 1545
frame #12: 0x00000001000090cd lua`luaD_precall + 589
frame #13: 0x00000001000098c1 lua`luaD_call + 81
frame #14: 0x0000000100008ba5 lua`luaD_rawrunprotected + 85
frame #15: 0x0000000100009bf4 lua`luaD_pcall + 68
frame #16: 0x00000001000046fb lua`lua_cpcall + 43
frame #17: 0x00000001000007af lua`main + 63
frame #18: 0x00007fff6468708d libdyld.dylib`start + 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The advantage of scenario analysis is that instead of looking for a needle in a haystack, you can narrow down the problem to a scope and understand it.&lt;/p&gt;

&lt;p&gt;The concept of &amp;ldquo;scenario analysis&amp;rdquo; is not a term I came up with. For example, there are several books that analyze code, such as &lt;a href=&#34;https://book.douban.com/subject/1231584/&#34;&gt;Linux Kernel Source Code Scenario Analysis&lt;/a&gt;, &lt;a href=&#34;https://book.douban.com/subject/1231584/&#34;&gt;Windows Kernel Scenario Analysis&lt;/a&gt;, and &lt;a href=&#34;https://book.douban.com/subject/1231584/&#34;&gt;Windows Kernel Scenario Analysis&lt;/a&gt;. Windows Kernel Scenario Analysis&amp;rdquo;](&lt;a href=&#34;https://book.douban.com/subject/3715700/&#34;&gt;https://book.douban.com/subject/3715700/&lt;/a&gt;).&lt;/p&gt;

&lt;h1 id=&#34;make-use-of-good-test-cases&#34;&gt;Make use of good test cases&lt;/h1&gt;

&lt;p&gt;Good projects come with a lot of use cases, examples of this type are: etcd, a few open source projects produced by google.&lt;/p&gt;

&lt;p&gt;If the test cases are written very carefully, then it is worthwhile to study them. The reason is: test cases are often for a single scenario, alone to construct some data to verify the process of the program. So, like the previous &amp;ldquo;scenario analysis&amp;rdquo;, it&amp;rsquo;s a way to move you from a big project to a specific scenario.&lt;/p&gt;

&lt;h1 id=&#34;clarify-the-relationship-between-core-data-structures&#34;&gt;Clarify the relationship between core data structures&lt;/h1&gt;

&lt;p&gt;Although it is said that &amp;ldquo;programming = algorithm + data structure&amp;rdquo;, my experience in practice is that data structure is more important.&lt;/p&gt;

&lt;p&gt;Because the structure defines the architecture of a program, there is no concrete implementation until the structure is set. Like building a house, the data structure is the framework structure of the house, if a house is very large, and you do not know the structure of the house, will be lost in it. As for the algorithm, if it is a part of the details that you do not need to delve into for the time being, you can refer to the previous section &amp;ldquo;Distinguishing the main and branch storylines&amp;rdquo; to understand the entrance and exit parameters and their roles first.&lt;/p&gt;

&lt;p&gt;Linus says: &amp;ldquo;Bad programmers care about code. Good programmers care about data structures and how they relate to each other.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Therefore, when reading a piece of code, it is especially important to clarify the relationships between the core data structures. At this time, it is necessary to use some tools to draw the relationship between these structures. There are many such examples in my source code analysis class blogs, such as &lt;a href=&#34;https://www.codedump.info/post/20190215-leveldb/&#34;&gt;Notes on Reading Leveldb Code&lt;/a&gt;, &lt;a href=&#34;https://www.codedump.info/post/20181125-etcd-server/&#34;&gt;Implementation of Etcd Storage&lt;/a&gt;, and so on.&lt;/p&gt;

&lt;p&gt;It should be noted that there is no strict sequential relationship between the two steps of scenario analysis and clarifying the core data structure; it does not have to be something first and then something else, but rather interactively.&lt;/p&gt;

&lt;p&gt;For example, if you have just taken over a project and need to understand the project briefly, you can first read the code to understand what core data structures are available. Once you understand it, if you are not sure about the process in certain scenarios, you can use scenario analysis. In short, alternate until your questions are answered.&lt;/p&gt;

&lt;h1 id=&#34;ask-yourself-more-questions&#34;&gt;Ask yourself more questions&lt;/h1&gt;

&lt;p&gt;The learning process cannot be separated from the interaction.&lt;/p&gt;

&lt;p&gt;If reading code is just an input, then there needs to be an output. Only simple input is like feeding something to you, and only better digestion can become your own nutrition, and output is an important means to better digest knowledge.&lt;/p&gt;

&lt;p&gt;In fact, this idea is very common, for example, students need to do practice assignments (Output) in class (Input), such as learning algorithms (Input) need to practice their own coding (Output), and so on. In short, output is a kind of timely feedback in the learning process, and the higher the quality, the more efficient the learning.&lt;/p&gt;

&lt;p&gt;There are many means of output, and when reading the code, it is more recommended to be able to ask yourself more questions, such as.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Why did you choose this data structure to describe this problem? How are other projects designed in similar scenarios? What data structures are there to do such a thing?&lt;/li&gt;
&lt;li&gt;If I were to design such a project, what would I do?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And so on and so forth. The more active and positive thinking you do, the better output you will have, and the quality of output is directly proportional to the quality of learning.&lt;/p&gt;

&lt;h1 id=&#34;write-your-own-code-reading-notes&#34;&gt;Write your own code reading notes&lt;/h1&gt;

&lt;p&gt;Since I started blogging, I have been writing code reading articles for various projects, and my screen name &amp;ldquo;codedump&amp;rdquo; also comes from the idea of trying to &amp;ldquo;dump the code internal implementation principle&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;As mentioned earlier, the quality of learning is directly proportional to the quality of output, which is my own deep experience. Because of this, I insist on writing my own analysis notes after reading the source code.&lt;/p&gt;

&lt;p&gt;Here are a few things to keep in mind when writing these kinds of notes.&lt;/p&gt;

&lt;p&gt;Although they are notes, imagine that you are explaining the principles to someone who is less familiar with the project, or imagine that you are looking back at the article months or even years later. In this case, try to organize the language as well as possible and explain it in a step-by-step manner.&lt;/p&gt;

&lt;p&gt;Try to avoid posting large paragraphs of code. I think it&amp;rsquo;s a bit self-defeating to post large paragraphs of code in such articles: it just looks like you understand it, but you don&amp;rsquo;t. If you really want to explain a piece of code, you can use pseudo-code or reduced code. Remember: don&amp;rsquo;t kid yourself, really get it. If you really want to add your own comments to the code, one suggestion I have is to fork a copy of some version of the project and commit it to your own github, where you can always add your own comments and save the commit. For example, my own commented code for etcd 3.1.10: &lt;a href=&#34;https://github.com/lichuang/etcd-3.1.10-codedump&#34;&gt;etcd-3.1.10-codedump&lt;/a&gt;, similarly other projects I read will fork a project on github with codedump suffix of the project.&lt;/p&gt;

&lt;p&gt;Draw more diagrams, a picture is worth a thousand words, use graphics to show the relationship between the code flow, data structures. I just recently discovered that the ability to draw diagrams is also an important ability, and I&amp;rsquo;m learning how to use images to express my ideas from scratch.&lt;/p&gt;

&lt;p&gt;Writing is an important foundational ability, and a friend of mine recently educated me to the effect that if you are strong in something, if you add good writing and good English, then it will greatly amplify your ability in that area. And similar to writing, English such as the underlying basic ability, not a handful, need to keep practicing for a long time to be able to. And writing a blog, for technical staff, is a good means to exercise writing.&lt;/p&gt;

&lt;p&gt;PS: If many things, you then do when you can think of the future to face the output of the person is your own, such as their own written code to maintain the back of their own articles written for their own eyes, and so on, the world will be much better. For example, writing a technical blog about these things, because I am writing when I consider that the person who will look at this document may be myself, so when writing will try to be clear and easy to understand, trying to see myself after a period of time when I see their own document, I can immediately recall the details of the time, but also because of this, I rarely post large sections of code in the blog, as far as possible to supplement the legend.&lt;/p&gt;

&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;

&lt;p&gt;The above is my brief summary of some of the means and methods of attention when reading source code, in general there are so many points, right?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Only better output can better digest the knowledge, the so-called build debugging environment, scenario analysis, ask yourself more questions, write code reading notes, etc. are all around the output to start. In short, you can&amp;rsquo;t be like a dead fish and expect to fully understand its principles just by reading the code, you need to find ways to interact with it.&lt;/li&gt;
&lt;li&gt;Writing is one of the basic hard skills of a person, not only to exercise their ability to express themselves, but also to help organize their thoughts. One means of exercising writing skills for programmers is to write a blog, and the sooner you start exercising, the better.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finally, as with any skill that can be acquired, the ability to read code requires long hours and lots of repetition, so next time start working on a project that interests you.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>KCP 1.4源码分析</title>
      <link>https://www.codedump.info/post/20201105-kcp/</link>
      <pubDate>Thu, 05 Nov 2020 22:08:40 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20201105-kcp/</guid>
      <description>

&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/skywind3000/kcp&#34;&gt;KCP&lt;/a&gt;是基于UDP协议之上的ARQ协议实现。TCP虽然使用的更广泛，但是在某些实时性要求更高的领域（如实时音视频、即时在线游戏等），会更倾向于使用基于UDP的可靠传输协议。&lt;/p&gt;

&lt;p&gt;在项目的官网上，对KCP是这么介绍的：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;KCP是一个快速可靠协议，能以比 TCP 浪费 10%-20% 的带宽的代价，换取平均延迟降低 30%-40%，且最大延迟降低三倍的传输效果。纯算法实现，并不负责底层协议（如UDP）的收发，需要使用者自己定义下层数据包的发送方式，以 callback的方式提供给 KCP。 连时钟都需要外部传递进来，内部不会有任何一次系统调用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;UDP并不是一个可靠的传输协议，如果数据没有发送成功并不会自动重传，KCP基于UDP协议之上实现了自己的ARQ协议，所以在继续介绍KCP协议之前，先大体了解一下ARQ协议。&lt;/p&gt;

&lt;h2 id=&#34;arq的两种模式&#34;&gt;ARQ的两种模式&lt;/h2&gt;

&lt;p&gt;KCP在UDP之上，自己实现了可靠性的算法，即给UDP加上了诸如超时重传、流量控制等机制，这些都是为了保证ARQ协议的运作。&lt;/p&gt;

&lt;p&gt;ARQ协议(Automatic Repeat-reQuest)，即自动重传请求，是传输层的错误纠正协议之一，它通过使用确认和超时两个机制，在不可靠的网络上实现可靠的信息传输。&lt;/p&gt;

&lt;p&gt;ARQ的实现通常有如下两种模式。&lt;/p&gt;

&lt;h3 id=&#34;停等arq协议-stop-and-wait&#34;&gt;停等ARQ协议（stop-and-wait）&lt;/h3&gt;

&lt;p&gt;停等ARQ协议，意味着每个数据在发送出去之后，在没有收到对端的接收回复之前，将一直等待下去，而不会继续发送新的数据包。如果超时还未收到应答，就会自动重传数据包，以保证数据的可靠性。&lt;/p&gt;

&lt;p&gt;下图是两种情况下停等协议的示意图：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20201105-kcp/stop-and-wait.png&#34; alt=&#34;stop-and-wait&#34; title=&#34;stop-and-wait&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;上图：正常不出错情况下运行的停等协议，消息2必须在发送方收到了消息1的对端确认回复之后才能发送出去。&lt;/li&gt;
&lt;li&gt;下图：出错情况下运行的停等协议，发送方发现消息1超时还未收到应答，就触发了针对消息1的重传机制。在这之前消息2都不会被发出去。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;协议栈如何确认这个“超时时间”呢？答案是根据数据往返时间动态估算出来的RTO（Retransmission TimeOut，重传超时时间）时间来确认的。&lt;/p&gt;

&lt;h3 id=&#34;连续arq协议-continuous-arq&#34;&gt;连续ARQ协议（Continuous ARQ）&lt;/h3&gt;

&lt;p&gt;可以看到，停等协议的机制是“一应一答”式的，对带宽的利用率不高，传输效率不高。&lt;/p&gt;

&lt;p&gt;连续ARQ协议，可以一次性发送多个数据，而不必像停等协议那样需要等待上一个数据包的确认回复才能继续发送数据。&lt;/p&gt;

&lt;p&gt;在使用连续ARQ协议的时候，接收方也并不会针对每一个收到的数据包进行确认应答，而只需应答确认最大的那个数据包，这时就认为在此之前的数据包都收到了。&lt;/p&gt;

&lt;p&gt;这种模式称为“UNA（unacknowledge，即第一个未应答数据包的序列号，小于该序列号的数据包都已经确认被接收到）”模式，与之对应的是，停等协议是ACK模式。&lt;/p&gt;

&lt;p&gt;然而，即便是可以一次发送多个数据包，也不意味着可以不受控制的发送数据，因为还要受到几种流量窗口的限制，这部分被称为“流量控制”。&lt;/p&gt;

&lt;h3 id=&#34;拥塞窗口&#34;&gt;拥塞窗口&lt;/h3&gt;

&lt;p&gt;拥塞窗口更多是对网络上经过的网络设备总体网络情况的一个预估。因为在真正发送数据时，并不清楚这时候的网络情况，因此启动时拥塞窗口会有一个初始值，然后根据以下几种算法进行动态的调整：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;慢启动：在启动时让拥塞窗口缓慢扩张。&lt;/li&gt;
&lt;li&gt;退半避让：在发生网络拥堵时让拥塞窗口大小减半。&lt;/li&gt;
&lt;li&gt;快重传：在网络恢复时尽快的将数据发送出去。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;滑动窗口&#34;&gt;滑动窗口&lt;/h3&gt;

&lt;p&gt;拥塞窗口是对外部网络情况的一种动态的检测，而滑动窗口则是进程本身接收缓冲区的控制，滑动窗口就是接收方用来通知发送方本方接收缓冲区大小的。由于一个网络进程分为协议层和应用层，如果协议层接收数据很快，但是应用层消费数据很慢，这个滑动窗口就会缩小，通过这种方式来通知对端放缓数据的发送，因为接收方已经忙不过来了。&lt;/p&gt;

&lt;p&gt;KCP作为一个ARQ协议，内部就是要实现对以上这些机制的支持。&lt;/p&gt;

&lt;p&gt;如果对TCP协议的实现有一些了解，可以看到上述的对端确认回复、超时重传、拥塞窗口、滑动窗口等概念，在TCP中就有，KCP自己实现的ARQ机制，与TCP对比起来有如下的不同点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在TCP中，超时之后的RTO时间直接翻倍（即RTO*2），而在KCP启用了快速模式之后，RTO的超时时间是*1.5，避免RTO时间的快速增长。&lt;/li&gt;
&lt;li&gt;TCP协议在丢包时会直接重传丢的那个包之后的所有数据包，KCP只会选择性的重传真正丢失的数据包。&lt;/li&gt;
&lt;li&gt;TCP为了充分利用带宽，会延迟发送ACK应答对端，这样会导致计算出来的RTT时间过大，KCP的ACK是否延迟发送则可以调节。&lt;/li&gt;
&lt;li&gt;KCP 正常模式同 TCP 一样使用公平退让法则，即发送窗口大小由：发送缓存大小、接收端剩余接收缓存大小、丢包退让及慢启动这四要素决定。但传送及时性要求很高的小数据时，可选择通过配置跳过后两步，仅用前两项来控制发送频率。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文基于KCP 1.4版本对其实现做分析。&lt;/p&gt;

&lt;h1 id=&#34;术语概念&#34;&gt;术语概念&lt;/h1&gt;

&lt;p&gt;在展开讨论之前，首先介绍相关的术语概念。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ARQ：Automatic Repeat-reQuest，自动重传请求协议。KCP就是其中一种ARQ协议的实现。&lt;/li&gt;
&lt;li&gt;MTU：Maximum Transmission Unit，最大传输单元，链路层规定的每一帧最大长度，通常为1500字节。&lt;/li&gt;
&lt;li&gt;MSS：Maximum Segment Size，最大分段大小。通常为MTU-协议头大小。&lt;/li&gt;
&lt;li&gt;RTT：Round-Trip Time，数据往返时间，即发出消息到接收到对端消息应答之间的时间差。&lt;/li&gt;
&lt;li&gt;RTO：Retransmission TimeOut，重传超时时间，根据收集到的RTT时间估算。&lt;/li&gt;
&lt;li&gt;rwnd：Receive Window，接收窗口大小，接收端通过该数据通知发送端本方接收窗口大小。&lt;/li&gt;
&lt;li&gt;cwnd：Congestion Window，拥塞窗口大小，影响发送方发送数据大小。&lt;/li&gt;
&lt;li&gt;ack：acknowledge，接收端接收到一个数据包之后，通过应答该数据包序列号来通知发送端接收成功。&lt;/li&gt;
&lt;li&gt;una：unacknowledge，即第一个未应答数据包的序列号，小于该序列号的数据包都已经确认被接收到。&lt;/li&gt;
&lt;li&gt;ssthresh：Slow Start threshold，慢启动阈值，用于在发生拥塞的情况下控制窗口的增长速度。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;数据结构&#34;&gt;数据结构&lt;/h1&gt;

&lt;h2 id=&#34;报文定义&#34;&gt;报文定义&lt;/h2&gt;

&lt;p&gt;每个KCP数据报文，其定义如下，注释中描述了每个字段的含义：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct IKCPSEG
{
	struct IQUEUEHEAD node;
	// 会话编号，两方一致才能通信
	IUINT32 conv;
	// 指令类型，可以同时有多个指令通过与操作设置进来
	IUINT32 cmd;
	// 分片编号，表示倒数第几个分片。
	IUINT32 frg;
	// 本方可用窗口大小
	IUINT32 wnd;
	// 当前时间
	IUINT32 ts;
	// 确认编号
	IUINT32 sn;
	// 代表编号前面的所有报都收到了的标志
	IUINT32 una;
	// 数据大小
	IUINT32 len;
	// 重传时间戳，超过这个时间重发这个包
	IUINT32 resendts;
	IUINT32 rto;
	// 快速应答数量，记录被跳过的次数，统计在这个封包的序列号之前有多少报已经应答了。
	// 比如1，2，3三个封包，收到2的时候知道1被跳过了，此时1的fastack加一，收到3的时候继续加一，超过一定阈值直接重传1这个封包。
	// 该阈值由ikcp_nodelay函数设置，默认为0
	IUINT32 fastack;
	// 重传次数
	IUINT32 xmit;
	// 数据
	char data[1];
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在这里，挑其中几个重点的字段来展开说说，其他的字段已经在上面的注释中有描述。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;conv：该字段是会话编号，由于UDP协议不是基于链接的，因此通信的双方需要会话编号一致才能进行通信。&lt;/li&gt;
&lt;li&gt;cmd：指令类型，具体有以下这几种：

&lt;ul&gt;
&lt;li&gt;IKCP_CMD_PUSH：传送数据。&lt;/li&gt;
&lt;li&gt;IKCP_CMD_ACK：应答接收到数据包。&lt;/li&gt;
&lt;li&gt;IKCP_CMD_WASK：探测接收端接收窗口大小。&lt;/li&gt;
&lt;li&gt;IKCP_CMD_WINS：通知接收窗口大小。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;frg：分片编号，当发送的数据超过MTU大小时，就会将数据分片来发送，该字段就是用来存储分片编号，值从大到小，比如有4个分片，则从第一块分片到第四块分片的报文，该字段依次为3、2、1、0。&lt;/li&gt;
&lt;li&gt;fastack：用于快速重传的字段，具体的使用在后面展开详细的讨论。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要说明的是，以上只是报文在内存中的表示，当写入报文时报文的头部数据如下（由于KCP文档中有这部分的图示就直接引用了）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kcp协议头,共24个字节
|&amp;lt;&amp;lt;----------- 4 bytes -----------&amp;gt;&amp;gt;|
|--------|--------|--------|--------|
|		conv		   |
|--------|--------|--------|--------|
|  cmd   |  frg   |	wnd	   |
|--------|--------|--------|--------|
|		ts	    	   |
|--------|--------|--------|--------|
|		sn		   |
|--------|--------|--------|--------|
|		una		   |
|--------|--------|--------|--------|
|		len		   |
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kcp结构体&#34;&gt;KCP结构体&lt;/h2&gt;

&lt;p&gt;除了上面定义每个报文的结构体之外，&lt;code&gt;kcp&lt;/code&gt;协议栈还有一个负责记录kcp协议栈信息的结构体&lt;code&gt;IKCPCB&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;其定义及成员的注释如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;struct IKCPCB
{
	// mss：MSS（Maximum Segment Size），最大报文长度
	IUINT32 conv, mtu, mss, state;
	// snd_una：最小的未ack序列号，即这个编号前面的所有报都收到了的标志
	// snd_nxt：下一个待发送的序列号
	// rcv_nxt：下一个待接收的序列号，会通过包头中的una字段通知对端
	IUINT32 snd_una, snd_nxt, rcv_nxt;
	// ssthresh：slow start threshhold，慢启动阈值
	IUINT32 ts_recent, ts_lastack, ssthresh;
	// RTT：Round Trip Time，往返时间
	// rx_rttval：RTT的平均偏差
	// rx_srtt：RTT的一个加权RTT平均值，平滑值。
	IINT32 rx_rttval, rx_srtt, rx_rto, rx_minrto;
	// rmt_wnd：对端（rmt=remote）窗口
	// probe：存储探测标志位
	IUINT32 snd_wnd, rcv_wnd, rmt_wnd, cwnd, probe;
	IUINT32 current, interval, ts_flush, xmit;
	// 接收和发送缓冲区大小
	IUINT32 nrcv_buf, nsnd_buf;
	// 接收和发送队列大小
	IUINT32 nrcv_que, nsnd_que;
	IUINT32 nodelay, updated;
	IUINT32 ts_probe, probe_wait;
	IUINT32 dead_link, incr;
	struct IQUEUEHEAD snd_queue;
	struct IQUEUEHEAD rcv_queue;
	struct IQUEUEHEAD snd_buf;
	struct IQUEUEHEAD rcv_buf;
	IUINT32 *acklist;
	IUINT32 ackcount;
	IUINT32 ackblock;
	void *user;
	char *buffer;
	int fastresend;
	int fastlimit;
	// nocwnd：是否关闭流控，0表示不关闭，默认值为0
	int nocwnd, stream;
	int logmask;
	int (*output)(const char *buf, int len, struct IKCPCB *kcp, void *user);
	void (*writelog)(const char *log, struct IKCPCB *kcp, void *user);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kcp库对外的接口中，首先需要调用&lt;code&gt;ikcp_create&lt;/code&gt;函数创建该结构体，才能继续后面的工作。&lt;/p&gt;

&lt;h2 id=&#34;几个队列&#34;&gt;几个队列&lt;/h2&gt;

&lt;p&gt;从上面定义的数据结构中，还看到了其中有队列指针，不难想象每个报文数据都是某种队列中的元素，确实也是这样，在KCP中定义了以下几个和报文相关的队列：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;snd_queue、nsnd_que：发送队列以及其大小。&lt;/li&gt;
&lt;li&gt;snd_buf、nsnd_buf：发送缓冲区及其大小。&lt;/li&gt;
&lt;li&gt;rcv_queue、nrcv_que：接收队列以及其大小。&lt;/li&gt;
&lt;li&gt;rcv_buf、nrcv_buf：接收缓冲区及其大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为什么发送和接收两端，既有缓冲区又有队列？在KCP中，队列是应用层可以直接进行读写的区域，而缓冲区则是KCP协议层接收和发送数据的区域了，如图所示：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20201105-kcp/kcp-queue-buf.png&#34; alt=&#34;kcp-queue-buf&#34; title=&#34;kcp-queue-buf&#34; /&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;在发送报文时，用户层调用&lt;code&gt;ikcp_send&lt;/code&gt;函数，该函数最终会分配报文结构体指针，然后添加到发送队列&lt;code&gt;snd_queue&lt;/code&gt;的末尾；而在KCP协议栈真正调用系统接口发送数据出去的时候，将从&lt;code&gt;snd_queue&lt;/code&gt;队列中将报文取出，放入&lt;code&gt;snd_buf&lt;/code&gt;缓冲区中再进行发送。接收报文的流程反之，这里就不再阐述了。&lt;/p&gt;

&lt;h1 id=&#34;核心流程&#34;&gt;核心流程&lt;/h1&gt;

&lt;p&gt;了解了相关的数据结构，这里开始分析核心流程。先来看看整体的框架。&lt;/p&gt;

&lt;h2 id=&#34;概述-1&#34;&gt;概述&lt;/h2&gt;

&lt;p&gt;KCP的实现中，把两个部分留给应用层来做：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;具体收发数据的流程，通过将&lt;code&gt;ikcp_setoutput&lt;/code&gt;函数留给应用层注册来进行数据发送，KCP自己并不负责这一块。&lt;/li&gt;
&lt;li&gt;何时驱动KCP进行数据的收发，即KCP内部并没有实现一个定时器，定期检查条件来触发收发流程，而是提供了&lt;code&gt;ikcp_update&lt;/code&gt;函数给应用层，通过该函数来驱动KCP协议栈的运作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除此以外，KCP提供另外几个函数的作用如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ikcp_input：当应用层接收到数据时，通过该函数通知KCP协议栈对接收到的数据进行解析，最终会生成报文存储到前面提到的接收队列&lt;code&gt;rcv_queue&lt;/code&gt;中。&lt;/li&gt;
&lt;li&gt;ikcp_recv：上一步调用&lt;code&gt;ikcp_input&lt;/code&gt;函数完成对接收到的报文的解析之后，&lt;code&gt;ikcp_recv&lt;/code&gt;函数将解析完成的报文重新拼装到buffer中返回给用户层。&lt;/li&gt;
&lt;li&gt;ikcp_send：用户层发送数据，最终会将待发送的数据编码成一个个的KCP报文存入&lt;code&gt;snd_queue&lt;/code&gt;中。&lt;/li&gt;
&lt;li&gt;ikcp_update：用户层调用该函数，来驱动KCP协议栈进行具体的协议收发、拥塞控制等流程，这些流程实际最终由函数&lt;code&gt;ikcp_flush&lt;/code&gt;完成，但是用户层并不会直接调用这个函数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;整个流程中涉及到的函数及流程如下图：&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://www.codedump.info/media/imgs/20201105-kcp/ikcp.png&#34; alt=&#34;ikcp&#34; title=&#34;ikcp&#34; /&gt;
&lt;/center&gt;
（出自：&lt;a href=&#34;https://blog.csdn.net/yongkai0214/article/details/85156452&#34;&gt;KCP 协议与源码分析（一）_老雍的博客-CSDN博客_kcp&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;在这里先对上图做简单的解释，下面再展开详细的分析：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;图中中轴的函数是&lt;code&gt;ikcp_create&lt;/code&gt;，负责创建kcp协议栈结构体指针；而真正需要发送数据时，需要用户层自己调用&lt;code&gt;ikcp_update&lt;/code&gt;函数驱动kcp协议栈工作。&lt;/li&gt;
&lt;li&gt;图的左边是用户层与协议栈的交互。用户调用&lt;code&gt;ikcp_send&lt;/code&gt;函数，将用户缓冲区的数据，根据KCP协议拼装成报文放到发送队列&lt;code&gt;snd_queue&lt;/code&gt;中。而当用户需要从协议栈接收数据时，会调用&lt;code&gt;ikcp_recv&lt;/code&gt;函数，该函数会将在接收队列&lt;code&gt;recv_queue&lt;/code&gt;中的报文反序列化成用户层缓冲数据，返回给应用层。&lt;/li&gt;
&lt;li&gt;图的右边是协议栈与网络之间的交互。首先&lt;code&gt;ikcp_flush&lt;/code&gt;函数，会将发送队列&lt;code&gt;snd_queue&lt;/code&gt;中的报文移动到发送缓冲区中，最终调用用户通过&lt;code&gt;ikcp_output&lt;/code&gt;函数注册发送函数发送出去；同时，当收到网络层的数据时，会调用&lt;code&gt;ikcp_input&lt;/code&gt;函数将这些数据以kcp协议的形式解析出来，放入到接收缓冲区&lt;code&gt;snd_buf&lt;/code&gt;中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下对其中的核心流程做分析。&lt;/p&gt;

&lt;h1 id=&#34;ikcp-input函数&#34;&gt;ikcp_input函数&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;ikcp_input&lt;/code&gt;函数是用户层接收到数据时调用的第一个函数，其传入的参数是收到数据的缓冲区。因为用户层接收到的数据，都没有经过KCP协议的解析，所以首先调用&lt;code&gt;ikcp_input&lt;/code&gt;函数进行协议解析。又由于一个报文中可能存在多个KCP协议包，所以会遍历这个用户层数据缓冲区进行多次的KCP协议解析。KCP协议，按照其包头中带的指令类型，可能有以下几种：&lt;/p&gt;

&lt;h2 id=&#34;ikcp-cmd-ack&#34;&gt;IKCP_CMD_ACK&lt;/h2&gt;

&lt;p&gt;对端应答ack报。处理流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用&lt;code&gt;ikcp_update_ack&lt;/code&gt;函数更新RTT估算值。&lt;/li&gt;
&lt;li&gt;由于收到了对端的ack，所以调用&lt;code&gt;ikcp_parse_ack&lt;/code&gt;函数，遍历当前的发送缓冲区&lt;code&gt;snd_buf&lt;/code&gt;删除对应该应答序列号的报文，因为该报文对端已经应答收到了，不需要再重发了。&lt;/li&gt;
&lt;li&gt;调用&lt;code&gt;ikcp_shrink_buf&lt;/code&gt;函数更新&lt;code&gt;snd_una&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;快速重传逻辑的处理，这部分在函数&lt;code&gt;ikcp_parse_fastack&lt;/code&gt;中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;ikcp_update_ack&lt;/code&gt;函数用于更新RTT相关的估算值，包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;rx_rttval：rtt平均值，为最近4次rtt的平均值。&lt;/li&gt;
&lt;li&gt;rx_srtt：ack接收rtt平滑值为最近8次的平均值。&lt;/li&gt;
&lt;li&gt;rx_minrto：最小RTO，系统启动时配置，在nodelay的情况下值为&lt;code&gt;IKCP_RTO_NDL&lt;/code&gt;，否则就是&lt;code&gt;IKCP_RTO_MIN&lt;/code&gt;。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;rx_rto：估算出来的rto值，为平滑值+max（interval，平均值），在[rx_minrto,IKCP_RTO_MAX]之间。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;static void ikcp_update_ack(ikcpcb *kcp, IINT32 rtt)
{
	IINT32 rto = 0;
	if (kcp-&amp;gt;rx_srtt == 0) { // 当前没有rtt加权平均值
		// 以这次RTT值来设置
		kcp-&amp;gt;rx_srtt = rtt;
		// 平均值要除以2
		kcp-&amp;gt;rx_rttval = rtt / 2;
	}	else {
		// 计算两者之差
		long delta = rtt - kcp-&amp;gt;rx_srtt;
		if (delta &amp;lt; 0) delta = -delta;
		// 算平均值，可以看到平均值是最近4次的平均
		kcp-&amp;gt;rx_rttval = (3 * kcp-&amp;gt;rx_rttval + delta) / 4;
		// 算加权值，加权值是最近8次加权值的平均
		kcp-&amp;gt;rx_srtt = (7 * kcp-&amp;gt;rx_srtt + rtt) / 8;
		// 不能小于1
		if (kcp-&amp;gt;rx_srtt &amp;lt; 1) kcp-&amp;gt;rx_srtt = 1;
	}
	// 计算RTO值：平滑值+max（interval，平均值）
	rto = kcp-&amp;gt;rx_srtt + _imax_(kcp-&amp;gt;interval, 4 * kcp-&amp;gt;rx_rttval);
	// 最终在[rx_minrto,IKCP_RTO_MAX]之间
	kcp-&amp;gt;rx_rto = _ibound_(kcp-&amp;gt;rx_minrto, rto, IKCP_RTO_MAX);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可见，以上流程最终要算出来当前KCP协议栈的&lt;code&gt;rx_rto&lt;/code&gt;，这个值最终会影响每个报文的超时发送时间，这在后面的发送流程中再解释。&lt;/p&gt;

&lt;p&gt;另外还需要专门聊一下&lt;code&gt;ikcp_parse_fastack&lt;/code&gt;函数，以及快速重传的处理。快速重传的原理是这样的：假设当前有序列号&lt;code&gt;[1,2,3]&lt;/code&gt;的报文等待对端应答，当KCP协议栈收到报文2的ack时，知道报文1被跳过1次了；同样的，当收到报文3的ack时，报文1又被跳过1次。&lt;/p&gt;

&lt;p&gt;这里的“跳过次数”就存储在&lt;code&gt;IKCPSEG.fastack&lt;/code&gt;成员中，KCP协议栈提供&lt;code&gt;ikcp_nodelay&lt;/code&gt;函数可以配置快速重传值&lt;code&gt;resend&lt;/code&gt;，当报文的跳过次数超过&lt;code&gt;resend&lt;/code&gt;时，就马上重传该报文，不会等待报文超时，一定程度上加速报文的重传降低了延迟。&lt;/p&gt;

&lt;h2 id=&#34;ikcp-cmd-push&#34;&gt;IKCP_CMD_PUSH&lt;/h2&gt;

&lt;p&gt;传送数据的指令，此时解析最终会进入&lt;code&gt;ikcp_parse_data&lt;/code&gt;函数中，该函数流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先会通过报文序列号判断是否在当前接收窗口以内（&lt;code&gt;_itimediff(sn, kcp-&amp;gt;rcv_nxt + kcp-&amp;gt;rcv_wnd) &amp;gt;= 0&lt;/code&gt;），或者已经接收过了（&lt;code&gt;_itimediff(sn, kcp-&amp;gt;rcv_nxt) &amp;lt; 0&lt;/code&gt;），这两种情况都删除报文返回，不做进一步处理。&lt;/li&gt;
&lt;li&gt;根据报文序列号在&lt;code&gt;rcv_buf&lt;/code&gt;判断当前接收缓冲区中是否已经存在同序列号的报文，如果已经存在说明是重复接收的，也删除报文不再处理。&lt;/li&gt;
&lt;li&gt;以上两步都通过了，说明是首次接收该序列号的报文，将把该报文放入接收缓冲区&lt;code&gt;rcv_buf&lt;/code&gt;中。&lt;/li&gt;
&lt;li&gt;由于&lt;code&gt;rcv_queue&lt;/code&gt;中的报文才是最终面向用户层的，而上面的操作可能让&lt;code&gt;rcv_buf&lt;/code&gt;接收缓冲区非空存在新的报文了，所以接下来将&lt;code&gt;rcv_buf&lt;/code&gt;中的报文移动到&lt;code&gt;rcv_queue&lt;/code&gt;中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ikcp-cmd-wask&#34;&gt;IKCP_CMD_WASK&lt;/h2&gt;

&lt;p&gt;对端请求探测窗口大小，此时会把探测标志位加上&lt;code&gt;IKCP_ASK_TELL&lt;/code&gt;，下一次发送数据时带上窗口大小通知对端。&lt;/p&gt;

&lt;h2 id=&#34;ikcp-cmd-wins&#34;&gt;IKCP_CMD_WINS&lt;/h2&gt;

&lt;p&gt;通知窗口大小。&lt;/p&gt;

&lt;h2 id=&#34;快速应答处理&#34;&gt;快速应答处理&lt;/h2&gt;

&lt;h2 id=&#34;更新参数&#34;&gt;更新参数&lt;/h2&gt;

&lt;p&gt;前面的处理完毕之后，可能会收到新的ack报文，这时就需要更新KCP协议栈的拥塞窗口大小。&lt;/p&gt;

&lt;p&gt;如果当前拥塞窗口大小小于对端的窗口大小（&lt;code&gt;kcp-&amp;gt;cwnd &amp;lt; kcp-&amp;gt;rmt_wnd&lt;/code&gt;），那么需要增加拥塞窗口大小，区分两种情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果拥塞窗口大小小于慢启动阈值（&lt;code&gt;kcp-&amp;gt;cwnd &amp;lt; kcp-&amp;gt;ssthresh&lt;/code&gt;）：递增拥塞窗口大小。&lt;/li&gt;
&lt;li&gt;否则：

&lt;ul&gt;
&lt;li&gt;拥塞窗口增量递增1/16；&lt;/li&gt;
&lt;li&gt;如果当前拥塞窗口递增后小于增量的情况下才递增。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;最后，拥塞窗口不能超过对端窗口大小。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;	// 前面处理完毕之后，最新的una更大，说明接收到了新的ack
	if (_itimediff(kcp-&amp;gt;snd_una, prev_una) &amp;gt; 0) {
		if (kcp-&amp;gt;cwnd &amp;lt; kcp-&amp;gt;rmt_wnd) {	// 拥塞窗口小于对端窗口
			IUINT32 mss = kcp-&amp;gt;mss;
			if (kcp-&amp;gt;cwnd &amp;lt; kcp-&amp;gt;ssthresh) { // 拥塞窗口小于慢启动阈值
				kcp-&amp;gt;cwnd++;	// 递增拥塞窗口
				kcp-&amp;gt;incr += mss;	// 递增mss
			}	else { // 拥塞窗口大于等于慢启动阈值
				// 不能小于mss了
				if (kcp-&amp;gt;incr &amp;lt; mss) kcp-&amp;gt;incr = mss;
				// 增加 mss + 1/16 mss
				kcp-&amp;gt;incr += (mss * mss) / kcp-&amp;gt;incr + (mss / 16);
				// 只有在拥塞窗口递增后不超过incr的情况下才允许加一
				if ((kcp-&amp;gt;cwnd + 1) * mss &amp;lt;= kcp-&amp;gt;incr) {
					kcp-&amp;gt;cwnd++;
				}
			}
			if (kcp-&amp;gt;cwnd &amp;gt; kcp-&amp;gt;rmt_wnd) { // 拥塞窗口不能比对端窗口大
				kcp-&amp;gt;cwnd = kcp-&amp;gt;rmt_wnd;
				kcp-&amp;gt;incr = kcp-&amp;gt;rmt_wnd * mss;
			}
		}
	}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;ikcp-recv函数&#34;&gt;ikcp_recv函数&lt;/h1&gt;

&lt;p&gt;前面的&lt;code&gt;ikcp_input&lt;/code&gt;解析完毕之后，将用户缓冲区的数据解析到一个一个的报文放到了接收队列&lt;code&gt;rcv_queue&lt;/code&gt;中，&lt;code&gt;ikcp_recv&lt;/code&gt;函数就负责将这些报文重新组装起来放入用户缓冲区返回给用户层。&lt;/p&gt;

&lt;p&gt;之所以这里还需要“组装”，是因为对端发送的数据由于超过MTU所以被KCP协议栈分成多个报文发送了。所以这里需要兼容多个分片的情况，如果待接收报文的所有分片没有接收完毕，那么不能处理。接收完毕或者不分片的情况下，就遍历这些报文将数据拷贝到缓冲区中。&lt;/p&gt;

&lt;p&gt;上面的步骤完成之后，如果接收缓冲区&lt;code&gt;rcv_buf&lt;/code&gt;还有报文，那么依然是把这部分报文移动到接收队列中，等待下一次&lt;code&gt;ikcp_recv&lt;/code&gt;调用。&lt;/p&gt;

&lt;h1 id=&#34;ikcp-send&#34;&gt;ikcp_send&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;ikcp_send&lt;/code&gt;函数是用户层发送数据的接口，最终会将用户传入的缓冲区数据，组装成KCP报文，放入发送队列&lt;code&gt;snd_queue&lt;/code&gt;中。&lt;/p&gt;

&lt;p&gt;这里需要注意两种情况。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果是流模式，那么首先KCP会取出发送队列当前的最后报文的结构体，如果当前报文还有空间就将部分数据拷贝过去。&lt;/li&gt;
&lt;li&gt;如果数据超过MSS大小，那么需要对数据分片，即将数据分为多个KCP报文发送。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;ikcp-update和ikcp-flush&#34;&gt;ikcp_update和ikcp_flush&lt;/h1&gt;

&lt;p&gt;前面的&lt;code&gt;ikcp_send&lt;/code&gt;只是将待发送数据组装成KCP报文放到发送队列中了，具体的发送流程由调用&lt;code&gt;ikcp_update&lt;/code&gt;函数来驱动完成的。&lt;/p&gt;

&lt;p&gt;KCP协议栈中，并没有任何的自定义定时器，即自己并不会主动来根据时间驱动来完成工作，这部分都留给了用户层，由用户层主动调用&lt;code&gt;ikcp_update&lt;/code&gt;来完成这些工作。&lt;code&gt;ikcp_update&lt;/code&gt;函数的处理其实很简单，会判断上一次刷新（flush）时间与这次的间隔，来判断是否调用&lt;code&gt;ikcp_flush&lt;/code&gt;函数来完成工作，所以这里真正工作的是&lt;code&gt;ikcp_flush&lt;/code&gt;函数，下面就来重点分析这个函数的实现。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ikcp_flush&lt;/code&gt;函数本质就是根据当前的情况，封装KCP报文，将这些报文放到发送缓冲区&lt;code&gt;snd_buf&lt;/code&gt;中，发送到对端。除此之外，还需要重新计算流控、拥塞窗口等参数。总体来看，需要完成以下的工作：&lt;/p&gt;

&lt;h2 id=&#34;处理ack应答&#34;&gt;处理ACK应答&lt;/h2&gt;

&lt;p&gt;首先，&lt;code&gt;ikcp_flush&lt;/code&gt;函数将编码&lt;code&gt;IKCP_CMD_ACK&lt;/code&gt;类型的指令，应答收到了对端那些报文。&lt;/p&gt;

&lt;h2 id=&#34;探测对端窗口&#34;&gt;探测对端窗口&lt;/h2&gt;

&lt;p&gt;在对端通知窗口为0（即&lt;code&gt;kcp-&amp;gt;rmt_wnd == 0&lt;/code&gt;）情况下，需要探测对端当前窗口大小，即需要发送&lt;code&gt;IKCP_ASK_SEND&lt;/code&gt;类型的报文。&lt;/p&gt;

&lt;p&gt;在这里，涉及到KCP协议栈&lt;code&gt;ikcpcb&lt;/code&gt;结构体的几个参数：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;probe_wait：存储下一次探测窗口的时间间隔，该参数的初始值为&lt;code&gt;IKCP_PROBE_INIT&lt;/code&gt;，每次新的探测间隔时间将在当前基础上递增当前的1/2，但是最高不超过&lt;code&gt;IKCP_PROBE_LIMIT&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;ts_probe：存储下一次探测时间，不难知道这个值每次都是根据当前时间加上&lt;code&gt;probe_wait&lt;/code&gt;计算出来的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在当前时间超过&lt;code&gt;ts_probe&lt;/code&gt;（即&lt;code&gt;_itimediff(kcp-&amp;gt;current, kcp-&amp;gt;ts_probe) &amp;gt;= 0&lt;/code&gt;）的情况下，&lt;code&gt;probe&lt;/code&gt;探测标志位就要加上&lt;code&gt;IKCP_ASK_SEND&lt;/code&gt;，表示需要给对端发送探测窗口的报文了。&lt;/p&gt;

&lt;h2 id=&#34;流控&#34;&gt;流控&lt;/h2&gt;

&lt;p&gt;以上已经处理了&lt;code&gt;IKCP_CMD_ACK&lt;/code&gt;、&lt;code&gt;IKCP_ASK_SEND&lt;/code&gt;、&lt;code&gt;IKCP_ASK_TELL&lt;/code&gt;这三个类型的指令了，接下来就是处理&lt;code&gt;IKCP_CMD_PUSH&lt;/code&gt;类型的数据了，这部分数据都已经在前面的&lt;code&gt;ikcp_send&lt;/code&gt;由用户层传入的缓冲区解析拼装到发送队列&lt;code&gt;snd_queue&lt;/code&gt;中了。&lt;/p&gt;

&lt;p&gt;接下来，就可以遍历发送队列&lt;code&gt;snd_queue&lt;/code&gt;中的报文移动到发送队列&lt;code&gt;snd_buf&lt;/code&gt;中，进行实际的报文发送了。&lt;/p&gt;

&lt;p&gt;但是，并不是所有当前在发送队列中的报文都能在一次flush过程被发送出去，要考虑三个窗口的大小：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先不能超过发送窗口（snd_wnd）和对端窗口（rmt_wnd）的大小。&lt;/li&gt;
&lt;li&gt;在开启流控（kcp-&amp;gt;nocwnd == 0）的情况下，还不能超过当前流控窗口（cwnd）的大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前面的流程算出来发送时的窗口大小，接下来就按照这个窗口大小将&lt;code&gt;snd_queue&lt;/code&gt;的报文取下来放入&lt;code&gt;snd_buf&lt;/code&gt;中了。&lt;/p&gt;

&lt;h2 id=&#34;发送数据&#34;&gt;发送数据&lt;/h2&gt;

&lt;p&gt;以上已经根据流控窗口选出了待发送的报文放在发送缓冲区&lt;code&gt;snd_buf&lt;/code&gt;里了，接下来就是具体的发送流程了。&lt;/p&gt;

&lt;p&gt;针对每个报文，在发送之前要计算它的几个参数：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;xmit：发送次数，每发送一次该计数递增，如果一个报文的发送次数超过了&lt;code&gt;dead_link&lt;/code&gt;，那么认为网络已经断了不再尝试发送。&lt;/li&gt;
&lt;li&gt;rto：用来计算重传超时时间的，初始值就是KCP协议栈当前估算出来的RTO值，在发生重传的情况下这个值会增加：

&lt;ul&gt;
&lt;li&gt;在非急速模式下，每次递增的值也是KCP协议栈估算出来的RTO值。（&lt;code&gt;segment-&amp;gt;rto += kcp-&amp;gt;rx_rto;&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;急速模式下，每次递增的值也是KCP协议栈估算出来的RTO值的二分之一。（&lt;code&gt;segment-&amp;gt;rto += kcp-&amp;gt;rx_rto / 2&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;resendts：根据当前时间加上rto时间计算出来的下次重传时间。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;来看看发送报文需要考虑的几种情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首次发送（&lt;code&gt;segment-&amp;gt;xmit == 0&lt;/code&gt;）：设置&lt;code&gt;xmit&lt;/code&gt;为1，&lt;code&gt;rto&lt;/code&gt;为&lt;code&gt;kcp-&amp;gt;rx_rto&lt;/code&gt;，以及重传时间为当前时间加上rto（&lt;code&gt;segment-&amp;gt;resendts = current + segment-&amp;gt;rto + rtomin&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;因为超时发生的重传（&lt;code&gt;_itimediff(current, segment-&amp;gt;resendts) &amp;gt;= 0&lt;/code&gt;）：递增&lt;code&gt;xmit&lt;/code&gt;计数值，增加&lt;code&gt;rto&lt;/code&gt;时间，以及更新下次重传时间&lt;code&gt;resendts&lt;/code&gt;，并且标记发生了丢包（&lt;code&gt;lost=1&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;快速重传（&lt;code&gt;segment-&amp;gt;fastack &amp;gt;= resent&lt;/code&gt;）：前面已经分析过快速重传参数&lt;code&gt;fastack&lt;/code&gt;的作用，这里就不再阐述了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过以上分析，可以知道除了第一种情况是正常发送之外，还发生了超时重传以及快速重传，根据这些情况，需要更新一下KCP协议栈的参数。&lt;/p&gt;

&lt;h2 id=&#34;更新参数-1&#34;&gt;更新参数&lt;/h2&gt;

&lt;p&gt;分以下两种情况处理：&lt;/p&gt;

&lt;h3 id=&#34;快速重传&#34;&gt;快速重传&lt;/h3&gt;

&lt;p&gt;在发生快速重传的情况下，会挑战ssthresh为当前发送窗口的一半大小，同时拥塞窗口为&lt;code&gt;ssthresh + resent&lt;/code&gt;大小：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	if (change) { // 发生了快速重传，计算新的ssthresh
		// 如果发生了快速重传，拥塞窗口阈值降低为当前未确认包数量的一半或最小值  
		// 当前发送窗口大小
		IUINT32 inflight = kcp-&amp;gt;snd_nxt - kcp-&amp;gt;snd_una;
		// ssthresh为当前窗口大小的一半
		kcp-&amp;gt;ssthresh = inflight / 2;
		// 不能小于IKCP_THRESH_MIN
		if (kcp-&amp;gt;ssthresh &amp;lt; IKCP_THRESH_MIN)
			kcp-&amp;gt;ssthresh = IKCP_THRESH_MIN;
		kcp-&amp;gt;cwnd = kcp-&amp;gt;ssthresh + resent;
		kcp-&amp;gt;incr = kcp-&amp;gt;cwnd * kcp-&amp;gt;mss;
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;超时丢包&#34;&gt;超时丢包&lt;/h3&gt;

&lt;p&gt;在发生超时丢包的情况下，慢启动阈值调整为旧的拥塞窗口的一半，但是不能小于&lt;code&gt;IKCP_THRESH_MIN&lt;/code&gt;，而新的拥塞窗口值变成1：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	if (lost) { // 发生了丢包
		// 丢失则阈值减半, cwd 窗口保留为 1  
		kcp-&amp;gt;ssthresh = cwnd / 2;
		if (kcp-&amp;gt;ssthresh &amp;lt; IKCP_THRESH_MIN)
			kcp-&amp;gt;ssthresh = IKCP_THRESH_MIN;
		kcp-&amp;gt;cwnd = 1;
		kcp-&amp;gt;incr = kcp-&amp;gt;mss;
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://kaiyuan.me/2017/07/29/KCP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/&#34;&gt;KCP: 快速可靠的ARQ协议 - Kaiyuan&amp;rsquo;s Blog | May the force be with me&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>