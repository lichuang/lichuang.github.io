<!DOCTYPE html>
<html lang="zh"
  dir="ltr">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">



<link rel="icon" type="image/ico" href="http://localhost:1313//favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313//favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313//favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="http://localhost:1313//android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313//apple-touch-icon.png">

<meta name="description" content="Memcached的存储原理解析（续）"/>



<title>
    
    Memcached的存储原理解析（续） | codedump notes
    
</title>

<link rel="canonical" href="http://localhost:1313/post/20210812-memcached/"/>

<meta property="og:url" content="http://localhost:1313/post/20210812-memcached/">
  <meta property="og:site_name" content="codedump notes">
  <meta property="og:title" content="Memcached的存储原理解析（续）">
  <meta property="og:description" content="Memcached的存储原理解析（续）">
  <meta property="og:locale" content="zh">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2021-08-12T08:40:04+08:00">
    <meta property="article:modified_time" content="2021-08-12T08:40:04+08:00">
    <meta property="article:tag" content="存储">













<link rel="stylesheet" href="/assets/combined.min.1356e1c8842105762b945263595323c16a5ce093eb9455a22e7910868b90a5c5.css" media="all">





</head>







<body class="typo">

  <div class="content">
    <header>
      

<div class="header">

    

    <h1 class="header-title">
        <a href="http://localhost:1313/">codedump notes</a>
    </h1>

    <div class="flex">
        

        
        
      
        <p class="small ">
            <a href="/" >
                /home
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/zh" >
                /中文
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/en" >
                /en
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/tags" >
                /tags
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/page/about" >
                /about
            </a>
        </p>
        
        
    </div>

    

</div>

    </header>

    <main class="main">
      




<div class="breadcrumbs"><a href="/">Home</a><span class="breadcrumbs-separator">/</span><a href="/post/">Posts</a><span class="breadcrumbs-separator">/</span>
        <a href="/post/20210812-memcached/">Memcached的存储原理解析（续）</a></div>


<div >

  <div class="single-intro-container">

    

    <h1 class="single-title">Memcached的存储原理解析（续）</h1>
    

    

    <p class="single-readtime">
      
      
      
      <time datetime="2021-08-12T08:40:04&#43;08:00">2021年8月12日</time>
      

      
    </p>

  </div>

  

  

  

  

  <div class="single-content">
    <h1 class="heading" id="概述">
  概述
  <a class="anchor" href="#%e6%a6%82%e8%bf%b0">#</a>
</h1>
<p>在前面的<a href="https://www.codedump.info/post/20210701-memcached/">Memcached的存储原理解析</a>一文中，简单分析了memcached的存储原理，但是最近在照搬memcached的实现原理到项目中时，发现前面的梳理还不够细致，有一些细节没有谈及，因此重新整理一篇文章。</p>
<h1 class="heading" id="slab">
  slab
  <a class="anchor" href="#slab">#</a>
</h1>
<p>memcached是根据slab为基础单位来管理空闲空间的。slab的大体原理如下图：</p>
<p>











<figure class="">

    <div>
        <img loading="lazy" alt="slabclass的分级存储" src="/media/imgs/20210812-memcached/slabclass.png" >
    </div>

    
    <div class="caption-container">
        <figcaption> slabclass的分级存储 </figcaption>
    </div>
    
</figure>
</p>
<p>slabs.c中定义了类型为<code>slabclass_t</code>、大小为<code>MAX_NUMBER_OF_SLAB_CLASSES</code>的数组<code>slabclass</code>，用于分级存储。</p>
<p>数组中的每个<code>slabclass_t</code>元素，其能分配出去的内存大小递增，由如下的规则决定：</p>
<ul>
<li>每个数组可分配的内存大小都要8字节对齐（<code>CHUNK_ALIGN_BYTES</code>）,这个大小保存在<code>slabclass_t</code>的<code>size</code>成员中。</li>
<li>数组的第一个<code>slabclass_t</code>元素的可分配内存大小为<code>sizeof(item) + settings.chunk_size</code>。这之后的<code>slabclass_t</code>可分配内存大小，都在上一个的元素的基础上放大<code>factor</code>倍，同时还要8字节对齐。</li>
<li>每次分配一个页面的大小由配置项<code>settings.slab_page_size</code>来决定，因此每一个<code>slabclass_t</code>元素的一个页面能容纳的<code>item</code>数量为<code>settings.slab_page_size / slabclass[i].size</code>。</li>
</ul>
<p>以上图为例，假设第一级存储的item大小不超过56字节，每个slab之间的增长因子是1.2，那么下一个slab存储的item内存大小就是56*1.2=72字节。</p>
<p>在当前还有空闲可用内存的情况下，每一次分配新的空间，都是以page（page=1MB）为单位的，然后再根据该slab的item大小划分为多个空闲可用item。</p>
<p><code>slabclass_t</code>类型中最重要的是以下两个成员：</p>
<ul>
<li>slab_list：保存已经分配出去的page数组，分配一个page的内存之后，需要将page根据该slab的size划分成多个空闲的item，挂载到下面提到的slots链表中。当最后需要回收分配出去的内存时，直接遍历slab_list中的成员回收内存即可。</li>
<li>slots：保存空闲item链表。空闲item来源有两部分，一部分是从page中分配但是还未使用的item，还有一部分是曾经被使用后来释放回来的item，上图中使用了不同的颜色进行了区分。</li>
</ul>
<p>当需要分配一块大小的内存时，首先需要根据其大小，计算出该尺寸最终对应到上面的哪个元素，这个数组索引在Memcached中被称为<code>clsid</code>，这个计算索引的过程参见函数<code>slabs_clsid</code>。</p>
<p>比如：</p>
<ul>
<li>slabclass[0].size = 56，fator参数为1.2，那么slabclass[1].size = (56 * 1.25)向上对齐8位 = 72，以此类推。</li>
<li>假设需要分配的内存大小为60，就会去找<code>slabclass_t.size &gt;= 60</code>的第一个slabclass，在这个例子中返回的<code>clsid</code>是1，也就是<code>slabclass[1]</code>。</li>
<li>内存分配时根据大小向上取满足条件的第一个slab的做法，优点在于方便了内存的分配管理，缺陷是会浪费掉部分空间，比如上面的例子中，将大小为72的slab用于60的内存，那么12字节的空间就被浪费掉了。</li>
</ul>
<p>从上面可以看到，<code>slabclass_t</code>用于管理空闲内存，当需要分配新item时，会依次做如下的检查：</p>
<ul>
<li>如果<code>slots</code>链表中还有空闲item，直接摘下来使用；</li>
<li>否则，如果当前还没有达到内存分配的阈值，就分配一个新的page出来，将page按照该slab的大小划分为多个item，这些新分配出来的item都挂载到<code>slots</code>链表中。</li>
<li>如果以上两步都不满足了，说明当前已经没有可用的内存和空闲item，需要进行淘汰了。</li>
</ul>
<p>讲到item的淘汰，就涉及到下面的LRU算法了。</p>
<h1 class="heading" id="lru算法">
  LRU算法
  <a class="anchor" href="#lru%e7%ae%97%e6%b3%95">#</a>
</h1>
<h2 class="heading" id="旧的lru算法及其问题">
  旧的LRU算法及其问题
  <a class="anchor" href="#%e6%97%a7%e7%9a%84lru%e7%ae%97%e6%b3%95%e5%8f%8a%e5%85%b6%e9%97%ae%e9%a2%98">#</a>
</h2>
<p>以往的LRU算法，基本做法都是这样的：</p>
<ul>
<li>创建一个LRU链表，每次新加入的元素都放在链表头。</li>
<li>如果元素被访问了一次，同样从当前链表中摘除放到链表头。</li>
<li>需要淘汰元素时，从链表尾开始找可以淘汰的元素出来淘汰。</li>
</ul>
<p>这个算法有如下几个问题：</p>
<ul>
<li>元素被访问一次就会被放到LRU链表的头部，这样即便这个元素可以被淘汰，也会需要很久才会淘汰掉这个元素。</li>
<li>由于上面的原因，从链表尾部开始找可以淘汰的元素时，实际可能访问到的是一些虽然不常被访问，但是还没到淘汰时间（即有效时间TTL还未过期）的数据，这样会一直沿着链表往前找很久才能找到适合淘汰的元素。由于这个查找被淘汰元素的过程是需要加锁保护的，加锁时间一长影响了系统的并发。</li>
</ul>
<p>











<figure class="">

    <div>
        <img loading="lazy" alt="经典的LRU链表实现" src="/media/imgs/20210701-memcached/old-lru-list.png" >
    </div>

    
    <div class="caption-container">
        <figcaption> 经典的LRU链表实现 </figcaption>
    </div>
    
</figure>
</p>
<p>综上，经典的LRU链表问题的核心在于：</p>
<ul>
<li>只需要一次被访问就能让元素远离被淘汰的地方。</li>
<li>以及如何高效定位到更可能被淘汰的元素。</li>
</ul>
<p>从Memcached 1.5版本开始，引入了所谓的分段LRU算法（Segmented LRU）来解决这些问题。</p>
<h2 class="heading" id="改进的分段lru算法segmented-lru">
  改进的分段LRU算法（Segmented LRU）
  <a class="anchor" href="#%e6%94%b9%e8%bf%9b%e7%9a%84%e5%88%86%e6%ae%b5lru%e7%ae%97%e6%b3%95segmented-lru">#</a>
</h2>
<p>分段LRU算法中将LRU链表根据<code>活跃度</code>分成了三类：</p>
<ul>
<li>HOT_LRU：存储热数据的LRU链表。</li>
<li>WARM_LRU：存储温数据（即活跃度不如热数据）的LRU链表。</li>
<li>COLD_LRU：存储冷数据的LRU链表。</li>
</ul>
<p>需要说明的是：热（参数<code>settings.hot_lru_pct</code>）和暖（参数<code>settings.warm_lru_pct</code>）数据的占总体内存的比例有限制，而冷数据则无限。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C" data-lang="C"><span style="display:flex;"><span><span style="color:#888;font-weight:bold">#define HOT_LRU 0
</span></span></span><span style="display:flex;"><span><span style="color:#888;font-weight:bold">#define WARM_LRU 64
</span></span></span><span style="display:flex;"><span><span style="color:#888;font-weight:bold">#define COLD_LRU 128
</span></span></span></code></pre></div><p>同时，使用了<code>heads</code>和<code>tails</code>两个数组用来保存LRU链表：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C" data-lang="C"><span style="display:flex;"><span><span style="color:#888;font-weight:bold">#define POWER_LARGEST  256 </span><span style="color:#888;font-style:italic">/* actual cap is 255 */</span><span style="color:#888;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#888;font-weight:bold"></span>
</span></span><span style="display:flex;"><span><span style="color:#888;font-weight:bold">#define LARGEST_ID POWER_LARGEST
</span></span></span><span style="display:flex;"><span><span style="color:#888;font-weight:bold"></span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">static</span> item *heads[LARGEST_ID];
</span></span><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">static</span> item *tails[LARGEST_ID];
</span></span></code></pre></div><p>上面分析<code>slabclass</code>的时候提到过，首先会根据被分配内存大小计算出来一个<code>slabclass</code>数组的索引。在需要从LRU链表中淘汰数据时，由于LRU链表分为了上面三类，那么就还需要再进行一次<code>slabid | lru id</code>计算（其实就是<code>slabid + lru id</code>），到对应的LRU链表中查找元素：</p>
<p>











<figure class="">

    <div>
        <img loading="lazy" alt="将slabclass数组索引映射到LRU队列数组" src="/media/imgs/20210701-memcached/slabclass-lru.png" >
    </div>

    
    <div class="caption-container">
        <figcaption> 将slabclass数组索引映射到LRU队列数组 </figcaption>
    </div>
    
</figure>
</p>
<p>有了这三种LRU队列的初步印象，可以接下来解释这个分段LRU算法了。</p>
<p>前面提到，原有LRU算法最大的问题是：只要元素被访问过一次，就马上会被移动到LRU链表的前面，影响了后面对这个元素的淘汰。</p>
<p>首先，改进的算法中，加入了一个机制：只有当元素被访问两次以后，才会标记成<code>活跃</code>元素。</p>
<p>代码中引入了两个标志位，其置位的规则如下：</p>
<ul>
<li>ITEM_FETCHED：第一次被访问时置位该标志位。</li>
<li>ITEM_ACTIVE：第二次被访问时（即<code>it-&gt;it_flags &amp; ITEM_FETCHED</code>为true的情况下）置位该标志位。</li>
<li>INACTIVE：不活跃状态。</li>
</ul>
<p>ITEM_ACTIVE标志位清除的规则如下：</p>
<ul>
<li>如果从链表尾遍历到某一个LRU链表时，该元素是链表的最后一个元素，则认为是不活跃的元素，即可以清除ITEM_ACTIVE标志位；</li>
</ul>
<p>这样，有效避免了只访问一次就变成<code>活跃</code>元素的问题（见函数<code>do_item_bump</code>）。</p>
<p>以下的讨论中，元素变成<code>活跃</code>就意指“至少被访问两次以上”。</p>
<p>其次，由于从链表尾部往前查找可以淘汰的元素，中间可能会经历很多不能被淘汰的元素，影响了淘汰的速度，因此前面的分级LRU链表就能帮助程序快速识别出哪些元素可以被淘汰。三个分级的LRU链表之间的转换规则如下：</p>
<ul>
<li>HOT_LRU：在HOT LRU队列中的数据绝不会到HOT_LRU队列的前面，只会往更冷的队列中放。规则是：如果元素变得活跃，就放到WARM队列中；否则如果不活跃，就直接放到COLD队列中。</li>
<li>WARM_LRU：如果WARM队列的元素变的<code>活跃</code>，就会移动到WARM队列头；否则往COLD队列移动。</li>
<li>COLD_LRU：从上面可知，COLD队列中的元素，都是不太活跃的了，所以当需要淘汰元素时都会首先到COLD LRU队列中找可以淘汰的数据。当一个在COLD队列的元素重新变成<code>活跃</code>元素时，并不会移动到COLD队列的头部，而是直接移动回去WARM队列。</li>
</ul>
<p>以上需要注意的是：任何操作都不能将一个元素从WARM和COLD队列中移动回去HOT队列了，也就是从HOT队列中移动元素出去的操作是单向操作。</p>
<p>上述算法的状态机转换过程，可以参考下图。使用了这些规则来维护着三个队列之后，基本能保证COLD队列中的元素是不活跃的，这样查找起被淘汰元素也更快了。</p>
<p>











<figure class="">

    <div>
        <img loading="lazy" alt="三级LRU队列转换状态图" src="/media/imgs/20210701-memcached/lru.png" >
    </div>

    
    <div class="caption-container">
        <figcaption> 三级LRU队列转换状态图 </figcaption>
    </div>
    
</figure>
</p>
<p>综述起来，改进的分段LRU算法做了如下的优化：</p>
<ul>
<li>需要至少两次被访问，才能变成<code>活跃</code>元素。</li>
<li>将元素按照被访问频率的<code>冷热程度</code>，划分为三种LRU链表来分段管理，加速了查找被淘汰元素的流程。</li>
</ul>
<h1 class="heading" id="读写操作的实现">
  读写操作的实现
  <a class="anchor" href="#%e8%af%bb%e5%86%99%e6%93%8d%e4%bd%9c%e7%9a%84%e5%ae%9e%e7%8e%b0">#</a>
</h1>
<p>从以上的分析里，可以看出memcached中主要有这么几种数据结构：</p>
<ul>
<li>item：存储一个KV数据的基本单位。</li>
<li>slabclass：存储空闲item的数据结构。</li>
<li>lru链表：根据访问的冷热程度存储当前在使用中的item。</li>
<li>hash表：这部分没有在上面描述，用于根据key查询item的数据结构。</li>
</ul>
<p>一个item，必然处于空闲和在使用这两种互斥状态之一，即：</p>
<ul>
<li>空闲的item：保存在slabclass的slots空闲链表中，这一点已经在上面slab的图示中描述过了。</li>
<li>在使用中的item：保存在lru链表中，用于数据回收之用；同时还保存在hash表中，用于数据访问时使用。如下图所示：</li>
</ul>
<p>











<figure class="">

    <div>
        <img loading="lazy" alt="使用中的item数据组织结构" src="/media/imgs/20210812-memcached/in-use-item.png" >
    </div>

    
    <div class="caption-container">
        <figcaption> 使用中的item数据组织结构 </figcaption>
    </div>
    
</figure>
</p>
<p>对item的数据组织有了大体的概念之后，下面展开来说读写操作的具体实现。</p>
<h2 class="heading" id="读操作">
  读操作
  <a class="anchor" href="#%e8%af%bb%e6%93%8d%e4%bd%9c">#</a>
</h2>
<p>由于被使用数据存储在hash表中，所以查询操作相对简单，其伪代码是：</p>
<pre tabindex="0"><code>读操作：
  加锁
    在hash表中查询数据
  释放锁

  返回查询的结果
</code></pre><p>虽然简单，但是其中有一个值得注意的细节。这里的加锁操作，并不是一个全局锁，否则系统的并发性会大大折扣；同时，也不是给hash数组中的某一个hash桶进行加锁，实际上hash表本身并不存在锁操作。</p>
<p>在这里，加的锁是首先根据所查询数据的键进行hash计算，再得到对应的锁，在memcached里被称为“item lock”（见全局变量<code>static pthread_mutex_t *item_locks</code>）。这个锁虽然与数据的键值相关，但是如果hash数组数量与item_locks不相等，那么就不是一一对应的关系，所以才说不是针对hash桶进行加锁。如果hash桶的数量大于item lock的数量，那么这就是一对多的关系，也就是对一个item lock加锁之后，获得锁的线程可以访问多个hash桶。</p>
<p>











<figure class="">

    <div>
        <img loading="lazy" alt="item锁与hash桶的对应关系" src="/media/imgs/20210812-memcached/item-lock.png" >
    </div>

    
    <div class="caption-container">
        <figcaption> item锁与hash桶的对应关系 </figcaption>
    </div>
    
</figure>
</p>
<p>上图中，索引为N的item锁，管理着索引为M、P这两个hash桶，因此拿到该item锁的线程可以同时访问这两个hash桶。</p>
<p>因此，上面的读操作更准确的描述应该是：</p>
<pre tabindex="0"><code>读操作：
  根据查询键值加item锁
    在hash表中查询数据
  根据查询键值释放item锁

  返回查询的结果
</code></pre><h2 class="heading" id="写操作">
  写操作
  <a class="anchor" href="#%e5%86%99%e6%93%8d%e4%bd%9c">#</a>
</h2>
<p>与前面非常简单的读操作相比，写操作会更加复杂，因为当内存不足时需要淘汰在LRU数组中的item。</p>
<pre tabindex="0"><code>写操作：  
  根据查询键值加item锁

    分配足够内存的item，写入新的数据
    向hash表中写入数据

  根据查询键值释放item锁
</code></pre><p>在上面的步骤中，<code>分配足够内存的item</code>这一步，暂不考虑分析内存足够下的情况，因为这种情况相对简单，只分析内存不足时需要淘汰的情况。将这部分代码展开来讨论，则伪代码如下：</p>
<pre tabindex="0"><code>写操作：  
  1:根据查询键值加item锁

    2:内存不足情况下分配足够内存的item，写入新的数据：

      2.1:计算满足所需内存所在的LRU数组元素，对该LRU链表加锁
      2.2:从后往前遍历所要求内存的LRU数组：
        2.2.1:找到一个item，如果尝试对该item的键值进行加锁失败，则继续尝试下一个item
        2.2.3:否则，对该item的键值进行加锁成功，如果符合回收条件：
          2.2.4:从item所在的hash表中删除item
        2.2.5:释放2.2.1中加的item锁
      
      2.3:对该LRU链表解锁

    3:向hash表中写入数据

  4:根据查询键值释放item锁
</code></pre><p>需要注意的是，步骤2.2.1中，是尝试对当前item的键值所在的item锁加锁，这一步是可能失败的，因为在第一步中已经加上了item锁，两者有可能相同，如果这里不是尝试而是直接等待解锁，则可能造成死锁。</p>
<p>但是仅有上面的步骤仍然是不够的，因为即便找到了一个可以被回收的item，也要确定该item没有被其他线程引用，判断的标准是根据item中的引用计数：首先将引用计数加1，如果为2的情况下（使用中的item默认引用计数为1）说明当前只有本线程引用了这个item，后面就可以安全的回收该item。</p>
<p>在memcached代码中，如果上一步增加引用计数之后不为2时，有可能是item泄露了，如果打开tail_repair_time开关且满足时间的情况下，可以进行强制回收，但是作者也提醒了这样可能会造成程序core掉，也就是出现上面提到的被引用的item被释放的情况：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C" data-lang="C"><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">int</span> <span style="color:#666;font-weight:bold;font-style:italic">lru_pull_tail</span>(<span style="font-weight:bold;text-decoration:underline">const</span> <span style="font-weight:bold;text-decoration:underline">int</span> orig_id, <span style="font-weight:bold;text-decoration:underline">const</span> <span style="font-weight:bold;text-decoration:underline">int</span> cur_lru,
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold;text-decoration:underline">const</span> <span style="font-weight:bold;text-decoration:underline">uint64_t</span> total_bytes, <span style="font-weight:bold;text-decoration:underline">const</span> <span style="font-weight:bold;text-decoration:underline">uint8_t</span> flags, <span style="font-weight:bold;text-decoration:underline">const</span> <span style="font-weight:bold;text-decoration:underline">rel_time_t</span> max_age,
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold;text-decoration:underline">struct</span> lru_pull_tail_return *ret_it) {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#888;font-style:italic">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#888;font-style:italic"></span>
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold;text-decoration:underline">if</span> (<span style="color:#666;font-weight:bold;font-style:italic">refcount_incr</span>(search) != 2) {
</span></span><span style="display:flex;"><span>            <span style="color:#888;font-style:italic">/* Note pathological case with ref&#39;ed items in tail.
</span></span></span><span style="display:flex;"><span><span style="color:#888;font-style:italic">             * Can still unlink the item, but it won&#39;t be reusable yet */</span>
</span></span><span style="display:flex;"><span>            itemstats[id].lrutail_reflocked++;
</span></span><span style="display:flex;"><span>            <span style="color:#888;font-style:italic">/* In case of refcount leaks, enable for quick workaround. */</span>
</span></span><span style="display:flex;"><span>            <span style="color:#888;font-style:italic">/* WARNING: This can cause terrible corruption */</span>
</span></span><span style="display:flex;"><span>            <span style="font-weight:bold;text-decoration:underline">if</span> (settings.tail_repair_time &amp;&amp;
</span></span><span style="display:flex;"><span>                    search-&gt;time + settings.tail_repair_time &lt; current_time) {
</span></span><span style="display:flex;"><span>                itemstats[id].tailrepairs++;
</span></span><span style="display:flex;"><span>                search-&gt;refcount = 1;
</span></span><span style="display:flex;"><span>                <span style="color:#888;font-style:italic">/* This will call item_remove -&gt; item_free since refcnt is 1 */</span>
</span></span><span style="display:flex;"><span>                <span style="color:#666;font-weight:bold;font-style:italic">STORAGE_delete</span>(ext_storage, search);
</span></span><span style="display:flex;"><span>                <span style="color:#666;font-weight:bold;font-style:italic">do_item_unlink_nolock</span>(search, hv);
</span></span><span style="display:flex;"><span>                <span style="color:#666;font-weight:bold;font-style:italic">item_trylock_unlock</span>(hold_lock);
</span></span><span style="display:flex;"><span>                <span style="font-weight:bold;text-decoration:underline">continue</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#888;font-style:italic">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#888;font-style:italic"></span>}
</span></span></code></pre></div><p>步骤2，内存不足情况下分配足够内存的item，其完整实现在函数<code>lru_pull_tail</code>中，读者可以自行结合上面的伪代码以及前面提及的LRU算法自行分析。</p>
<p>以上的整个流程如下图所示：</p>
<p>











<figure class="">

    <div>
        <img loading="lazy" alt="需淘汰item时的写入数据流程图" src="/media/imgs/20210812-memcached/item-recycle.png" >
    </div>

    
    <div class="caption-container">
        <figcaption> 需淘汰item时的写入数据流程图 </figcaption>
    </div>
    
</figure>
</p>
<p>解释完毕了读写操作流程之后，需要回答这个问题：为什么针对键值的锁加在了item锁上，而不是hash桶？</p>
<p>原因在于：当写入的元素过多时，hash表需要进行扩容操作，即可以认为hash桶的数量是有可能发生变化的。因此，如果锁在hash桶上，在容量发生变化的时候就难以处理。而item锁数组，其大小则是固定的，不存在这个问题。</p>
<h1 class="heading" id="hash数组的扩容操作">
  hash数组的扩容操作
  <a class="anchor" href="#hash%e6%95%b0%e7%bb%84%e7%9a%84%e6%89%a9%e5%ae%b9%e6%93%8d%e4%bd%9c">#</a>
</h1>
<p>hash数组的数量必须是2的次方，每次存储的数据总量超过数组数量的1.5倍时，就需要扩容一倍，最多到2^32。</p>
<p>扩容流程示意图如下：</p>
<p>











<figure class="">

    <div>
        <img loading="lazy" alt="hashtable扩容示意图" src="/media/imgs/20210812-memcached/expand-hashtable.png" >
    </div>

    
    <div class="caption-container">
        <figcaption> hashtable扩容示意图 </figcaption>
    </div>
    
</figure>
</p>
<p>扩容步骤为：</p>
<ul>
<li>按照新的大小分配出来新的hash数组保存到primary_hashtable中，原hash数组命名为old_hashtable，另外有扩容索引值expand_bucket，在该索引之前的数据，表示已经从old_hashtable中转移到新的hash数组了。</li>
<li>每次操作一个hash桶元素，需要对该hash桶对应的item锁进行加锁之后才能开始转移。</li>
<li>期间如果有数据访问，首先按照旧的hash桶数量进行计算，如果计算出来的索引值不小于expand_bucket，说明这个数据还在旧的桶里，到old_hashtable中查找；否则说明在新的hash数组里了，按照新的hash桶数量计算器索引值，然后再到primary_hashtable中操作。</li>
</ul>
<h1 class="heading" id="综述">
  综述
  <a class="anchor" href="#%e7%bb%bc%e8%bf%b0">#</a>
</h1>
<p>从以上分析可以看出，实现一个完备的LRU cache库，需要考虑的细节问题其实不少的，尤其memcached需要应对的是多线程情况下cache的读写，比之redis单进程单线程的情况还是要复杂不少，主要包括以下方面：</p>
<ul>
<li>如何有效、快速的分配、利用内存（slab算法与数据结构）。</li>
<li>更合理的LRU算法，不至于一次访问就导致该数据难以被回收（分段LRU算法）。</li>
<li>细粒度加锁操作，而不是全局锁，保证读写操作的并发。不把针对键值的锁放在hash桶上，因为可能会因为容量扩充导致hash桶数组变化，而是使用了一个固定大小的锁数组。</li>
<li>除了上述的锁之外，还需要不要回收正在被使用的内存（item引用计数）。</li>
<li>hash数组扩容时如何尽量减少数据访问的冲突。</li>
</ul>
<h1 class="heading" id="参考资料">
  参考资料
  <a class="anchor" href="#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99">#</a>
</h1>
<ul>
<li><a href="https://memcached.org/blog/modern-lru/">Replacing the cache replacement algorithm in memcached</a></li>
<li><a href="https://github.com/memcached/memcached/blob/master/doc/new_lru.txt">memcached/new_lru.txt</a></li>
</ul>

    
    
    <script src="https://giscus.app/client.js"
        data-repo="lichuang/lichuang.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnkxNDk2MzEzMjU="
        data-category=""
        data-category-id="DIC_kwDOCOsxXc4Crotc"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="en"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

    
    
  </div>

  

  

  

  

  

</div>


    </main>
  </div>

  <footer>
    <div class="footer-social-icons">

    <a href="https://github.com/lichuang" target="_blank"
        rel="noopener noreferrer me"
        class="me-2"
        title="Github">
        <svg role="img" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
    </a>
    <a href="https://x.com/lichuang" target="_blank"
        rel="noopener noreferrer me"
        class="me-2"
        title="Twitter">
        <svg role="img" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="m 20.808145,8.2320672 c 0.0097,0.2043875 0.0097,0.418508 0.0097,0.632628 0,6.2873468 -4.788505,13.5285018 -13.5285014,13.5285018 v 0 c -2.5791818,0 -5.1096931,-0.759154 -7.28982572375,-2.141201 0.37957667375,0.04867 0.75915336375,0.06813 1.12899732375,0.06813 2.1412017,0 4.224007,-0.720223 5.9077703,-2.043875 -2.0341418,0 -3.8152323,-1.362583 -4.4381274,-3.30913 0.7104897,0.136259 1.4501775,0.10706 2.1412018,-0.08759 -2.209331,-0.447712 -3.80549947,-2.384527 -3.80549947,-4.632788 v -0.0584 C 1.5957264,10.558191 2.3354143,10.782044 3.0945676,10.811242 1.206417,8.1542054 0.63218569,4.971601 2.4035435,2.4800207 c 2.4039856,2.9684842 5.9661667,4.7787731 9.7911305,4.9734277 -0.379576,-1.654565 0.136259,-3.3869919 1.372317,-4.5451873 1.927081,-1.8102888 4.953962,-1.7226943 6.754518,0.2043873 1.0706,-0.2141202 2.092538,-0.6131622 3.036613,-1.1581954 -0.360111,1.1095318 -1.109532,2.0536071 -2.102271,2.6570367 0.953808,-0.1167928 1.868685,-0.369844 2.744631,-0.7786188 -0.64236,0.9635408 -1.450177,1.8005561 -2.38452,2.4818475 z"/></svg>
    </a>
    <a href="https://www.douban.com/people/Lichuang" target="_blank"
        rel="noopener noreferrer me"
        class="me-2"
        title="Douban">
        <svg role="img" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Douban</title><path d="M.51 3.06h22.98V.755H.51V3.06Zm20.976 2.537v9.608h-2.137l-1.669 5.76H24v2.28H0v-2.28h6.32l-1.67-5.76H2.515V5.597h18.972Zm-5.066 9.608H7.58l1.67 5.76h5.501l1.67-5.76ZM18.367 7.9H5.634v5.025h12.733V7.9Z"/></svg>
    </a>
    <a href="t.me/codedump_notes" target="_blank"
        rel="noopener noreferrer me"
        class="me-2"
        title="Telegram">
        <svg role="img" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Telegram</title><path d="M11.944 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0a12 12 0 0 0-.056 0zm4.962 7.224c.1-.002.321.023.465.14a.506.506 0 0 1 .171.325c.016.093.036.306.02.472-.18 1.898-.962 6.502-1.36 8.627-.168.9-.499 1.201-.82 1.23-.696.065-1.225-.46-1.9-.902-1.056-.693-1.653-1.124-2.678-1.8-1.185-.78-.417-1.21.258-1.91.177-.184 3.247-2.977 3.307-3.23.007-.032.014-.15-.056-.212s-.174-.041-.249-.024c-.106.024-1.793 1.14-5.061 3.345-.48.33-.913.49-1.302.48-.428-.008-1.252-.241-1.865-.44-.752-.245-1.349-.374-1.297-.789.027-.216.325-.437.893-.663 3.498-1.524 5.83-2.529 6.998-3.014 3.332-1.386 4.025-1.627 4.476-1.635z"/></svg>
    </a>







<div class="text-center">
    <p class="text-sm text-tertiary-text"> @2018 codedump <a href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener noreferrer" target="_blank">CC BY-SA</a>Powered by<a href="https://gohugo.io/">Hugo</a>and<a href="https://github.com/tomfran/typo">typo</a>

</div>

</div>

  </footer>

  
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">
<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script>

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false }
      ]
    });
  });
</script>
  

</body>

<script src="/js/theme-switch.js"></script>
<script defer src="/js/copy-code.js"></script>
</html>
