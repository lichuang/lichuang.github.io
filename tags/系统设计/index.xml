<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>系统设计 on codedump的网络日志</title>
    <link>https://www.codedump.info/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
    <description>Recent content in 系统设计 on codedump的网络日志</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 14 Dec 2019 22:41:22 +0800</lastBuildDate><atom:link href="https://www.codedump.info/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>C&#43;&#43;11中的内存模型下篇 - C&#43;&#43;11支持的几种内存模型</title>
      <link>https://www.codedump.info/post/20191214-cxx11-memory-model-2/</link>
      <pubDate>Sat, 14 Dec 2019 22:41:22 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20191214-cxx11-memory-model-2/</guid>
      
      <description>&lt;p&gt;在本系列的上篇，介绍了内存模型的基本概念，接下来看C++11中支持的几种内存模型。&lt;/p&gt;
&lt;h1 id=&#34;几种关系术语&#34;&gt;几种关系术语&lt;/h1&gt;
&lt;p&gt;在接着继续解释之前，先了解一下几种关系术语。&lt;/p&gt;
&lt;h2 id=&#34;sequenced-before&#34;&gt;sequenced-before&lt;/h2&gt;
&lt;p&gt;sequenced-before用于表示&lt;strong&gt;单线程&lt;/strong&gt;之间，两个操作上的先后顺序，这个顺序是非对称、可以进行传递的关系。&lt;/p&gt;
&lt;p&gt;它不仅仅表示两个操作之间的先后顺序，还表示了操作结果之间的可见性关系。两个操作A和操作B，如果有A sequenced-before B，除了表示操作A的顺序在B之前，还表示了操作A的结果操作B可见。&lt;/p&gt;
&lt;h2 id=&#34;happens-before&#34;&gt;happens-before&lt;/h2&gt;
&lt;p&gt;与sequenced-before不同的是，happens-before关系表示的&lt;strong&gt;不同线程&lt;/strong&gt;之间的操作先后顺序，同样的也是非对称、可传递的关系。&lt;/p&gt;
&lt;p&gt;如果A happens-before B，则A的内存状态将在B操作执行之前就可见。在上一篇文章中，某些情况下一个写操作只是简单的写入内存就返回了，其他核心上的操作不一定能马上见到操作的结果，这样的关系是不满足happens-before的。&lt;/p&gt;
&lt;h2 id=&#34;synchronizes-with&#34;&gt;synchronizes-with&lt;/h2&gt;
&lt;p&gt;synchronizes-with关系强调的是变量被修改之后的传播关系（propagate），即如果一个线程修改某变量的之后的结果能被其它线程可见，那么就是满足synchronizes-with关系的。&lt;/p&gt;
&lt;p&gt;显然，满足synchronizes-with关系的操作一定满足happens-before关系了。&lt;/p&gt;
&lt;h1 id=&#34;c11中支持的内存模型&#34;&gt;C++11中支持的内存模型&lt;/h1&gt;
&lt;p&gt;从C++11开始，就支持以下几种内存模型：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;enum memory_order {
    memory_order_relaxed,
    memory_order_consume,
    memory_order_acquire,
    memory_order_release,
    memory_order_acq_rel,
    memory_order_seq_cst
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;与内存模型相关的枚举类型有以上六种，但是其实分为四类，如下图所示，其中对一致性的要求逐渐减弱，以下来分别讲解。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-2/c++model.png&#34; alt=&#34;c++model&#34; title=&#34;c++model&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;memory_order_seq_cst&#34;&gt;memory_order_seq_cst&lt;/h1&gt;
&lt;p&gt;这是默认的内存模型，即上篇文章中分析过的顺序一致性内存模型，由于在上篇中的相关概念已经做过详细的介绍，这里就不再阐述了。仅列出引用自《C++  Concurrency In Action》的示例代码。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;atomic&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;assert.h&amp;gt;

std::atomic&amp;lt;bool&amp;gt; x,y;
std::atomic&amp;lt;int&amp;gt; z;

void write_x()
{
    x.store(true,std::memory_order_seq_cst);
}

void write_y()
{
    y.store(true,std::memory_order_seq_cst);
}

void read_x_then_y()
{
    while(!x.load(std::memory_order_seq_cst));
    if(y.load(std::memory_order_seq_cst))
        ++z;
}

void read_y_then_x()
{
    while(!y.load(std::memory_order_seq_cst));
    if(x.load(std::memory_order_seq_cst))
        ++z;
}

int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join();
    b.join();
    c.join();
    d.join();
    assert(z.load()!=0);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于采用了顺序一致性模型，因此最后的断言不可能发生，即在程序结束时不可能出现z为0的情况。&lt;/p&gt;
&lt;h1 id=&#34;memory_order_relaxed&#34;&gt;memory_order_relaxed&lt;/h1&gt;
&lt;p&gt;这种类型对应的松散内存模型，这种内存模型的特点是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;针对一个变量的读写操作是原子操作；&lt;/li&gt;
&lt;li&gt;不同线程之间针对该变量的访问操作先后顺序不能得到保证，即有可能乱序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;来看示例代码：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;atomic&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;assert.h&amp;gt;

std::atomic&amp;lt;bool&amp;gt; x,y;
std::atomic&amp;lt;int&amp;gt; z;

void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed);
    y.store(true,std::memory_order_relaxed);
}

void read_y_then_x()
{
    while(!y.load(std::memory_order_relaxed));
    if(x.load(std::memory_order_relaxed))
        ++z;
}

int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在上面的代码中，对原子变量的访问都使用memory_order_relaxed模型，导致了最后的断言可能失败，即在程序结束时z可能为0。&lt;/p&gt;
&lt;h1 id=&#34;acquire-release&#34;&gt;Acquire-Release&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;memory_order_acquire：用来修饰一个读操作，表示在本线程中，所有后续的关于此变量的内存操作都必须在本条原子操作完成后执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-2/read-acquire.png&#34; alt=&#34;read-acquire&#34; title=&#34;read-acquire&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;memory_order_release：用来修饰一个写操作，表示在本线程中，所有之前的针对该变量的内存操作完成后才能执行本条原子操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-2/write-release.png&#34; alt=&#34;write-release&#34; title=&#34;write-release&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;memory_order_acq_rel：同时包含memory_order_acquire和memory_order_release标志。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;来看示例代码：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 5.7.cpp
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;assert.h&amp;gt;

std::atomic&amp;lt;bool&amp;gt; x,y;
std::atomic&amp;lt;int&amp;gt; z;

void write_x()
{
    x.store(true,std::memory_order_release);
}

void write_y()
{
    y.store(true,std::memory_order_release);
}

void read_x_then_y()
{
    while(!x.load(std::memory_order_acquire));
    if(y.load(std::memory_order_acquire))
        ++z;
}

void read_y_then_x()
{
    while(!y.load(std::memory_order_acquire));
    if(x.load(std::memory_order_acquire))
        ++z;
}

int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join();
    b.join();
    c.join();
    d.join();
    assert(z.load()!=0);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面这个例子中，并不能保证程序最后的断言即z!=0为真，其原因在于：在不同的线程中分别针对x、y两个变量进行了同步操作并不能保证x、y变量的读取操作。&lt;/p&gt;
&lt;p&gt;线程write_x针对变量x使用了write-release模型，这样保证了read_x_then_y函数中，在load变量y之前x为true；同理线程write_y针对变量y使用了write-release模型，这样保证了read_y_then_x函数中，在load变量x之前y为true。&lt;/p&gt;
&lt;p&gt;然而即便是这样，仍然可能出现以下类似的情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-2/5.7.png&#34; alt=&#34;5.7&#34; title=&#34;5.7&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始条件为x = y = false。&lt;/li&gt;
&lt;li&gt;由于在read_x_and_y线程中，对x的load操作使用了acquire模型，因此保证了是先执行write_x函数才到这一步的；同理先执行write_y才到read_y_and_x中针对y的load操作。&lt;/li&gt;
&lt;li&gt;然而即便如此，也可能出现在read_x_then_y中针对y的load操作在y的store操作之前完成，因为y.store操作与此之间没有先后顺序关系；同理也不能保证x一定读到true值，因此到程序结束是就出现了z = 0的情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从上面的分析可以看到，即便在这里使用了release-acquire模型，仍然没有保证z=0，其原因在于：最开始针对x、y两个变量的写操作是分别在write_x和write_y线程中进行的，不能保证两者执行的顺序导致。因此修改如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 5.8.cpp
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;assert.h&amp;gt;

std::atomic&amp;lt;bool&amp;gt; x,y;
std::atomic&amp;lt;int&amp;gt; z;

void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed);
    y.store(true,std::memory_order_release);
}

void read_y_then_x()
{
    while(!y.load(std::memory_order_acquire));
    if(x.load(std::memory_order_relaxed))
        ++z;
}

int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-2/5.8.png&#34; alt=&#34;5.8&#34; title=&#34;5.8&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始条件为x = y = false。&lt;/li&gt;
&lt;li&gt;在write_x_then_y线程中，先执行对x的写操作，再执行对y的写操作，由于两者在同一个线程中，所以即便针对x的修改操作使用relaxed模型，修改x也一定在修改y之前执行。&lt;/li&gt;
&lt;li&gt;在write_x_then_y线程中，对y的load操作使用了acquire模型，而在线程write_x_then_y中针对变量y的读操作使用release模型，因此保证了是先执行write_x_then_y函数才到read_y_then_x的针对变量y的load操作。&lt;/li&gt;
&lt;li&gt;因此最终的执行顺序如上图所示，此时不可能出现z=0的情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从以上的分析可以看出，针对同一个变量的release-acquire操作，更多时候扮演了一种“线程间使用某一变量的同步”作用，由于有了这个语义的保证，做到了线程间操作的先后顺序保证（inter-thread happens-before）。&lt;/p&gt;
&lt;h1 id=&#34;release-consume&#34;&gt;Release-Consume&lt;/h1&gt;
&lt;p&gt;从上面对Acquire-Release模型的分析可以知道，虽然可以使用这个模型做到两个线程之间某些操作的synchronizes-with关系，然后这个粒度有些过于大了。&lt;/p&gt;
&lt;p&gt;在很多时候，线程间只想针对有依赖关系的操作进行同步，除此之外线程中的其他操作顺序如何无所谓。比如下面的代码中：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;b = *a;
c = *b;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中第二行代码的执行结果依赖于第一行代码的执行结果，此时称这两行代码之间的关系为“carry-a-dependency ”。C++中引入的memory_order_consume内存模型就针对这类代码间有明确的依赖关系的语句限制其先后顺序。&lt;/p&gt;
&lt;p&gt;来看下面的示例代码：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 5.10
#include &amp;lt;string&amp;gt;
#include &amp;lt;thread&amp;gt;
#include &amp;lt;atomic&amp;gt;
#include &amp;lt;assert.h&amp;gt;
struct X
{
    int i;
    std::string s;
};

std::atomic&amp;lt;X*&amp;gt; p;
std::atomic&amp;lt;int&amp;gt; a;

void create_x()
{
    X* x=new X;
    x-&amp;gt;i=42;
    x-&amp;gt;s=&amp;#34;hello&amp;#34;;
    a.store(99,std::memory_order_relaxed);
    p.store(x,std::memory_order_release);
}

void use_x()
{
    X* x;
    while(!(x=p.load(std::memory_order_consume)))
        std::this_thread::sleep_for(std::chrono::microseconds(1));
    assert(x-&amp;gt;i==42);
    assert(x-&amp;gt;s==&amp;#34;hello&amp;#34;);
    assert(a.load(std::memory_order_relaxed)==99);
}
int main()
{
    std::thread t1(create_x);
    std::thread t2(use_x);
    t1.join();
    t2.join();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上的代码中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create_x线程中的store(x)操作使用memory_order_release，而在use_x线程中，有针对x的使用memory_order_consume内存模型的load操作，两者之间由于有carry-a-dependency关系，因此能保证两者的先后执行顺序。所以，x-&amp;gt;i == 42以及x-&amp;gt;s==&amp;ldquo;hello&amp;quot;这两个断言都不会失败。&lt;/li&gt;
&lt;li&gt;然而，create_x中针对变量a的使用relax内存模型的store操作，use_x线程中也有针对变量a的使用relax内存模型的load操作。这两者的先后执行顺序，并不受前面的memory_order_consume内存模型影响，所以并不能保证前后顺序，因此断言a.load(std::memory_order_relaxed)==99真假都有可能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上可以对比Acquire-Release以及Release-Consume两个内存模型，可以知道：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Acquire-Release能保证不同线程之间的Synchronizes-With关系，这同时也约束到同一个线程中前后语句的执行顺序。&lt;/li&gt;
&lt;li&gt;而Release-Consume只约束有明确的carry-a-dependency关系的语句的执行顺序，同一个线程中的其他语句的执行先后顺序并不受这个内存模型的影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;《C++  Concurrency In Action》&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preshing.com/20140709/the-purpose-of-memory_order_consume-in-cpp11/&#34;&gt;《The Purpose of memory_order_consume in C++11》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preshing.com/20130823/the-synchronizes-with-relation/&#34;&gt;《The Synchronizes-With Relation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;修改历史&#34;&gt;修改历史&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;2019-12-14：初稿。&lt;/li&gt;
&lt;li&gt;2020-04-11：修改代码显示。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>C&#43;&#43;11中的内存模型上篇 - 内存模型基础</title>
      <link>https://www.codedump.info/post/20191214-cxx11-memory-model-1/</link>
      <pubDate>Sat, 14 Dec 2019 10:10:15 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20191214-cxx11-memory-model-1/</guid>
      
      <description>&lt;p&gt;前段时间花了些精力研究C++11引入的内存模型相关的操作，于是把相关的知识都学习了一下，将这个学习过程整理为两篇文档，这是第一篇，主要分析内存模型的一些基础概念，第二篇展开讨论C++11相关的操作。&lt;/p&gt;
&lt;h1 id=&#34;cpu架构的演进&#34;&gt;CPU架构的演进&lt;/h1&gt;
&lt;p&gt;早期的CPU，CPU之间能共享访问的只有内存，此时的结构大体如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/memory.png&#34; alt=&#34;memory&#34; title=&#34;memory&#34;&gt;&lt;/p&gt;
&lt;p&gt;随着硬件技术的发展，内存的访问已经跟不上CPU的执行速度，此时内存反而变成了瓶颈。为了加速读写速度，每个CPU也都有自己内部才能访问的缓存，结构变成了这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/multicore.png&#34; alt=&#34;multicore&#34; title=&#34;multicore&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有多个CPU处理器，每个CPU处理器内部又有多个核心。&lt;/li&gt;
&lt;li&gt;存在只能被一个CPU核心访问的L1 cache。&lt;/li&gt;
&lt;li&gt;存在只能被一个CPU处理器的多个核心访问的L2 cache。&lt;/li&gt;
&lt;li&gt;存在能被所有CPU处理器都能访问到的L3 cache以及内存。&lt;/li&gt;
&lt;li&gt;L1 cache、L2 cache、L3 cache的容量空间依次变大，但是访问速度依次变慢。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当CPU结构发生变化，增加了只能由内部才能访问的缓存之后，一些在旧架构上不会出现的问题，在新的架构上就会出现。而本篇的主角内存模型（memory model），其作用就是规定了各种不同的访问共享内存的方式，不同的内存模型，既需要编译器的支持，也需要硬件CPU的支持。&lt;/p&gt;
&lt;p&gt;我们从一个最简单的多线程访问变量问题谈起。&lt;/p&gt;
&lt;h1 id=&#34;简单的多线程访问数据问题&#34;&gt;简单的多线程访问数据问题&lt;/h1&gt;
&lt;p&gt;假设在程序执行之前，A=B=0，有两个线程同时分别执行如下的代码：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;线程1&lt;/th&gt;
&lt;th&gt;线程2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1. A=1&lt;/td&gt;
&lt;td&gt;3. B=2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2. print(B)&lt;/td&gt;
&lt;td&gt;4. print(A)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;问上述程序的执行结果如何？&lt;/p&gt;
&lt;p&gt;这个问题是一个简单的排列组合问题，其结果有：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2（先选择A或B输出）* 2（输出修改前还是之后的结果）* 1（前面第一步选择了一个变量之后，现在只能选剩下的变量）* 2（输出修改前还是之后的结果） = 8&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其可能的结果包括：(0,0)、(1,0)、(0,2)、(1,2)、(0,1)、(2,0)、(2,1)。（这里只有7个结果，是因为有两个(0,0)，所以少了一个）。&lt;/p&gt;
&lt;p&gt;由于多个线程交替执行，可能有以下几种结果，下面来分别解析。&lt;/p&gt;
&lt;h2 id=&#34;两个线程依次执行&#34;&gt;两个线程依次执行&lt;/h2&gt;
&lt;p&gt;最简单的情况，就是这两个线程依次执行，即一个线程执行完毕之后再执行另一个线程的指令，这种情况下有两种可能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1-&amp;gt;2-&amp;gt;3-&amp;gt;4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种情况先执行完毕线程1，再执行线程2，最后输出的结果是(0,1)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/sc1.png&#34; alt=&#34;sc1&#34; title=&#34;sc1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3-&amp;gt;4-&amp;gt;1-&amp;gt;2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种情况先执行完毕线程2，再执行线程1，最后输出的结果是(0,2)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/sc2.png&#34; alt=&#34;sc2&#34; title=&#34;sc2&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;两个线程交替执行&#34;&gt;两个线程交替执行&lt;/h2&gt;
&lt;p&gt;这样情况下，先执行的可能是线程1或者线程2，来看线程1先执行的情况。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1-&amp;gt;3-&amp;gt;2-&amp;gt;4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种情况下的输出是（2,1）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/sc3.png&#34; alt=&#34;sc3&#34; title=&#34;sc3&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1-&amp;gt;3-&amp;gt;4-&amp;gt;2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种情况下的输出是（1,2）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/sc4.png&#34; alt=&#34;sc4&#34; title=&#34;sc4&#34;&gt;&lt;/p&gt;
&lt;p&gt;以上是第一条指令先执行线程1执行的情况，同样地也有先执行线程2指令的情况（3-1-&amp;gt;4-&amp;gt;2和3-&amp;gt;1-&amp;gt;2-4），这里不再列出，有兴趣的读者可以自行画图理解。&lt;/p&gt;
&lt;h2 id=&#34;不可能出现的情况&#34;&gt;不可能出现的情况&lt;/h2&gt;
&lt;p&gt;除了以上的情况之外，还有一种可能是输出(0,0)，但是这种输出在一般情况下不可能出现（我们接下来会解释什么情况下可能出现），下面来做解释。&lt;/p&gt;
&lt;p&gt;首先先来理解一个概念“happen-before（先于）”，比如对于变量A而言，其初始值是0，有如下两个操作：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;A = 1
print(A)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;那么要对操作print(A)输出结果0，就要保证&amp;quot;print(A)&amp;ldquo;这个操作“happen-before（先于）”操作&amp;quot;A=1&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;有了happen-before这个概念的初步印象，就可以进一步解释为什么在SC的要求之下，程序不可能输出(0,0)，在下面的讲解中，用箭头来表示两个操作之间的happen-before关系。&lt;/p&gt;
&lt;p&gt;由前面的分析可知，要求对变量A输出0，那么意味着&amp;quot;print(A)&amp;ldquo;操作happen-before修改变量A的赋值操作&amp;quot;A=1&amp;rdquo;。同样的，要求针对变量B的输出为0，那么意味着&amp;quot;print(B)&amp;ldquo;操作happen-before修改变量B的赋值操作&amp;quot;B=2&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;用图来表示就是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/happen-before.png&#34; alt=&#34;happen-before&#34; title=&#34;happen-before&#34;&gt;&lt;/p&gt;
&lt;p&gt;由于输出结果(0,0)要求同时满足前面的两个分别针对变量A和B的happen-before关系，同时又不能违背程序顺序，因此出错了，见下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/00.png&#34; alt=&#34;00&#34; title=&#34;00&#34;&gt;&lt;/p&gt;
&lt;p&gt;首先，根据前面分析的输出关系，必须保证“4 happen-before 1”以及“2 happen-before 3”。
同时，一个处理器内的执行顺序必须按照程序顺序（program order），因此也必须保证“1 happen before 2”以及“2 happen before 3”。&lt;/p&gt;
&lt;p&gt;当前面几个happen before关系合在一起，这个执行过程出现了死循环，不知道在哪里终止了。&lt;/p&gt;
&lt;h1 id=&#34;sequential-consistency-顺序一致性&#34;&gt;Sequential Consistency (顺序一致性）&lt;/h1&gt;
&lt;p&gt;这里就可以引入最直白、简单的一种内存模型：顺序一致性内存模型（Sequential Consistency）了。&lt;/p&gt;
&lt;p&gt;Sequential Consistency（以下简称SC）由Lamport提出，其严格定义是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“… the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这句话看起来很拗口，它对程序的执行结果有两个要求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个处理器的执行顺序和代码中的顺序（program order）一样。&lt;/li&gt;
&lt;li&gt;所有处理器都只能看到一个单一的操作执行顺序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在要求满足SC内存模型的情况下，上面多线程执行中（0,0）是不可能输出的。&lt;/p&gt;
&lt;p&gt;我们以IM中的群聊消息作为例子说明顺序一致性的这两个要求。在这个例子中，群聊中的每个成员，相当于多核编程中的一个处理器，那么对照顺序一致性的两个要求就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个人自己发出去的消息，必然是和ta说话的顺序一致的。即用户A在群聊中依次说了消息1和消息2，在群聊天的时候也必然是先看到消息1然后再看到消息2，这就是前面顺序一致性的第一个要求。&lt;/li&gt;
&lt;li&gt;群聊中有多个用户参与聊天（多处理器），如果所有人看到的消息顺序都一样，那么就满足了前面顺序一致性的第二个要求了，但是这个顺序首先不能违背前面的第一个要求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;顺序一致性的缺点&#34;&gt;顺序一致性的缺点&lt;/h2&gt;
&lt;p&gt;从以上的分析可以看到，顺序一致性实际上是一种强一致性，可以想象成整个程序过程中由一个开关来选择执行的线程，这样才能同时保证顺序一致性的两个条件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/sc-switch.png&#34; alt=&#34;sc-switch&#34; title=&#34;sc-switch&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，这样实际上还是相当于同一时间只有一个线程在工作，这种保证导致了程序是低效的，无法充分利用上多核的优点。&lt;/p&gt;
&lt;h1 id=&#34;全存储排序total-store-ordering-简称tso&#34;&gt;全存储排序（Total Store Ordering, 简称TSO）&lt;/h1&gt;
&lt;p&gt;有一些CPU架构，在处理核心中增加写缓存，一个写操作只要写入到本核心的写缓存中就可以返回，此时的CPU结构如图所示（图中并没有画出三级cache）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/tso.png&#34; alt=&#34;tso&#34; title=&#34;tso&#34;&gt;&lt;/p&gt;
&lt;p&gt;在这种结构下，SC所不允许的一些操作可能会出现。&lt;/p&gt;
&lt;p&gt;还是以前面分析SC的程序例子来说明：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;线程1&lt;/th&gt;
&lt;th&gt;线程2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1. A=1&lt;/td&gt;
&lt;td&gt;3. B=2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2. print(B)&lt;/td&gt;
&lt;td&gt;4. print(A)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在新的CPU架构下，写一个值可能值写到本核心的缓冲区中就返回了，接着执行下面的一条指令，因此可能出现以下的情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/multicore-2.png&#34; alt=&#34;multicore-2&#34; title=&#34;multicore-2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;执行操作1，core 1写入A的新值1到core 1的缓冲区中之后就马上返回了，还并没有更新到所有CPU都能访问到的内存中。&lt;/li&gt;
&lt;li&gt;执行操作3，core 2写入B的新值2到core 2的缓冲区中之后就马上返回了，还并没有更新到所有CPU都能访问到的内存中。&lt;/li&gt;
&lt;li&gt;执行操作2，由于操作2访问到本core缓冲区中存储的B值还是原来的0，因此输出0。&lt;/li&gt;
&lt;li&gt;执行操作4，由于操作4访问到本core缓冲区中存储的A值还是原来的0，因此输出0。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，在引入了只能由每个core才能访问到的写缓冲区之后，之前SC中不可能出现的输出(0,0)的情况在这样的条件下可能出现了。&lt;/p&gt;
&lt;h1 id=&#34;松弛型内存模型relaxed-memory-models&#34;&gt;松弛型内存模型（Relaxed memory models）&lt;/h1&gt;
&lt;p&gt;以上已经介绍了两种内存模型，SC是最简单直白的内存模型，TSO在SC的基础上，加入了写缓存，写缓存的加入导致了一些在SC条件下不可能出现的情况也成为了可能。&lt;/p&gt;
&lt;p&gt;然而，即便如此，以上两种内存模型都没有改变单线程执行一个程序时的执行顺序。在这里要讲的松弛型内存模型，则改变了程序的执行顺序。&lt;/p&gt;
&lt;p&gt;在松散型的内存模型中，编译器可以在满足程序单线程执行结果的情况下进行重排序（reorder），来看下面的程序：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;int&lt;/span&gt; A, B;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;foo&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  A &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; B &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  B &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;main&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  foo();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果在不使用优化的情况下编译，gcc foo.c -S，foo函数中针对A和B操作的汇编代码如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;	movl	B(%rip), %eax
	addl	$1, %eax
	movl	%eax, A(%rip)
	movl	$0, B(%rip)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;即先把变量B的值赋给寄存器eax，将寄存器eax加一的结果赋值给变量A，最后再将变量B置为0。&lt;/p&gt;
&lt;p&gt;而如果使用O2优化编译，gcc foo.c -S -O2 则得到下面的汇编代码：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;	movl	B(%rip), %eax
	movl	$0, B(%rip)
	addl	$1, %eax
	movl	%eax, A(%rip)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;即先把变量B的值赋给寄存器eax，然后变量B置零，再将寄存器eax加一的结果赋值给变量A。&lt;/p&gt;
&lt;p&gt;其原因在于，foo函数中，只要将变量B的值暂存下来，那么对变量B的赋值操作可以被打乱而并不影响程序的执行结果，这就是编译器可以做的重排序优化。&lt;/p&gt;
&lt;p&gt;回到前面的例子中，在松弛型内存模型中，程序的执行顺序就不见得和代码中编写的一样了，这是这种内存模型和SC、TSO模型最大的差异。&lt;/p&gt;
&lt;p&gt;仍然以IM群聊消息为例子说明这个问题。假设有多人在群里聊天，如果A说的消息1与B说的消息2之间，没用明确的先后顺序，比如消息1是回复或者引用了消息2的话，那么其实在整个群聊视图里面，两者的先后顺序如何是无关紧要的。即参与群聊的两个用户，其中一个用户可能看到消息1在消息2之前，另一个用户看到的顺序相反，这都是无关大局的，因为两个消息之间没有关系。&lt;/p&gt;
&lt;h2 id=&#34;内存栅栏memory-barrier&#34;&gt;内存栅栏（memory barrier）&lt;/h2&gt;
&lt;p&gt;讲完了三种内存模型，这里还需要了解一下内存栅栏的概念。&lt;/p&gt;
&lt;p&gt;由于有了缓冲区的出现，导致一些操作不用到内存就可以返回继续执行后面的操作，为了保证某些操作必须是写入到内存之后才执行，就引入了内存栅栏（memory barrier，又称为memory fence）操作。内存栅栏指令保证了，在这条指令之前所有的内存操作的结果，都在这个指令之后的内存操作指令被执行之前，写入到内存中。也可以换另外的角度来理解内存栅栏指令的作用：显式的在程序的某些执行点上保证SC。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/memorybarrier.png&#34; alt=&#34;memorybarrier&#34; title=&#34;memorybarrier&#34;&gt;&lt;/p&gt;
&lt;p&gt;再次以前面的例子来说明这个指令，在X64下面，内存屏障指令使用汇编指令&lt;code&gt;asm volatile (&amp;quot;pause&amp;quot; ::: &amp;quot;memory&amp;quot;);&lt;/code&gt;来实现，如果将这个指令放到两个赋值语句之间：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;int&lt;/span&gt; A, B;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;foo&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    A &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; B &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;asm&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;volatile&lt;/span&gt; (&lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;pause&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;:::&lt;/span&gt; &lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;memory&amp;#34;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    B &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;main&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  foo();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;那么再次使用O2编译出来的汇编代码就变成了：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;.LFB1:
  .cfi_startproc
  movl  B(%rip), %eax
  addl  $1, %eax
  movl  %eax, A(%rip)
#APP
# 6 &amp;#34;foo.c&amp;#34; 1
  pause
# 0 &amp;#34;&amp;#34; 2
#NO_APP
  movl  $0, B(%rip)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到，插入内存屏障指令之后，生成的汇编代码顺序就不会乱序了。&lt;/p&gt;
&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;
&lt;p&gt;以上，从引入一个多线程读写多个变量的例子出发，依次讲解了SC、TSO、Relaxed model三种内存模型，这三种内存模型其一致性要求依次减弱，其总结如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191214-cxx11-memory-model-1/memorymodel.png&#34; alt=&#34;memorymodel&#34; title=&#34;memorymodel&#34;&gt;&lt;/p&gt;
&lt;p&gt;有了上面的介绍，下一篇介绍C++11之后引入的几种内存模型操作。&lt;/p&gt;
&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;《A Primer on Memory Consistency and Cache Coherence》&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.parallellabs.com/2010/03/06/why-should-programmer-care-about-sequential-consistency-rather-than-cache-coherence/&#34;&gt;《为什么程序员需要关心顺序一致性（Sequential Consistency）而不是Cache一致性（Cache Coherence？）》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.utexas.edu/~bornholt/post/memory-models.html&#34;&gt;《Memory Consistency Models: A Tutorial》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://preshing.com/20120625/memory-ordering-at-compile-time/&#34;&gt;《Memory Ordering at Compile Time》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>对比脚本型和编译型游戏服务器的热更新方案</title>
      <link>https://www.codedump.info/post/20191206-gameserver-hot-refresh/</link>
      <pubDate>Fri, 06 Dec 2019 22:40:49 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20191206-gameserver-hot-refresh/</guid>
      
      <description>&lt;p&gt;本文对比游戏服务器中C++搭配脚本语言（Lua、Python）以及纯编译型语言（C++、Golang）来进行开发时，进行线上服务器热更新的方案。&lt;/p&gt;
&lt;h1 id=&#34;游戏开发模式&#34;&gt;游戏开发模式&lt;/h1&gt;
&lt;p&gt;在开始下文之前，有必要简单描述一下游戏服务与web服务的区别。&lt;/p&gt;
&lt;h2 id=&#34;长连接-vs-短连接&#34;&gt;长连接 VS 短连接&lt;/h2&gt;
&lt;p&gt;游戏服务对外与客户端之间的链接多是长连接形式，而web服务多是短连接。&lt;/p&gt;
&lt;h2 id=&#34;有状态服务-vs-无状态服务&#34;&gt;有状态服务 VS 无状态服务&lt;/h2&gt;
&lt;p&gt;游戏服务内，需要维持着玩家的状态数据，如玩家属性、位置等，web请求多是无状态服务。&lt;/p&gt;
&lt;h2 id=&#34;启动时间&#34;&gt;启动时间&lt;/h2&gt;
&lt;p&gt;由于前面提到的游戏服务是有状态服务，因此游戏服务器启动的时候，需要从持久化存储中将数据加载到内存中，这意味着游戏服务器的启动时间会很长，一般一次需要几分钟，web服务器相对轻量很多，因为需要访问的持久化数据在另外的存储服务器上。&lt;/p&gt;
&lt;h2 id=&#34;开发周期&#34;&gt;开发周期&lt;/h2&gt;
&lt;p&gt;游戏服务的开发周期短，有一些游戏一周就需要进行一次维护，这意味着在这一周内策划（对应互联网中的产品经理）提出的需求都要完成上线。&lt;/p&gt;
&lt;p&gt;从以上对比可以看到，游戏业务的特点是更新频繁，而启动一个服务器的时间又比较长。在进行开发的过程中，如果使用纯编译型语言进行开发，那么流程就是如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191206-gameserver-hot-refresh/cpp-dev.png&#34; alt=&#34;cpp-dev&#34; title=&#34;cpp-dev&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，上面是一个比较长的开发功能流程，而如果还考虑到开发周期短这个特点，显然是不能匹配游戏开发这种业务的特征的，此时就需要“热更新”功能才能提高开发效率。&lt;/p&gt;
&lt;p&gt;以下就脚本语言与编译型语言如何实现“热更新”展开讨论。&lt;/p&gt;
&lt;h1 id=&#34;c搭配脚本语言&#34;&gt;C++搭配脚本语言&lt;/h1&gt;
&lt;p&gt;这种方案是笔者见过的方案，其一般的做法是：C++来实现底层的框架（网络、与数据库通信等），接收到数据包之后，将数据传递给脚本层，由脚本来处理具体的业务逻辑。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191206-gameserver-hot-refresh/script-level.png&#34; alt=&#34;script-level&#34; title=&#34;script-level&#34;&gt;&lt;/p&gt;
&lt;p&gt;这种也是软件设计中常见的分层方案：底层的模块为上层的模块服务，同时底层模块也变动的较少。&lt;/p&gt;
&lt;p&gt;由于嵌入到进程里面的脚本语言引擎，本质上是将脚本语言代码翻译成内存中的Opcode来执行，因此这类型游戏服务器实现“热更新”方案很简单：将新的脚本同步到服务器上，然后给服务器发出一个信号，重新读取脚本代码到内存中即可。&lt;/p&gt;
&lt;p&gt;有了这个架构之后，原先的开发模式就变成了下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191206-gameserver-hot-refresh/script-dev.png&#34; alt=&#34;script-dev&#34; title=&#34;script-dev&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，前面编译型语言中编译和重启服务器这两部最消耗时间的步骤，变成了热更新脚本，这样就不需要重启服务器来验证功能，开发效率提高了很多。&lt;/p&gt;
&lt;h1 id=&#34;编译型语言实现热更新&#34;&gt;编译型语言实现热更新&lt;/h1&gt;
&lt;p&gt;从上面的分析可以看到，因为编译型语言存在需要重启服务器的步骤，导致了以下两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端连接需要断开，因为游戏服务是长连接。&lt;/li&gt;
&lt;li&gt;重启服务器时需要耗费大量的时间将持久化存储的数据加载到内存中，这样启停过程中的客户端请求就会丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面依次看看如何解决这两个问题。&lt;/p&gt;
&lt;p&gt;维护客户端连接，可以再引入一个网关组件，由网关来维护连接，这样服务器重启流程中客户端对内部游戏服务器的启停并无感知。&lt;/p&gt;
&lt;p&gt;为了在启动新版本服务器的过程中继续服务客户端请求，并且新版本服务器上线之后能接着当前的玩家属性继续操作，可以考虑将数据存入共享内存中，这样即便进程退出共享内存还存在。这样做的思路是“代码与数据分离”。&lt;/p&gt;
&lt;p&gt;如果要实现这个方案，又要做到以下两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设计一套面向共享内存的数据结构，至少应该能支持常见的链表、数组、字典等类型。&lt;/li&gt;
&lt;li&gt;数据结构的设计需要考虑可扩展性以及前后兼容性，因为可能出现两个前后版本中，有一些字段不存在或者有一些字段新增的情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有了以上的介绍，下图中就是为了支持热更新的编译型语言的架构方案：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191206-gameserver-hot-refresh/cpp-hotrefresh.png&#34; alt=&#34;cpp-hotrefresh&#34; title=&#34;cpp-hotrefresh&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网关负责维护与客户端的连接，同时也知道当前访问的是哪个游戏服务器。当新版本服务器启动完毕之后，向网关发送一个指令，让网关在收到这个指令之后的所有客户端请求，都转发到新的游戏服务器上，这样就完成了一个看似没有重启的“热更新”。&lt;/li&gt;
&lt;li&gt;数据保存在共享内存中，这样即使在启动新版本服务器的时候也能继续服务客户端的请求。另外需要注意的是，启动的时候服务器需要判断一下是否已经有一个进程存在，如果存在进程且有共享内存数据的情况下，不需要再从持久化存储中加载数据到内存中。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;方案对比&#34;&gt;方案对比&lt;/h1&gt;
&lt;p&gt;以下来对比一下两种技术方案的优缺点。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;特性&lt;/th&gt;
&lt;th&gt;脚本型游戏服务器&lt;/th&gt;
&lt;th&gt;编译型游戏服务器&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;开发效率&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;脚本语言没有编译步骤&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;性能&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;脚本语言执行性能不如编译型语言&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;架构难度&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;编译型语言为了实现热更新，需要解决：网关维护连接，代码数据分离，数据存入共享内存等，而脚本型语言只需要实现热更新脚本即可&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;重构难度&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;“脚本语言一时爽，代码重构火葬场”&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
      
    </item>
    
    <item>
      <title>IM服务器设计-如何解决消息的乱序</title>
      <link>https://www.codedump.info/post/20191013-im-msg-out-of-order/</link>
      <pubDate>Sun, 13 Oct 2019 10:59:16 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20191013-im-msg-out-of-order/</guid>
      
      <description>&lt;p&gt;IM消息需要面对的另一个难题：如何保证收到的消息不乱序。下面先展开看看要解决这个难题有哪些障碍。&lt;/p&gt;
&lt;h1 id=&#34;消息乱序的原因&#34;&gt;消息乱序的原因&lt;/h1&gt;
&lt;h2 id=&#34;时间难以保证&#34;&gt;时间难以保证&lt;/h2&gt;
&lt;p&gt;既然谈到“顺序”，就必然有一个衡量的标准，然而无论是使用客户端时间还是服务器时间都难以作为这个标准来衡量消息的先后顺序。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191013-im-msg-out-of-order/msg.png&#34; alt=&#34;msg&#34; title=&#34;msg&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图中，一个IM系统在多个客户端，在不同的接入网关进行接入，进而又在不同的逻辑处理服务器上进行处理，不论是客户端本身，还是服务器（网络、逻辑服务器），各自机器上的时间都不相同，因此无法以机器本地的时间来作为衡量消息顺序的标准。&lt;/p&gt;
&lt;h2 id=&#34;网络顺序无法保证&#34;&gt;网络顺序无法保证&lt;/h2&gt;
&lt;p&gt;考虑到只有一个客户端连接上一个网关的场景，即使在这样的场景中，消息的先后顺序也因为网络的因素难以得到保证。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191013-im-msg-out-of-order/msg-network.png&#34; alt=&#34;msg-network&#34; title=&#34;msg-network&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图中，网关试图向客户端依次发送消息1、2这两条消息，可能出现下面的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网关向客户端发送消息1，此时客户端的网络状况不好，导致该消息可能会丢失或者重传。&lt;/li&gt;
&lt;li&gt;网关没有等待消息1的发送结果，继续发送了消息2，而此时客户端的网络状况变好，这条消息比消息1更快的被客户端收到。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上的场景，可能会有人想到一种处理模式：网关只有在客户端应答收到了消息1之后再继续发送消息2，这样就不会出现网络原因导致的消息乱序问题了。然而这样的话，消息相当于串行发送了，效率并不高。&lt;/p&gt;
&lt;h2 id=&#34;多线程因素导致的乱序&#34;&gt;多线程因素导致的乱序&lt;/h2&gt;
&lt;p&gt;客户端、服务器都可能存在多个发送、接收线程，这也是导致消息乱序的原因之一。&lt;/p&gt;
&lt;h1 id=&#34;解决策略&#34;&gt;解决策略&lt;/h1&gt;
&lt;p&gt;前面分析了消息乱序的几个成因，下面就逐个分析都应该怎么解决。&lt;/p&gt;
&lt;h2 id=&#34;消息序列号&#34;&gt;消息序列号&lt;/h2&gt;
&lt;p&gt;前面提过的第一个问题：消息的时序标准问题，无法以客户端或者服务器本地的时间来作为衡量的标准，此时可以引入一个产生递增ID的组件，由这一组件来统一生成递增、不回退的消息序列号用于衡量消息的先后顺序。&lt;/p&gt;
&lt;p&gt;然而这里还有可以细化讨论的部分：这个组件生成的ID，是否需要全局唯一？即不论单聊、群聊都需要保证生成出来的序列号唯一。&lt;/p&gt;
&lt;p&gt;这个全局唯一性不是必要的，原因在于不同的聊天，能保证消息在自己的频道唯一、递增即可。有了这个前提，这个组件生成ID的流程大体如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;处理该聊天的逻辑服务器ID。&lt;/li&gt;
&lt;li&gt;每个聊天频道（单聊、群聊）有自己一个独立的频道ID。&lt;/li&gt;
&lt;li&gt;每个频道内部，保证能够产生一个递增、不回退的序列号。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样，消息序列号实际上由三部分部分组成：逻辑服务器ID-频道ID-频道内的消息序列号。&lt;/p&gt;
&lt;h2 id=&#34;群聊消息的处理&#34;&gt;群聊消息的处理&lt;/h2&gt;
&lt;p&gt;有了前面的消息序列号，已经解决了第一个问题：消息的时序标准问题。然而这样还不足够，考虑到下图中的群聊场景：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191013-im-msg-out-of-order/group-msg.png&#34; alt=&#34;group-msg&#34; title=&#34;group-msg&#34;&gt;&lt;/p&gt;
&lt;p&gt;在上图中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两个客户端依次发出消息A和消息B。&lt;/li&gt;
&lt;li&gt;在两个不同的处理群聊消息的服务器中，由于种种原因，反倒是消息B比消息A先到。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从上面可以看出，群聊消息乱序的原因在于：同一个群聊的消息，最后被分派到了两个不同的逻辑服务器上处理。&lt;/p&gt;
&lt;p&gt;还是继续沿用上面生成消息序列号的思路：如果是同一个聊天频道的消息，就放在一起处理。因此可以变成下图中的处理方式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191013-im-msg-out-of-order/group-msg-2.png&#34; alt=&#34;group-msg-2&#34; title=&#34;group-msg-2&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，根据群聊消息的群ID来选择逻辑服务器，这样同一个群的消息都能落在同一个服务器中来处理了。&lt;/p&gt;
&lt;p&gt;可以看到，这里并不需要使用一个“分布式唯一递增ID”这样的组件来产生ID，因为这里的问题简化成了：只需要该消息序列号在所在的逻辑服务器处理的聊天频道中唯一且递增就可以了。问题的重新分析和定义，让这个处理变得简单了很多。&lt;/p&gt;
&lt;h2 id=&#34;网络乱序的处理&#34;&gt;网络乱序的处理&lt;/h2&gt;
&lt;p&gt;接着处理由于网络原因导致的乱序，TCP协议中也有类似处理网络乱序的手段，简单来说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TCP协议栈中有缓冲区缓存收到的数据。&lt;/li&gt;
&lt;li&gt;发送端使用序列号ACK来确认接收端收到的数据，比如1、2、3三个序列号的数据，如果先接收到1，此时发送端会收到ACK 1的消息，但是在这之后如果消息3先于消息2被接收端收到，此时发送端仍然会ACK消息1，表示消息3这条消息是乱序的。&lt;/li&gt;
&lt;li&gt;有了缓冲区和确认序列号，就知道哪些数据可以由协议栈提供给应用层。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191013-im-msg-out-of-order/tcp-stack.png&#34; alt=&#34;tcp-stack&#34; title=&#34;tcp-stack&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接收方TCP协议栈中依次存有消息1和3，而消息2还未接收到。&lt;/li&gt;
&lt;li&gt;消息1被发送方确认，此时消息1可以提供给应用层。&lt;/li&gt;
&lt;li&gt;由于消息2没有接收到，因此消息3是乱序消息，不能提供给应用层。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从中得到的启发是：收发队列是可以有发送者来掌控的，发送者知道消息的顺序，虽然不能保证消息收发的前后顺序，但是由于引入了缓冲区，只有被确认的消息才可以被消费，这样可以通过发送者的ACK确认，来保证消息的顺序消费。&lt;/p&gt;
&lt;p&gt;以上的思路，可以沿用到网络乱序消息的处理中。&lt;/p&gt;
&lt;h1 id=&#34;最终方案&#34;&gt;最终方案&lt;/h1&gt;
&lt;p&gt;综合以上的分析，消息乱序问题可以使用下面的方式来解决。&lt;/p&gt;
&lt;h2 id=&#34;客户端消息缓存队列&#34;&gt;客户端消息缓存队列&lt;/h2&gt;
&lt;p&gt;客户端内部，维持一个缓存消息的队列，每个消息都有对应的消息序列号，收到消息之后需要与网关进行确认，以此确认这条消息是否是按序接收的消息，只有这样的消息才能提供给应用层消费。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20191013-im-msg-out-of-order/cs-msg-queue.png&#34; alt=&#34;cs-msg-queue&#34; title=&#34;cs-msg-queue&#34;&gt;&lt;/p&gt;
&lt;p&gt;在上图中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消息序列号格式为：逻辑服务器ID-频道ID-频道内唯一且递增ID，因此上图中的消息，对应的逻辑服务器ID为1，频道ID为2。后面的描述为了方便仅使用频道内ID。&lt;/li&gt;
&lt;li&gt;客户端收到消息序号为101的消息，此时客户端会ACK和网关进行消息确认。由于101之前的消息都已经被确认过了，所以网关应答ACK 101，这意味着在这个序列号可以直接提供给应用层进行消息。&lt;/li&gt;
&lt;li&gt;客户端收到消息序号为103的消息，此时客户端会ACK和网关进行消息确认。由于在这个消息之前的102消息并没有得到ACK，因此网关应答ACK 101，这意味着通知客户端此时能提交给应用层消息的消息仍然还是101。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;消息序列号与逻辑服务器切换&#34;&gt;消息序列号与逻辑服务器切换&lt;/h2&gt;
&lt;p&gt;消息序列号由：逻辑服务器ID、频道ID、频道内唯一且递增ID组成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;逻辑服务器ID：可以组合服务所在的hostname、进程号、监听端口号来生成逻辑服务器ID。&lt;/li&gt;
&lt;li&gt;频道ID：由于聊天频道仅仅和参与聊天者相关，因此单聊频道可以组合参与聊天的两端客户端ID来生成频道ID，而群聊ID则使用群ID生成频道ID。&lt;/li&gt;
&lt;li&gt;频道内唯一且递增ID：这个值甚至可以不用去落盘保存，只需要每次聊天逻辑服务器针对频道ID对应一个与之对应的递增ID即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当处理该消息的逻辑服务器发生变化时，逻辑服务器ID也随之发生变化。此时，无论是网关还是客户端，一旦发现与某个客户端建立通信维持的消息缓存队列其逻辑服务器ID发生了变化，以前缓存的消息都将被丢弃重新进行通信。&lt;/p&gt;
&lt;p&gt;如在上面的图中，接收完毕序列号为1-2-103的消息之后，逻辑服务器宕机，此时客户端的聊天服务由另一台服务器进行处理，其逻辑服务器ID变成了2，频道ID变成3。此时网关检测到收发的消息中，逻辑服务器ID与频道ID发生了变化，因此会清空之前的消息缓存，并且通知客户端清空消息缓存，重新以这个逻辑服务器ID与频道ID的消息进行通信。这也就意味着101之后的消息需要重新进行收发确认，才能提供给客户端应用层进行消息了。&lt;/p&gt;
&lt;h1 id=&#34;完整示例&#34;&gt;完整示例&lt;/h1&gt;
&lt;p&gt;下面以一个完整的流程作为例子结束这篇文章。&lt;/p&gt;
&lt;h2 id=&#34;客户端收到1-2-101序列号的消息&#34;&gt;客户端收到1-2-101序列号的消息&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;客户端向服务器应答收到1-2-101序列号的消息。&lt;/li&gt;
&lt;li&gt;网关层判断在这个序列号之前的消息已经全部传输成功了，通知逻辑服务器客户端已经接收到这条消息。&lt;/li&gt;
&lt;li&gt;逻辑服务器收到网关的消息之后，修改存储层该消息为已读消息，这样下次就不会再发这条消息给客户端了，然后向网关应答这条消息。&lt;/li&gt;
&lt;li&gt;网关应答客户端，ACK 1-2-101。&lt;/li&gt;
&lt;li&gt;客户端收到ACK 1-2-101消息之后，知道这条消息被服务器认为是按序的消息，可以提供给上层应用消费。&lt;/li&gt;
&lt;li&gt;消费完毕之后，客户端消息缓存队列就可以删除这条消息了。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;客户端收到1-2-103序列号的消息&#34;&gt;客户端收到1-2-103序列号的消息&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;客户端向服务器应答收到1-2-103序列号的消息。&lt;/li&gt;
&lt;li&gt;网关层判断这个序列号之前的1-2-102消息客户端还没有收到，因此既不会同步这条消息给逻辑服务器，也不会ACK这条消息的序列号，只会继续ACK上一条消息序列号即1-2-101。&lt;/li&gt;
&lt;li&gt;客户端收到这条消息的ACK，说明1-2-103序列号的消息既不能提供给业务层消费，也不能删除。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;逻辑服务器发生切换&#34;&gt;逻辑服务器发生切换&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;逻辑服务器发生切换，此时逻辑服务器ID变成了2。查询向这个客户端的这个聊天频道同步的消息中，拿出未读消息中的最早的消息，构建其序列号2-2-200，发送给网关。&lt;/li&gt;
&lt;li&gt;网关收到逻辑服务器的消息，发现逻辑服务器ID已经发生了变化，遂将之前还没有删除的消息1-2-102和1-2-103从消息队列中删除，并且转发2-2-200消息给客户端。&lt;/li&gt;
&lt;li&gt;客户端收到2-2-200消息之后，同样判断逻辑服务器ID已经发生了变化，将之前缓存但是还未提供给业务层消息的消息1-2-103删除。&lt;/li&gt;
&lt;li&gt;接着客户端就是走前面的ACK流程向服务器来确认消息的顺序了。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>IM服务器设计-网关接入层</title>
      <link>https://www.codedump.info/post/20190818-im-msg-gate/</link>
      <pubDate>Sun, 18 Aug 2019 16:55:17 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20190818-im-msg-gate/</guid>
      
      <description>&lt;p&gt;IM服务系列文章：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190608-im-design-base/&#34;&gt;IM服务器设计-基础&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20190608-im-msg-storage/&#34;&gt;IM服务器设计-消息存储&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;网关接入层负责维护与客户端之间的长连接，由于它是唯一一个与客户端进行直接通信的服务入口，维护着大量的客户端连接，其设计原则应该满足：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;安全&lt;/li&gt;
&lt;li&gt;稳定&lt;/li&gt;
&lt;li&gt;快速&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体来说，需要考虑不少的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用什么数据结构保存与客户端的连接？&lt;/li&gt;
&lt;li&gt;如何清除死链？&lt;/li&gt;
&lt;li&gt;在网关宕机的情况下如何容错？&lt;/li&gt;
&lt;li&gt;服务如何降级？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下具体展开。&lt;/p&gt;
&lt;h1 id=&#34;基础设计&#34;&gt;基础设计&lt;/h1&gt;
&lt;p&gt;简而言之，网关内部维护着一个map，其中保存着客户端相关的ID与对应连接的映射关系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190818-im-msg-gate/map.png&#34; alt=&#34;map&#34; title=&#34;map&#34;&gt;&lt;/p&gt;
&lt;p&gt;内部服务需要应答客户端时，经历如下步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;到redis中查询路由信息，即客户端连接到了哪个网关，将消息发送给该网关。&lt;/li&gt;
&lt;li&gt;网关服务在上面的map中找到对应的客户端连接，将消息发送给客户端。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;死链的处理&#34;&gt;死链的处理&lt;/h2&gt;
&lt;p&gt;由于网关上维护着大量的客户端连接，需要通过收发心跳报的方式检查死链，具体做法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网关针对每个连上的连接，都创建一个定时器。&lt;/li&gt;
&lt;li&gt;网关跟客户端的每次交互之后，网关都对应的更新一下该客户端的心跳时间为当前时间。&lt;/li&gt;
&lt;li&gt;客户端内部同样也维护一个定时器，每次定时器超时时，判断当前是否已经有一段时间没有跟网关通信了，此时将发出心跳消息进行保活。&lt;/li&gt;
&lt;li&gt;当该每个定时器到期时，检查客户端的心跳时间距离当前时间已经超过一个阈值了，那么将认为该客户端已经失连，将清除掉该连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要注意的是，客户端的定时器应该小于网关层给每个连接加上的定时器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190818-im-msg-gate/keepalive.png&#34; alt=&#34;keepalive&#34; title=&#34;keepalive&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;容错设计&#34;&gt;容错设计&lt;/h1&gt;
&lt;p&gt;网关有可能宕机，此时要考虑到这种情况下的容错处理。&lt;/p&gt;
&lt;p&gt;这里的原则有两条：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端一旦发现前面连接的网关宕机，将尝试重连。&lt;/li&gt;
&lt;li&gt;内部服务要通过网关层应答给客户端的消息，一旦发现由于网关宕机而无法发出，将直接丢弃，由客户端重新尝试重连。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下来详细解释一下这两个原则。&lt;/p&gt;
&lt;h2 id=&#34;客户端重连&#34;&gt;客户端重连&lt;/h2&gt;
&lt;p&gt;客户端内部维护着一个发出消息的消息队列，仅在收到服务器的处理应答之后才可以从其中清除相应的消息。注意，这里每个客户端的消息ID需要做到严格递增。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190818-im-msg-gate/messagequeue.png&#34; alt=&#34;messagequeue&#34; title=&#34;messagequeue&#34;&gt;&lt;/p&gt;
&lt;p&gt;比如，上图中发出但是未收到应答的消息有三条，消息ID依次递增，分别是100、101、102。此时如果收到服务器应答消息101已经被确认处理，那么在这个序号之前的消息100以及101都可以被认为已经被服务器正常接收并且处理完毕，此时可以从消息队列中删除掉序号101之前的消息了。&lt;/p&gt;
&lt;p&gt;反之，客户端同时还维护另外一个定时器，一段时间没有收到连接的网关消息时，将向网关发出心跳消息，如果仍然没有回复则认为网关出现异常，将重新走正常的登录流程尝试选择另外一台网关登录。重连之后，将重新发送消息队列中已经存在的消息。&lt;/p&gt;
&lt;h2 id=&#34;重连策略&#34;&gt;重连策略&lt;/h2&gt;
&lt;p&gt;当一台网关出现问题需要客户端进行重连时，还需要考虑到不要因为重连问题导致了其他网关服务器也受影响，产生雪崩效应，此时还需要考虑以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;打散重连时间：需要进行重连的客户端，在一个时间范围内选择一个随机的时间，这样将这些客户端的重连时间打散，不至于一下子都连接上来。&lt;/li&gt;
&lt;li&gt;指数退避：一次重连不上时，客户端还需要再次尝试进行多次重连，然而重连的时间需要像TCP协议那样在阻塞恢复时做指数退避，即第一次重连时间是1秒后，第二次2秒后，第三次4秒后，等等。这个策略也是为了避免由于重连导致的服务雪崩。&lt;/li&gt;
&lt;li&gt;服务器保护：上面两条是客户端的重连策略，然而服务器自身也需要进行保护，当服务器判断自己当前的负载到一定程度时，将拒绝客户端的连接请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;内部服务丢弃应答消息&#34;&gt;内部服务丢弃应答消息&lt;/h2&gt;
&lt;p&gt;同样的，内部服务也只是通过网关层与客户端进行通信，当处理了一些消息之后需要应答客户端，此时发现对应的网关已经宕机，那么应该丢弃掉这些应答消息，等待客户端重连之后重新将前面没有收到应答的消息发出来。&lt;/p&gt;
&lt;p&gt;如果是这个处理原则的话，对应的就需要服务器的逻辑中做到“幂等性（idempotent）”了，即同一个操作，一次请求与多次请求的结果是一样的。比如，逻辑服务器可以通过客户端的消息ID来判断这条消息之前是否已经被处理过，如果是的话可以直接忽略处理应答处理即可。&lt;/p&gt;
&lt;h1 id=&#34;服务保证&#34;&gt;服务保证&lt;/h1&gt;
&lt;p&gt;每个网关服务器可以容纳的长连接总数是固定的，到了一定程度系统资源就消耗的差不多了，应答的延迟也提高了。所以，网关层还需要考虑到服务的可用性。&lt;/p&gt;
&lt;p&gt;比如，可以向管理网关的服务器上报如下数据：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当前维护的连接数量。&lt;/li&gt;
&lt;li&gt;当前应答延迟指标，90%的延迟到多少，99%的应答延迟到多少，等等。&lt;/li&gt;
&lt;li&gt;当前系统资源的消耗情况，比如CPU占用、内存占用等等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样，可以有依据来判断该网关是否还能继续接收新的连接，如果不能接收连接可以返回一批当前可用的其他网关服务列表给客户端重新发起连接，同时将当前不可用的网关从返回给客户端的网关列表中删除，这样下次就不会再来这个网关进行连接。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190818-im-msg-gate/qos.png&#34; alt=&#34;qos&#34; title=&#34;qos&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图中，有如下步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网关都向网关管理服务上报自己当前的服务状态，管理服务发现网关A已经接近服务极限，此时将通知网关A此时不能再接收新的连接，同时还告知当前可用的网关B和C地址。&lt;/li&gt;
&lt;li&gt;客户端向网关A发起请求，此时网关A拒绝该连接请求，并且返回网关B和C的服务列表给客户端。&lt;/li&gt;
&lt;li&gt;客户端选择网关C进行连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，这实际上是“服务降级”的一种做法。&lt;/p&gt;
&lt;p&gt;在某台网关服务降级之后，还可以针对具体的服务来进行优先级排列，即在当前负载的情况下，优先处理哪一类的客户端请求，而更低优先级的请求可以先不处理，比如微信在&lt;a href=&#34;https://mp.weixin.qq.com/s/uv4WkTIPvDCFlvKAEXrT2g&#34;&gt;DAGOR论文&lt;/a&gt;中阐述了微信内部的服务优先级：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190818-im-msg-gate/wechat.webp&#34; alt=&#34;wechat&#34; title=&#34;wechat&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>服务调用的演进历史</title>
      <link>https://www.codedump.info/post/20190629-service-history/</link>
      <pubDate>Sat, 29 Jun 2019 12:47:07 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20190629-service-history/</guid>
      
      <description>&lt;blockquote&gt;
&lt;p&gt;这是2019年给组内分享时整理的一篇服务调用演进历史的科普文。写作本文的时候，我自己最大的感受是：如果能清楚理解演化历史中的一些原则和思路，就会发现现在的变化并不新鲜。它们不是今天才有，也不会止于今天的演化。在技术大发展的今天，更多的关注本质才能让我们不至于在变化中失去方向。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个题目稍微有点大，纯粹是一篇科普文，将我所了解到的解决“服务调用”相关的技术演进历史简述一下，本文专注于演化过程中每一步的为什么（Why）和是什么（What）上面，尽量不在技术细节（How）上面做太多深入。&lt;/p&gt;
&lt;h1 id=&#34;服务的三要素&#34;&gt;服务的三要素&lt;/h1&gt;
&lt;p&gt;一般而言，一个网络服务包括以下的三个要素：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;地址：调用方根据地址访问到网络接口。地址包括以下要素：IP地址、服务端口、服务协议（TCP、UDP，etc）。&lt;/li&gt;
&lt;li&gt;协议格式：协议格式指的是该协议都有哪些字段，由接口提供者与协议调用者协商之后确定下来。&lt;/li&gt;
&lt;li&gt;协议名称：或者叫协议类型，因为在同一个服务监听端口上面，可能同时提供多种接口服务于调用方，这时候需要协议类型（名称）来区分不同的网络接口。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要说明在服务地址中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP地址提供了在互联网上找到这台机器的凭证。&lt;/li&gt;
&lt;li&gt;协议以及服务端口提供了在这台机器上找到提供服务的进程的凭证。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/service-address.png&#34; alt=&#34;service-address&#34; title=&#34;service address&#34;&gt;&lt;/p&gt;
&lt;p&gt;这都属于TCPIP协议栈的知识点，不在这里深入详述。&lt;/p&gt;
&lt;p&gt;下图中，以最简单的一个HTTP请求，来拆解请求URL中的服务要素：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/http-request.png&#34; alt=&#34;http-request&#34; title=&#34;http-request&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;http：指明使用的是哪种应用层协议，同类型的还有“https”、“ftp”等。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.abc.com&#34;&gt;www.abc.com&lt;/a&gt;：域名地址，最终会由DNS域名解析服务器解析成数字的IP地址。&lt;/li&gt;
&lt;li&gt;8080：前面解析成数字化的IP地址之后，就可以访问到具体提供服务的机器上，但是上面提供服务的进程可能有很多，这时候就需要端口号来告诉协议栈到底是访问哪个进程提供的服务了。&lt;/li&gt;
&lt;li&gt;hello：该服务进程中，可能提供多个接口供访问，所以需要接口名+协议（即前面的http）告诉进程访问哪个协议的哪个接口。&lt;/li&gt;
&lt;li&gt;msg=world：不同的接口，需要的参数不同，最后跟上的查询参数（query param）告诉服务请求该接口服务时传入的参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上，简单的把网络服务的几个要素进行了描述。&lt;/p&gt;
&lt;p&gt;这里还需要对涉及到服务相关的一些名词做解释。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务实例：服务对应的IP地址加端口的简称。需要访问服务的时候，需要先寻址知道该服务每个运行实例的地址加端口，然后才能建立连接进行访问。&lt;/li&gt;
&lt;li&gt;服务注册：某个服务实例宣称自己提供了哪些服务，即某个IP地址+端口都提供了哪些服务接口。&lt;/li&gt;
&lt;li&gt;服务发现：调用方通过某种方式找到服务提供方，即知道服务运行的IP地址加端口。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;基于ip地址的调用&#34;&gt;基于IP地址的调用&lt;/h1&gt;
&lt;p&gt;最初的网络服务，通过原始的IP地址暴露给调用者。这种方式有以下的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP地址是难于记忆并且无意义的。&lt;/li&gt;
&lt;li&gt;另外，从上面的服务三要素可以看到，IP地址其实是一个很底层的概念，直接对应了一台机器上的一个网络接口，如果直接使用IP地址进行寻址，更换机器就变的很麻烦。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“尽量不使用过于底层的概念来提供服务”，是这个演化流程中的重要原则，好比在今天已经很少能够看到直接用汇编语言编写代码的场景了，取而代之的，就是越来越多的抽象，本文中就展现了服务调用这一领域在这个过程中的演进流程。&lt;/p&gt;
&lt;p&gt;在现在除非是测试阶段，否则已经不能直接以IP地址的形式将服务提供出去了。&lt;/p&gt;
&lt;h1 id=&#34;域名系统&#34;&gt;域名系统&lt;/h1&gt;
&lt;p&gt;前面的IP地址是给主机做为路由器寻址的数字型标识，并不好记忆。此时产生了域名系统，与单纯提供IP地址相比，域名系统由于使用有意义的域名来标识服务，所以更容易记忆。另外，还可以更改域名所对应的IP地址，这为变换机器提供了便利。有了域名之后，调用方需要访问某个网络服务时，首先到域名地址服务中，根据DNS协议将域名解析为相应的IP地址，再根据返回的IP地址来访问服务。&lt;/p&gt;
&lt;p&gt;从这里可以看到，由于多了一步到域名地址服务查询映射IP地址的流程，所以多了一步解析，为了减少这一步带来的影响，调用方会缓存解析之后的结果，在一段时间内不过期，这样就省去了这一步查询的代价。&lt;/p&gt;
&lt;h1 id=&#34;协议的接收与解析&#34;&gt;协议的接收与解析&lt;/h1&gt;
&lt;p&gt;以上通过域名系统，已经解决了服务IP地址难以记忆的问题，下面来看协议格式解析方面的演进。&lt;/p&gt;
&lt;p&gt;一般而言，一个网络协议包括两部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;协议包头：这里存储协议的元信息（meta infomation），其中可能会包括协议类型、报体长度、协议格式等。需要说明的是，包头一般为固定大小，或者有明确的边界（如HTTP协议中的\r\n结束符），否则无法知道包头何时结束。&lt;/li&gt;
&lt;li&gt;协议包体：具体的协议内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;无论是HTTP协议，又或者是自定义的二进制网络协议，大体都由这两部分组成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/protocol-format.png&#34; alt=&#34;protocol-format&#34; title=&#34;protocol format&#34;&gt;&lt;/p&gt;
&lt;p&gt;由于很多时候不能一口气接收完毕客户端的协议数据，因此在接收协议数据时，一般采用状态机来做协议数据的接收：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/protocol-statemachine.png&#34; alt=&#34;protocol-statemachine&#34; title=&#34;protocol statemachine&#34;&gt;&lt;/p&gt;
&lt;p&gt;接收完毕了网络数据，在协议解析方面却长期停滞不前。一个协议，有多个字段（field），而这些不同的字段有不同的类型，简单的raw类型（如整型、字符串）还好说，但是遇到复杂的类型如字典、数组等就比较麻烦。&lt;/p&gt;
&lt;p&gt;当时常见的手段有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用json或者xml这样的数据格式。好处是可视性强，表达起上面的复杂类型也方便，缺陷是容易被破解，传输过去的数据较大。&lt;/li&gt;
&lt;li&gt;自定义二进制协议。每个公司做大了，在这一块难免有几个类似的轮子。笔者见过比较典型的是所谓的TLV格式（Type-Length-Value），自定义二进制格式最大的问题出现在协议联调与协商的时候，由于可视性比较弱，有可能这边少了一个字段那边多了一个字段，给联调流程带来麻烦。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面的问题一直到Google的Protocol Buffer（以下简称PB）出现之后才得到很大的改善。PB出现之后，也有很多类似的技术出现，如Thrift、MsgPack等，不在这里阐述，将这一类技术都以PB来描述。&lt;/p&gt;
&lt;p&gt;与前面的两种手段相比，PB具有以下的优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用proto格式文件来定义协议格式，proto文件是一个典型的DSL（domain-specific language）文件，文件中描述了协议的具体格式，每个字段都是什么类型，哪些是可选字段哪些是必选字段。有了proto文件之后，C\S两端是通过这个文件来进行协议的沟通交流的，而不是具体的技术细节。&lt;/li&gt;
&lt;li&gt;PB能通过proto文件生成各种语言对应的序列化反序列化代码，给跨语言调用提供了方便。&lt;/li&gt;
&lt;li&gt;PB自己能够对特定类型进行数据压缩，减少数据大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/pb.png&#34; alt=&#34;pb&#34; title=&#34;pb&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;服务网关&#34;&gt;服务网关&lt;/h1&gt;
&lt;p&gt;有了前面的演化之后，写一个简单的单机服务器已经不难。然而，当随着访问量的增大，一台机器已经不足以支撑所有的请求，此时就需要横向扩展多加一些业务服务器。&lt;/p&gt;
&lt;p&gt;而前面通过域名访问服务的架构就遇到了问题：如果有多个服务实例可以提供相同的服务，那么势必需要在DNS的域名解析中将域名与多个地址进行绑定。这样的方案就有如下的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何检查这些实例的健康情况，同时在发现出现问题的时候增删服务实例地址？即所谓的服务高可用问题。&lt;/li&gt;
&lt;li&gt;把这些服务实例地址都暴露到外网，会不会涉及到安全问题？即使可以解决安全问题，那么也需要每台机器都做安全策略。&lt;/li&gt;
&lt;li&gt;由于DNS协议的特点，增删服务实例并不是实时的，有时候会影响到业务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了解决这些问题，就引入了反向代理网关这一组件。它提供如下的功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负载均衡功能：根据某些算法将请求分派到服务实例上。&lt;/li&gt;
&lt;li&gt;提供管理功能，可以给运维管理员增减服务实例。&lt;/li&gt;
&lt;li&gt;由于它决定了服务请求流量的走向，因此还可以做更多的其他功能：灰度引流、安全防攻击(如访问黑白名单、卸载SSL证书)等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/gateway.png&#34; alt=&#34;gateway&#34; title=&#34;gateway&#34;&gt;&lt;/p&gt;
&lt;p&gt;有四层和七层负载均衡软件，其中四层负载均衡这里介绍LVS，七层负载均衡介绍Nginx。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/tcpip.png&#34; alt=&#34;tcpip&#34; title=&#34;tcpip&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图是简易的TCPIP协议栈层次图，其中LVS工作在四层，即请求来到LVS这里时是根据四层协议来决定请求最终走到哪个服务实例；而Nginx工作在七层，主要用于HTTP协议，即根据HTTP协议本身来决定请求的走向。需要说明的是，Nginx也可以工作在四层，但是这么用的地方不是很多，可以参考nginx的stream模块。&lt;/p&gt;
&lt;h2 id=&#34;做为四层负载均衡的lvs&#34;&gt;做为四层负载均衡的LVS&lt;/h2&gt;
&lt;p&gt;（由于LVS有好几种工作模式，并不是每一种我都很清楚，以下表述仅针对Full NAT模式，下面的表述或者有误）&lt;/p&gt;
&lt;p&gt;LVS有如下的组成部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Direct Server（以下简称DS）：前端暴露给客户端进行负载均衡的服务器。&lt;/li&gt;
&lt;li&gt;Virtual Ip地址（以下简称VIP）：DS暴露出去的IP地址，做为客户端请求的地址。&lt;/li&gt;
&lt;li&gt;Direct Ip地址（以下简称DIP）：DS用于与Real Server交互的IP地址。&lt;/li&gt;
&lt;li&gt;Real Server（以下简称RS）：后端真正进行工作的服务器，可以横向扩展。&lt;/li&gt;
&lt;li&gt;Real IP地址（以下简称RIP）：RS的地址。&lt;/li&gt;
&lt;li&gt;Client IP地址（以下简称CIP）：Client的地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/lvs.png&#34; alt=&#34;lvs&#34; title=&#34;lvs&#34;&gt;&lt;/p&gt;
&lt;p&gt;客户端进行请求时，流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用VIP地址访问DS，此时的地址二元组为&amp;lt;src:CIP,dst:VIP&amp;gt;。&lt;/li&gt;
&lt;li&gt;DS根据自己的负载均衡算法，选择一个RS将请求转发过去，在转发过去的时候，修改请求的源IP地址为DIP地址，让RS看上去认为是DS在访问它，此时的地址二元组为&amp;lt;src:DIP,dst:RIP A&amp;gt;。&lt;/li&gt;
&lt;li&gt;RS处理并且应答该请求，这个回报的源地址为RS的RIP地址，目的地址为DIP地址，此时的地址二元组为&amp;lt;src:RIP A,dst:DIP&amp;gt;。&lt;/li&gt;
&lt;li&gt;DS在收到该应答包之后，将报文应答客户端，此时修改应答报文的源地址为VIP地址，目的地址为CIP地址，此时的地址二元组为&amp;lt;src:VIP,dst:CIP&amp;gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;做为七层负载均衡的nginx&#34;&gt;做为七层负载均衡的Nginx&lt;/h2&gt;
&lt;p&gt;在开始展开讨论之前，需要简单说一下正向代理和反向代理。&lt;/p&gt;
&lt;p&gt;所谓的正向代理（proxy），我的理解就是在客户端处的代理。如浏览器中的可以配置的访问某些网站的代理，就属于正向代理，但是一般而言不会说正向代理而是代理，即默认代理都是正向的。&lt;/p&gt;
&lt;p&gt;而反向代理（reverse proxy）就是挡在服务器端前面的代理，比如前面LVS中的DS服务器就属于一种反向代理。为什么需要反向代理，大体的原因有以下的考量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负载均衡：希望在这个反向代理的服务器中，将请求均衡的分发到后面的服务器中。&lt;/li&gt;
&lt;li&gt;安全：不想向客户端暴露太多的服务器地址，统一接入到这个反向代理服务器中，在这里做限流、安全控制等。&lt;/li&gt;
&lt;li&gt;由于统一接入了客户端的请求，所以在反向代理的接入层可以做更多的控制策略，比如灰度流量发布、权重控制等等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;反向代理与所谓的gateway、网关等，我认为没有太多的差异，只是叫法不同而已，做的事情都是类似的。&lt;/p&gt;
&lt;p&gt;Nginx应该是现在用的最多的HTTP 七层负载均衡软件，在Nginx中，可以通过在配置的server块中定义一个域名，然后将该域名的请求绑定到对应的Upstream中，而实现转发请求到这些Upstream的效果。&lt;/p&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;upstream hello {
       server A:11001;
       server B:11001;
}

location / {
            root   html;
            index  index.html index.htm;
            proxy_pass http://hello;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是最简单的Nginx反向代理配置，实际线上一个接入层背后可能有多个域名，如果配置变动的很大，每次域名以及对应的Upstream的配置修改都需要人工干预，效率会很慢。这时候就要提到一个叫DevOps的名词了，我的理解就是开发各种便于自动化运维工具的工程师。&lt;/p&gt;
&lt;p&gt;有了上面的分析，此时一个提供七层HTTP访问接口的服务架构大体是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/gate.png&#34; alt=&#34;gate&#34; title=&#34;gate&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;服务发现与rpc&#34;&gt;服务发现与RPC&lt;/h1&gt;
&lt;p&gt;前面已经解决单机服务器对外提供服务的大部分问题，来简单回顾：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;域名系统解决了需要记住复杂的数字IP地址的问题。&lt;/li&gt;
&lt;li&gt;PB类软件库的出现解决协议定义解析的痛点。&lt;/li&gt;
&lt;li&gt;网关类组件解决客户端接入以及服务器横向扩展等一系列问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然而一个服务，通常并不见得只由本身提供服务就可以，服务过程中可能还涉及到查询其他服务的流程，常见的如数据类服务如Mysql、Redis等，这一类供服务内调用查询的服务被成为内部的服务，通常并不直接暴露到外网去。&lt;/p&gt;
&lt;p&gt;面向公网的服务，一般都是以域名的形式提供给外部调用者，然而对于服务内部之间的互相调用，域名形式还不够，其原因在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DNS服务发现的粒度太粗，只能到IP地址级别，而服务的端口还需要用户自己维护。&lt;/li&gt;
&lt;li&gt;对于服务的健康状况的检查，DNS的检查还不够，需要运维的参与。&lt;/li&gt;
&lt;li&gt;DNS对于服务状态的收集很欠缺，而服务状态最终应该是反过来影响服务被调用情况的。&lt;/li&gt;
&lt;li&gt;DNS的变更需要人工的参与，不够智能以及自动化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上，内网间的服务调用，通常而言会自己实现一套“服务发现”类的系统，其包括以下几个组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务发现系统：用于提供服务的寻址、注册能力，以及对服务状态进行统计汇总，根据服务情况更改服务的调用情况。比如，某个服务实例的响应慢了，此时分配给该实例的流量响应的就会少一些。而由于这个系统能提供服务的寻址能力，所以一些寻址策略就可以在这里做，比如灰度某些特定的流量只能到某些特定的实例上，比如可以配置每个实例的流量权重等。&lt;/li&gt;
&lt;li&gt;一套与该服务系统搭配使用的RPC库，其提供以下功能：
&lt;ul&gt;
&lt;li&gt;服务提供方：使用RPC库注册自己的服务到服务发现系统，另外上报自己的服务情况。&lt;/li&gt;
&lt;li&gt;服务调用方：使用RPC库进行服务寻址，实时从服务发现系统那边获取最新的服务调度策略。&lt;/li&gt;
&lt;li&gt;提供协议的序列化、反序列化功能，负载均衡的调用策略、熔断限流等安全访问策略，这部分对于服务的提供方以及调用方都适用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/name-system.png&#34; alt=&#34;name-system&#34; title=&#34;name system&#34;&gt;&lt;/p&gt;
&lt;p&gt;有了这套服务发现系统以及搭配使用的RPC库之后，来看看现在的服务调用是什么样的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;写业务逻辑的，再也不用关注服务地址、协议解析、服务调度、自身服务情况上报等等与业务逻辑本身并没有太多关系的工作，专注于业务逻辑即可。&lt;/li&gt;
&lt;li&gt;服务发现系统一般还有与之搭配的管理后台界面，可以通过这里对服务的策略进行修改查看等操作。&lt;/li&gt;
&lt;li&gt;对应的还会有服务监控系统，对应的这是一台实时采集服务数据进行计算的系统，有了这套系统服务质量如何一目了然。&lt;/li&gt;
&lt;li&gt;服务健康状态的检查完全自动化，在状况不好的时候对服务进行降级处理，人工干预变少，更加智能以及自动化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在服务的架构又演进成了这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/arch.png&#34; alt=&#34;arch&#34; title=&#34;arch&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;servicemesh&#34;&gt;ServiceMesh&lt;/h1&gt;
&lt;p&gt;架构发展到上面的程度，实际上已经能够解决大部分的问题了。这两年又出现了一个很火的概念：ServiceMesh，中文翻译为“服务网格”，来看看它又能解决什么问题。&lt;/p&gt;
&lt;p&gt;前面的服务发现系统中，需要一个与之配套的RPC库，然而这又会有如下的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果需要支持多语言，该怎么做？每个语言实现一个对应的RPC库吗？&lt;/li&gt;
&lt;li&gt;库的升级很麻烦，比如RPC库本身出了安全漏洞，比如需要升级版本，一般推动业务方去做这个升级是很难的，尤其是系统做大了之后。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，由于RPC库是嵌入到进程之中的组件，所以以上问题很麻烦，于是就想出了一个办法：将原先的一个进程拆分成两个进程，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/servicemesh.png&#34; alt=&#34;servicemesh&#34; title=&#34;servicemesh&#34;&gt;&lt;/p&gt;
&lt;p&gt;在服务mesh化之前，服务调用方实例通过自己内部的RPC库来与服务提供方实例进行通信。&lt;/p&gt;
&lt;p&gt;在服务mesh化之后，会与服务调用方同机部署一个local Proxy也就是ServiceMesh的proxy，此时服务调用的流量会先走到这个proxy，再由它完成原先RPC库响应的工作。至于如何实现这个流量的劫持，答案是采用iptables，将特定端口的流量转发到proxy上面即可。&lt;/p&gt;
&lt;p&gt;有了这一层的分拆，将业务服务与负责RPC库作用的Proxy分开来，上面的两个痛点问题就变成了对每台物理机上面的mesh proxy的升级维护问题，多语言也不是问题了，因为都是通过网络调用完成的RPC通信，而不是进程内使用RPC库。&lt;/p&gt;
&lt;p&gt;然而这个方案并不是什么问题都没有的，最大的问题在于，多了这一层的调用之后，势必有影响原来的响应时间。&lt;/p&gt;
&lt;p&gt;截止目前（2019.6月），ServiceMesh仍然还是一个概念大于实际的产品。&lt;/p&gt;
&lt;p&gt;从上面的演进历史可以看到，所谓的“中间层理论”，即“Any problem in computer science can be solved by another layer of indirection（计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决）”在这个过程中被广泛使用，比如为了解决IP地址难于记忆的问题，引入了域名系统，比如为了解决负载均衡问题引入了网关，等等。然而每引入一个中间层，势必带来另外的影响，比如ServiceMesh多一次到Proxy的调用，如何权衡又是另外的问题了。&lt;/p&gt;
&lt;p&gt;另外，回到最开始的服务三要素中，可以看到整个演化的历史也是逐渐屏蔽了下层组件的流程，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;域名的出现屏蔽了IP地址。&lt;/li&gt;
&lt;li&gt;服务发现系统屏蔽协议及端口号。&lt;/li&gt;
&lt;li&gt;PB类序列化库屏蔽了使用者自己对协议的解析。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，演进流程让业务开发者更加专注在业务逻辑上，这类的演进流程不只发生在今天，也不会仅仅发生在今天，未来类似的演进也将再次发生。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>IM服务器设计-消息存储</title>
      <link>https://www.codedump.info/post/20190608-im-msg-storage/</link>
      <pubDate>Sat, 08 Jun 2019 20:18:47 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20190608-im-msg-storage/</guid>
      
      <description>&lt;p&gt;这部分专门讲述IM消息存储的设计。消息存储的难度在于，要考虑以下的场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;离线消息存储。即发送消息时对方不在线该怎么处理。&lt;/li&gt;
&lt;li&gt;单聊、群聊消息。&lt;/li&gt;
&lt;li&gt;随着用户量越来越大，应该以后如何扩展。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;读扩散-vs-写扩散&#34;&gt;读扩散 VS 写扩散&lt;/h1&gt;
&lt;p&gt;消息同步模型中，有写扩散和读扩散这两种模型。在开始讨论之前需要先了解两个相关的概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收件箱（inbox）：该用户收到的消息。&lt;/li&gt;
&lt;li&gt;发件箱（outbox）：该用户发出的消息。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;写扩散push&#34;&gt;写扩散（push）&lt;/h2&gt;
&lt;p&gt;写扩散就是经常说的push模式，即每个消息都直接发送到该用户的收件箱中。其优缺点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：读优化，用户每次只需要去读取自己收件箱中的消息即可。&lt;/li&gt;
&lt;li&gt;缺点：写很重，如果这个消息是一条群消息，那么一个群成员发送出去的消息将拷贝到所有其余群成员的收件箱中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-msg-storage/im-msg-push.png&#34; alt=&#34;im-msg-push&#34; title=&#34;im msg push&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;读扩散pull&#34;&gt;读扩散（pull）&lt;/h2&gt;
&lt;p&gt;读扩散就是pull模式，用户每次到消息发送者的发件箱去拉取消息，优缺点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：写优化，每次发送的消息只需要写到一个地方，由收件者自己去拉取消息即可。&lt;/li&gt;
&lt;li&gt;缺点：读操作很重，假设一个用户有一千个好友，重新登录时需要拉取这些好友所有的离线消息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-msg-storage/im-msg-pull.png&#34; alt=&#34;im-msg-pull&#34; title=&#34;im msg pull&#34;&gt;&lt;/p&gt;
&lt;p&gt;最终选择的是以pull模式为主的模式，理由在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IM业务属于『写多读少』类型的业务，如果使用push模式，将造成消息的大量冗余。&lt;/li&gt;
&lt;li&gt;pull模式读操作较重的缺陷可以通过其他方式来优化解决。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面来看具体的设计。&lt;/p&gt;
&lt;h1 id=&#34;表设计&#34;&gt;表设计&lt;/h1&gt;
&lt;p&gt;在数据库设计中，仅使用一个发送消息表来存储消息的具体内容，而另外有一个消息接收表用来存储消息的ID信息而不是具体内容，这样用户查询消息时，大体流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先拉取接收消息表中的信息。&lt;/li&gt;
&lt;li&gt;根据接收消息表中的ID以及发送者ID信息到发送信息表来具体查询消息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-msg-storage/im-msg.png&#34; alt=&#34;im-msg&#34; title=&#34;im msg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;用户发送消息表&#34;&gt;用户发送消息表&lt;/h2&gt;
&lt;p&gt;无论是单聊还是群聊消息，都使用这个表来存储发送出去的消息。&lt;/p&gt;
&lt;p&gt;im_message_send（msg_id,msg_from,msg_to,msg_seq,msg_content,send_time,msg_type）&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;msg_id：消息ID。&lt;/li&gt;
&lt;li&gt;msg_from：消息发送者UID。&lt;/li&gt;
&lt;li&gt;msg_to：消息接收者。如果是单聊消息那么就是用户UID，如果是群聊消息就是群ID。&lt;/li&gt;
&lt;li&gt;msg_seq：客户端发送消息时带上的序列号，主要用于消息排重以及通知客户端消息发送成功之用。&lt;/li&gt;
&lt;li&gt;msg_content：消息内容。&lt;/li&gt;
&lt;li&gt;send_time：消息发送时间。&lt;/li&gt;
&lt;li&gt;msg_type：消息类型，如单聊、群聊消息等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;用户接收消息表&#34;&gt;用户接收消息表&lt;/h2&gt;
&lt;p&gt;im_message_recieve（id,msg_from,msg_to,msg_id,flag）&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;id：这个表的ID，自增。&lt;/li&gt;
&lt;li&gt;msg_from：消息发送者ID。&lt;/li&gt;
&lt;li&gt;msg_to：消息接收者ID。&lt;/li&gt;
&lt;li&gt;msg_id：消息ID，对应发送消息表中的ID。&lt;/li&gt;
&lt;li&gt;flag：标志位，表示该消息是否已读。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接收消息表的信息并没有很多，因为主体部分如消息内容、发送消息时间等都在发送消息表中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-msg-storage/im-msg-table.png&#34; alt=&#34;im-msg-table&#34; title=&#34;im msg table&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;分库分表及访问策略&#34;&gt;分库分表及访问策略&lt;/h1&gt;
&lt;p&gt;发送消息表，根据msg_from字段做为分库分表的依据，而接收消息表则使用msg_to字段做为分库分表的依据。&lt;/p&gt;
&lt;p&gt;另外，还需要添加缓存将群聊消息进行缓存，缓存的key为msg_to和msg_id的组合，这样查询具体群聊消息的时候就可以根据组ID来查询一条具体的消息了。&lt;/p&gt;
&lt;p&gt;以上需要对存储之上的业务层完全透明，因此加上一个db proxy来处理消息的读写，除了应付这套流程以外，proxy的引入还有这些好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;无状态，可以横向扩展。&lt;/li&gt;
&lt;li&gt;下面的存储服务扩缩容的时候，proxy可以感知到变化，而这些对上面的应用层而言都是透明的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有了这一层proxy之后，消息的读写流程如下。&lt;/p&gt;
&lt;h2 id=&#34;写消息&#34;&gt;写消息&lt;/h2&gt;
&lt;p&gt;收到用户发送过来的消息，db proxy做如下处理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据msg_from查询到哪个存储服务存储该发送消息，写入消息，同时得到写入成功之后的消息ID。&lt;/li&gt;
&lt;li&gt;如果这条消息是一个群聊消息，此时根据群ID以及第一步返回的消息ID，写一条键为群ID以及消息ID组合，而值为消息内容的缓存数据到缓存中。&lt;/li&gt;
&lt;li&gt;根据msg_to查询是哪个存储服务存储该接收消息，写入这部分信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-msg-storage/im-msg-write.png&#34; alt=&#34;im-msg-write&#34; title=&#34;im msg write&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;读消息&#34;&gt;读消息&lt;/h2&gt;
&lt;p&gt;读消息的过程反之：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据msg_to查询是哪个存储服务存储该接收消息，查询到该消息之后就知道对应的msg_id。&lt;/li&gt;
&lt;li&gt;根据第一步查询到msg_from以及msg_id来去发送消息表中查询消息，如果是群聊消息的话，可以首先组合这两个字段到缓存中查询，查询不到再查询数据库。&lt;/li&gt;
&lt;li&gt;如果上面第二步中的群聊消息，在缓存中没有查询到，需要一个策略来向缓存中写入一份该群聊消息。&lt;/li&gt;
&lt;li&gt;如果接收到用户已读该消息的应答，那么还需要再次根据msg_to查询该消息将flag字段变成用户已读状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;登录之后拉取离线消息的优化&#34;&gt;登录之后拉取离线消息的优化&lt;/h1&gt;
&lt;p&gt;在第一篇&lt;a href=&#34;https://www.codedump.info/post/20190608-im-design-base/&#34;&gt;基础篇&lt;/a&gt;中已经给出了拉取离线消息的基本流程，在这里还需要进行一些优化。&lt;/p&gt;
&lt;p&gt;在实际的应用中，离线的群聊消息并不是需要每次登录都完整拉取下来的，因此这里可以做一个优化：登录时针对群聊消息仅拉取每个群的未读消息数量，用于客户端的展示，而实际消息内容的加载，可以等到用户真的点到这个群查看消息或者可以后台加载，总之不影响登录主流程即可。&lt;/p&gt;
&lt;p&gt;细化了消息存储部分之后的整体架构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-msg-storage/im-arch.png&#34; alt=&#34;im-arch&#34; title=&#34;im arch&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;采用pull模式为主的消息发送存储方式。&lt;/li&gt;
&lt;li&gt;为了解决pull模式的读消息较重的问题，引入了以下组件：
&lt;ul&gt;
&lt;li&gt;db proxy来解决整个读写逻辑，这部分对业务层完全透明，同时proxy可以感知下面存储服务的扩缩容变更等。&lt;/li&gt;
&lt;li&gt;群聊消息根据消息ID以及群ID写入缓存一份，不必每次都到存储服务器上面拉取消息。&lt;/li&gt;
&lt;li&gt;使用另一个消息计数表来存储未读消息数量，登录之后群聊消息仅展示未读消息数量，这部分群聊消息可以延迟拉取或者后台拉取不影响客户端登录主流程。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>IM服务器设计-基础</title>
      <link>https://www.codedump.info/post/20190608-im-design-base/</link>
      <pubDate>Sat, 08 Jun 2019 11:09:10 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20190608-im-design-base/</guid>
      
      <description>&lt;p&gt;IM做为非常经典的服务器系统，其设计时候的考量具备代表性，所以这一次花几个篇幅讨论其相关设计。&lt;/p&gt;
&lt;p&gt;主要内容相当部分参考了 &lt;a href=&#34;http://www.52im.net/thread-812-1-1.html&#34;&gt;一套海量在线用户的移动端IM架构设计实践分享&lt;/a&gt;一文，在此之上补充了更好的消息存储设计以及集群设计。&lt;/p&gt;
&lt;h1 id=&#34;整体架构&#34;&gt;整体架构&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-arch.png&#34; alt=&#34;im-arch&#34; title=&#34;im arch&#34;&gt;&lt;/p&gt;
&lt;p&gt;以上架构图中，分为几个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端：支持IOS、Android系统。&lt;/li&gt;
&lt;li&gt;接入层：负责维护与客户端之间的长连接。&lt;/li&gt;
&lt;li&gt;逻辑层：负责IM系统中各逻辑功能的实现。&lt;/li&gt;
&lt;li&gt;存储层：存储IM系统相关的数据，主要包括Redis缓存系统（用于保存用户状态及路由数据）、消息数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上图中几部分的交互如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端通过gate接入IM服务器。在这里，客户端与gate之间保持TCP长连接，客户端使用DNS查询域名返回最近的gate地址进行连接。&lt;/li&gt;
&lt;li&gt;Gate的作用：保持与客户端之间的长连接，将请求数据转发给后面的逻辑服务LogicServer。LogicServer最上面是一个消息路由服务Router，根据请求的类型转发到后面具体的逻辑服务器。其中c代表客户端，s代表服务器，g代表群组，因此比如c2c服务就是处理客户端之间消息的服务器，而auth服务是处理客户端登录请求的服务器。&lt;/li&gt;
&lt;li&gt;逻辑类服务器与存储层服务打交道，其中：redis用于存储用户在线状态、用户路由数据（用户路由数据就是指用户在哪个gate服务上维护长连接），而DB用于存储用户的消息数据，这部分留待下一部分讲解。&lt;/li&gt;
&lt;li&gt;以上的接入层、逻辑层由于本身不存储状态，因此都可以进行横向扩展。看似Gate维护着长连接，但是即使一个Gate宕机，客户端检测到之后可以重新发起请求接入另一台Gate服务器。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;数据存储&#34;&gt;数据存储&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;路由数据：存放在Redis中，格式为（UID,客户端在哪个gate登录）。&lt;/li&gt;
&lt;li&gt;消息数据：存储在DB中，部分也会缓存在缓存中方便查询，这部分做为下一部分文章的重点来讲解，不在这部分展开讨论。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;核心交互流程&#34;&gt;核心交互流程&lt;/h1&gt;
&lt;h2 id=&#34;统一登录系统&#34;&gt;统一登录系统&lt;/h2&gt;
&lt;h2 id=&#34;登录授权auth&#34;&gt;登录授权（auth）&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-login.png&#34; alt=&#34;im-login&#34; title=&#34;im login&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端通过统一登录系统验证登录密码等。&lt;/li&gt;
&lt;li&gt;SSO验证客户端用户名密码之后，生成登录token并返回给客户端。&lt;/li&gt;
&lt;li&gt;客户端使用UID和返回的token向gate发起授权验证请求。&lt;/li&gt;
&lt;li&gt;gate同步调用logic server的验证接口。&lt;/li&gt;
&lt;li&gt;logic server请求SSO系统验证token合法性。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;SSO向auth系统返回验证token结果。&lt;/li&gt;
&lt;li&gt;如果验证成功，auth系统在redis中存储客户端的路由信息，即客户端在哪个gate上登录。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;auth系统向gate返回验证登录结果。&lt;/li&gt;
&lt;li&gt;gate向客户端返回授权结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;登出logout&#34;&gt;登出（logout）&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-logout.png&#34; alt=&#34;im-logout&#34; title=&#34;im logout&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端向gate发出logout请求。&lt;/li&gt;
&lt;li&gt;gate设置客户端UID对应的peer无效，然后应答客户端登出成功。&lt;/li&gt;
&lt;li&gt;gate向logic server发出登录请求。&lt;/li&gt;
&lt;li&gt;处理该类请求的c2s服务器，清除redis中的客户端路由信息。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;踢人kickout&#34;&gt;踢人（kickout）&lt;/h2&gt;
&lt;p&gt;用户请求授权时，可能在另一个设备（同类型设备，比如一台苹果手机登录时发现一台安卓手机也在登录这个账号）开着软件处于登录状态。这种情况需要系统将那个设备踢下线。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-kickout.png&#34; alt=&#34;im-kickout&#34; title=&#34;im kickout&#34;&gt;&lt;/p&gt;
&lt;p&gt;新的客户端登陆流程同上面的登陆认证流程，只不过在auth模块完成认证之后，会做如下的操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据UID到redis中查询路由数据，如果不存在说明前面没有登陆过，那么就像登陆流程一样返回即可。&lt;/li&gt;
&lt;li&gt;否则说明前面已经有其他设备登陆了，将向前面的gate发送踢人请求，然后保存新的路由信息到redis中。&lt;/li&gt;
&lt;li&gt;gate接收到踢人请求，踢掉客户端之后断掉与客户端的连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;客户端上报消息c2s消息&#34;&gt;客户端上报消息（c2s消息）&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-c2smsg.png&#34; alt=&#34;im-c2smsg&#34; title=&#34;im c2s msg&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端向gate发送c2s消息数据。&lt;/li&gt;
&lt;li&gt;gate应答客户端。&lt;/li&gt;
&lt;li&gt;gate向逻辑服务器发送c2s消息。&lt;/li&gt;
&lt;li&gt;logic server的c2s模块，将消息发送到MQ消息总线中。&lt;/li&gt;
&lt;li&gt;appserver消费MQ消息做处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;应用服务器推送消息s2c消息&#34;&gt;应用服务器推送消息（s2c消息）&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-s2cmsg.png&#34; alt=&#34;im-s2cmsg&#34; title=&#34;im s2c msg&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;业务服务器向逻辑服务器发送s2c消息。&lt;/li&gt;
&lt;li&gt;逻辑服务器的s2c模块从redis中查询UID的路由数据，知道该用户在哪个gate上面登陆。&lt;/li&gt;
&lt;li&gt;逻辑服务器向gate发送s2c消息。&lt;/li&gt;
&lt;li&gt;gate服务器向客户端发送s2c消息。&lt;/li&gt;
&lt;li&gt;客户端收到之后向gate ack消息。&lt;/li&gt;
&lt;li&gt;gate向逻辑服务器ack s2c消息。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;单对单聊天c2c消息&#34;&gt;单对单聊天（c2c消息）&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-c2cmsg.png&#34; alt=&#34;im-c2cmsg&#34; title=&#34;im c2c msg&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端向gate发送c2c消息。&lt;/li&gt;
&lt;li&gt;gate向逻辑服务器发送c2c消息。&lt;/li&gt;
&lt;li&gt;逻辑服务器的c2c模块保存消息到消息存储中，此时会将该消息的未读标志置位表示未读。&lt;/li&gt;
&lt;li&gt;逻辑服务器应答gate，说明已经保存了该消息，即客户端发送成功。&lt;/li&gt;
&lt;li&gt;gate应答客户端，表示c2c消息发送成功。&lt;/li&gt;
&lt;li&gt;逻辑服务器的c2c模块，查询redis服务看该c2c消息的目标客户端的路由信息，如果不在线就直接返回。&lt;/li&gt;
&lt;li&gt;否则说明该消息的目的客户端在线，向所在gate发送c2c消息。&lt;/li&gt;
&lt;li&gt;gate向客户端转发c2c消息。&lt;/li&gt;
&lt;li&gt;客户端向gate应答收到c2c消息。&lt;/li&gt;
&lt;li&gt;gate向逻辑服务器应答客户端已经收到c2c消息。&lt;/li&gt;
&lt;li&gt;逻辑服务器的c2c模块，在消息存储中清空该消息的未读标志表示消息已读。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意第7步中，逻辑服务器的c2c模块在向gate转发c2c消息之后，需要加上定时器，如果在指定时间没有收到最后客户端的应答，需要重发。尝试几次重发都失败则放弃，等待下次用户登录了拉取离线消息。&lt;/p&gt;
&lt;h2 id=&#34;群聊消息c2g消息&#34;&gt;群聊消息（c2g消息）&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-c2gmsg.png&#34; alt=&#34;im-c2gmsg&#34; title=&#34;im c2g msg&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端A向gate发送c2g消息。&lt;/li&gt;
&lt;li&gt;gate向逻辑服务器发送c2g消息。&lt;/li&gt;
&lt;li&gt;逻辑服务器的c2g模块将消息保存到SendMsg DB中，这部分消息将根据消息的发送者ID水平扩展。&lt;/li&gt;
&lt;li&gt;c2g模块从cache中查询该群组的用户ID，如果查不到会到存放群组信息的DB中查询。&lt;/li&gt;
&lt;li&gt;遍历获取到的群组ID，保存消息到RecvMsg DB中，这部分消息将根据接受者ID水平扩展。&lt;/li&gt;
&lt;li&gt;查询redis，知道哪些群组用户当前在线。&lt;/li&gt;
&lt;li&gt;向当前在线的用户所在gate发送c2g消息。&lt;/li&gt;
&lt;li&gt;gate转发给客户端c2g消息。&lt;/li&gt;
&lt;li&gt;客户端应答gate c2g消息。&lt;/li&gt;
&lt;li&gt;gate应答逻辑服务器的c2g模块用户已经收到c2g消息。&lt;/li&gt;
&lt;li&gt;c2g模块修改发送消息库该消息已读。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;登录后拉取离线消息流程&#34;&gt;登录后拉取离线消息流程&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-offlinemsg.png&#34; alt=&#34;im-offlinemsg&#34; title=&#34;im offline msg&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端请求离线消息，其中会带上的字段是：客户端uid、当前客户端上保存的最大消息id（msgid）、每次最多获取多少离线消息（size）。当msgid为0的时候，由服务器自行查询当前的离线消息返回给客户端；否则服务器只会返回该消息id以后的消息。在这个例子中，假设第一次请求时，msgid为0，即由服务器查询需要给客户端返回哪些离线消息。&lt;/li&gt;
&lt;li&gt;im服务器查询uid为100的用户的前10（因为size=10）的离线消息，具体来说就是去消息接收表中查询uid=100且read flag为false的前10条消息。这里假设第一次查询返回的消息中，最大消息id为100。&lt;/li&gt;
&lt;li&gt;向客户端返回最新离线消息，同时带上最大离线消息id 100。&lt;/li&gt;
&lt;li&gt;客户端收到离线消息只会，由于收到的消息数量等于size，说明可能还有没有读取的离线消息，因此再次向服务器查询，这一次带上的消息id为100，表示请求该id之后的未读消息。&lt;/li&gt;
&lt;li&gt;IM服务器收到这一次拉取离线消息请求之后，由于msgid不为0，因此首先会将uid=100且msgid在100之前的未读消息全部置为已读。&lt;/li&gt;
&lt;li&gt;获取uid=100且msgid&amp;gt;100的未读消息返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果每次拉取的离线消息都等于拉取离线消息数量，客户端会一直重复拉取离线消息流程，直到拉取完毕。&lt;/p&gt;
&lt;h1 id=&#34;协议设计&#34;&gt;协议设计&lt;/h1&gt;
&lt;h2 id=&#34;协议格式&#34;&gt;协议格式&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190608-im-design-base/im-protocol-format.png&#34; alt=&#34;im-protocol-format&#34; title=&#34;im protocol format&#34;&gt;&lt;/p&gt;
&lt;p&gt;协议分为包头和包体两部分，其中包体为固定的大小，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;version（4字节）：协议版本号。&lt;/li&gt;
&lt;li&gt;cmd（4字节）：协议类型。&lt;/li&gt;
&lt;li&gt;seq（4字节）：序列号。&lt;/li&gt;
&lt;li&gt;timestamp（8字节）：消息的时间戳&lt;/li&gt;
&lt;li&gt;body length（4字节）：包体大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中，包体部分使用protobuf来定义，以下介绍不同命令的包体格式。&lt;/p&gt;
&lt;h2 id=&#34;认证auth&#34;&gt;认证（auth）&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message AuthRequest {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  string token &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 从SSO服务器返回的登录token，登录之后保存在客户端
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  srting uid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;;   &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 用户ID
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message AuthResponse {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  int32 status &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 应答状态码，0表示成功，其他表示失败
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  string err_msg &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 错误描述信息
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;登出logout-1&#34;&gt;登出（logout）&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message LogoutRequest {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  string token &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 从SSO服务器返回的登录token，登录之后保存在客户端
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  srting uid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;;   &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 用户ID
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message LogoutResponse {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;踢人kickout-1&#34;&gt;踢人（kickout）&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message KickoutRequest {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;enum&lt;/span&gt; Reason {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    OTHER_LOGIN &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 其他设备登录
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  int32 reason &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 踢人原因
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message KickoutResponse {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;心跳包&#34;&gt;心跳包&lt;/h2&gt;
&lt;p&gt;无包体&lt;/p&gt;
&lt;h2 id=&#34;单对单消息c2c&#34;&gt;单对单消息（c2c）&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 发送者发送消息的协议
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;message C2CSendRequest {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  string from &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 发送者
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  string to &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 接收者
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  string content &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 消息内容
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message C2CSendResponse {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  int64 msgid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 落地的消息ID
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 推送给接收者的协议
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;message C2CPushRequest {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  string from &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  string content &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  int64 msgid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message C2CPushResponse {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  int64 msgid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;;  &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 消息id，服务器收到这个id可以去置位这个消息已读
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;群聊c2g&#34;&gt;群聊（c2g）&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 发送者发送群消息协议
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;message C2GSendRequest {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  string from &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 发送者
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  string group &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 群
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  string content &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 消息内容
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message C2GSendResponse {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  int64 msgid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 落地的消息ID
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 推送给其他群成员消息协议
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;message C2GPushRequest {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  string from &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 发送者
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  string group &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 群
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  string content &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 消息内容
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;  int64 msgid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 落地的消息ID
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;message C2GPushResponse {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  int64 msgid &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 落地的消息ID
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;拉离线消息pull&#34;&gt;拉离线消息（pull）&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;message C2SPullMessageRequest {
  string uid = 1;
  int64 msgid = 2;  // 拉取该消息id以后的离线消息，为0由服务器自行判断
  int32 limit = 3; //  单次拉取离线消息的数量
}

message PullMsg {
  string from = 1;  // 发送者
  int64 group = 2;  // 目的群
  string content = 3; // 消息内容
  int64 msgid = 4;  // 消息编号
  int64 send_time = 5;  // 服务器接收消息时间
}

message C2SPullMessageResponse {
  repeated PullMsg msg = 1; // 离线消息数组
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.tencent.com/developer/article/1166255&#34;&gt;单点登录（SSO），从原理到实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ken.io/note/sso-design-implement&#34;&gt;单点登录（SSO）的设计与实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52im.net/thread-812-1-1.html&#34;&gt;一套海量在线用户的移动端IM架构设计实践分享&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>
