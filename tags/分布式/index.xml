<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>分布式 on codedump的网络日志</title>
    <link>https://www.codedump.info/tags/%E5%88%86%E5%B8%83%E5%BC%8F/</link>
    <description>Recent content in 分布式 on codedump的网络日志</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 01 Jan 2022 15:02:50 +0800</lastBuildDate><atom:link href="https://www.codedump.info/tags/%E5%88%86%E5%B8%83%E5%BC%8F/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>etcd 3.5版本的joint consensus实现解析</title>
      <link>https://www.codedump.info/post/20220101-etcd3.5-joint-consensus/</link>
      <pubDate>Sat, 01 Jan 2022 15:02:50 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20220101-etcd3.5-joint-consensus/</guid>
      
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;
&lt;p&gt;在以前的etcd实现中，“集群节点变更”这一功能，仅支持每次变更一个节点，最新的etcd已经能支持一次变更多个节点配置的功能了。本文将就这部分的实现进行解析。&lt;/p&gt;
&lt;h1 id=&#34;原理&#34;&gt;原理&lt;/h1&gt;
&lt;p&gt;Raft论文《CONSENSUS: BRIDGING THEORY AND PRACTICE》的第四章”集群成员变更“中，支持两种集群变更方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次变更单节点，即“One Server Config Change”。&lt;/li&gt;
&lt;li&gt;多节点联合共识，即“Joint Consensus”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文先就这两种实现方式进行原理上的讲解。&lt;/p&gt;
&lt;h2 id=&#34;集群节点变更的问题&#34;&gt;集群节点变更的问题&lt;/h2&gt;
&lt;p&gt;要保证Raft协议的安全性，就是要保证任意时刻，集群中只有唯一的&lt;code&gt;leader&lt;/code&gt;节点。如果不加限制条件，那么动态向当前运行集群增删节点的操作，有可能会导致存在多个&lt;code&gt;leader&lt;/code&gt;的情况。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20220101-etcd3.5-joint-Consensus/multi-server.png&#34; alt=&#34;集群节点变更问题&#34; title=&#34;集群节点变更问题&#34;&gt;&lt;/p&gt;
&lt;p&gt;图中有两种颜色的配置，绿色表示旧的集群配置（&lt;code&gt;C_old&lt;/code&gt;），蓝色表示新的集群配置（&lt;code&gt;C_new&lt;/code&gt;），如果不加任何限制，直接将配置启用，由于不同的集群节点之间，存在时间差，那么可能出现这样的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Server{1,2}：当前都使用旧的集群配置，所以可能选出server1为集群的leader。&lt;/li&gt;
&lt;li&gt;Server{3,4,5}：当前都使用新的集群配置，可能选出server3为集群的leader。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由上图可以看到：如果不加任何限制，直接应用新的集群配置，由于时间差的原因，可能导致集群中出现两个不同leader的情况。&lt;/p&gt;
&lt;h2 id=&#34;单节点成员变更one-server-confchange&#34;&gt;单节点成员变更（One Server ConfChange）&lt;/h2&gt;
&lt;p&gt;“单节点成员变更”，意指每次只添加或删除一个节点，这样就能保证集群的安全性，不会在同一时间出现多个&lt;code&gt;leader&lt;/code&gt;的情况。之所以能有这个保证，是因为每次变更一个节点，那么新旧两种配置的半数节点（majorrity）肯定存在交集。以下图来说明：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20220101-etcd3.5-joint-Consensus/one-server-confchange.png&#34; alt=&#34;单节点成员变更&#34; title=&#34;单节点成员变更&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图演示了向偶数或奇数的集群增删一个节点的所有可能情况。不论哪种情况，新旧配置都有交集，在每个任期只能投出一张票的情况下，是不会出现多&lt;code&gt;leader&lt;/code&gt;的情况的。&lt;/p&gt;
&lt;p&gt;有了上面的理论基础，下面来看&lt;code&gt;单节点集群变更&lt;/code&gt;的全流程，当下发集群节点变更配置时，新的配置会以一种特殊的日志方式进行提交，即：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;普通日志：半数通过，提交成功时，会传给应用层的状态机。&lt;/li&gt;
&lt;li&gt;配置变更类日志：半数通过，提交成功时，集群节点将以新的集群配置生效。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将集群配置变更数据，序列化为日志数据，需要将日志类型标记为&lt;code&gt;集群配置变更&lt;/code&gt;类的日志，提交给&lt;code&gt;leader&lt;/code&gt;节点。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leader&lt;/code&gt;节点收到日志后，需要存储该日志的索引为&lt;code&gt;未完成的集群配置变更索引&lt;/code&gt;，像其它正常日志一样处理：先写本地的日志，再广播给集群的其他节点，半数应答则认为日志达成一致可以提交了。如果提交了这类日志，可以将前面保存的&lt;code&gt;未完成的集群配置变更索引&lt;/code&gt;置为空了。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;集群配置变更&lt;/code&gt;日志提交之后，对照新旧的集群变更数据，该添加到集群的添加到集群，该删除的节点停机。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要注意的是，同一时间只能有唯一一个&lt;code&gt;集群变更类日志&lt;/code&gt;存在，怎么保证这一点？就算是在&lt;code&gt;leader&lt;/code&gt;收到该类型日志时，判断&lt;code&gt;未完成的集群配置变更索引&lt;/code&gt;是否为空。&lt;/p&gt;
&lt;h2 id=&#34;多节点联合共识joint-consensus&#34;&gt;多节点联合共识（Joint Consensus）&lt;/h2&gt;
&lt;p&gt;除了上面的单节点变更，有时候还需要一次提交多个节点的变更。但是按照前面的描述，如果一次提交多个节点，很可能会导致集群的安全性被破坏，即同时出现多个&lt;code&gt;leader&lt;/code&gt;的情况。因此，一次提交多节点时，就需要走&lt;code&gt;联合共识&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;所谓的&lt;code&gt;联合共识&lt;/code&gt;，就是将新旧配置的节点一起做为一个节点集合，只有该节点集合达成半数一致，才能认为日志可以提交，由于新旧两个集合做了合并，那么就不会出现多&lt;code&gt;leader&lt;/code&gt;的情况了。具体流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;leader&lt;/code&gt;收到成员变更请求，新集群节点集合为&lt;code&gt;C_new&lt;/code&gt;，当前集群节点集合为&lt;code&gt;C_old&lt;/code&gt;，此时首先会以新旧节点集合的交集&lt;code&gt;C_{old,new}&lt;/code&gt;做为一个&lt;code&gt;集群配置变更&lt;/code&gt;类的日志，走正常的日志提交流程。注意，这时候的日志，需要提交到&lt;code&gt;C_{old,new}&lt;/code&gt;中的所有节点。&lt;/li&gt;
&lt;li&gt;当&lt;code&gt;C_{old,new}&lt;/code&gt;集群变更日志提交之后，&lt;code&gt;leader&lt;/code&gt;节点再马上创建一个只有&lt;code&gt;C_new&lt;/code&gt;节点集合的&lt;code&gt;集群配置变更&lt;/code&gt;类日志，再次走正常的日志提交流程。这时候的日志，只需要提交到&lt;code&gt;C_new&lt;/code&gt;中的所有节点。&lt;/li&gt;
&lt;li&gt;当&lt;code&gt;C_new&lt;/code&gt;日志被提交之后，集群的配置就能切换到&lt;code&gt;C_new&lt;/code&gt;对应的新集群配置下了。而不在&lt;code&gt;C_new&lt;/code&gt;配置内的节点，将被移除。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，&lt;code&gt;多节点联合共识&lt;/code&gt;的提交流程分为了两次提交：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先提交新旧集合的交集&lt;code&gt;C_{old,new}&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;再提交新节点集合&lt;code&gt;C_new&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下图来说明，这几个阶段中，集群的安全性都得到了保证：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20220101-etcd3.5-joint-Consensus/Joint-Consensus.png&#34; alt=&#34;多节点联合共识&#34; title=&#34;多节点联合共识&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;C_{old,new}&lt;/code&gt;配置提交之前：在做个阶段，集群中的节点，要么处于&lt;code&gt;C_old&lt;/code&gt;配置下，要么处于&lt;code&gt;C_new,old&lt;/code&gt;配置之下。此时，如果集群的&lt;code&gt;leader&lt;/code&gt;节点宕机，那么将会基于&lt;code&gt;C_old&lt;/code&gt;或者&lt;code&gt;C_new,old&lt;/code&gt;配置来选出新的&lt;code&gt;leader&lt;/code&gt;，而不会仅仅基于&lt;code&gt;C_new&lt;/code&gt;，因此不会选出不同的&lt;code&gt;leader&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C_{old,new}&lt;/code&gt;配置提交之后，&lt;code&gt;C_new&lt;/code&gt;下发之前：如果这时候&lt;code&gt;leader&lt;/code&gt;宕机，只会基于&lt;code&gt;C_{old,new}&lt;/code&gt;的配置选出&lt;code&gt;leader&lt;/code&gt;，因此也不会选出不同的&lt;code&gt;leader&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C_new&lt;/code&gt;下发但还未提交时：如果这时候&lt;code&gt;leader&lt;/code&gt;宕机，只会基于&lt;code&gt;C_{old,new}&lt;/code&gt;或者&lt;code&gt;C_new&lt;/code&gt;的配置选出&lt;code&gt;leader&lt;/code&gt;，同时也不再会发给仅仅在&lt;code&gt;C_old&lt;/code&gt;中的节点了，所以无论是哪个配置，都需要得到&lt;code&gt;C_new&lt;/code&gt;的半数同意，因此不会选出不同的&lt;code&gt;leader&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C_new&lt;/code&gt;提交之后：此时集群中只有一种配置了，安全性得到了保证。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;实现&#34;&gt;实现&lt;/h1&gt;
&lt;p&gt;了解了原理之后，可以来具体看etcd 3.5中这部分的实现了。&lt;/p&gt;
&lt;h2 id=&#34;learner&#34;&gt;learner&lt;/h2&gt;
&lt;p&gt;首先需要了解&lt;code&gt;learner&lt;/code&gt;这个概念，在Raft中，这类型节点有以下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;与其他节点一样，能正常接收&lt;code&gt;leader&lt;/code&gt;同步的日志。&lt;/li&gt;
&lt;li&gt;但是&lt;code&gt;learner&lt;/code&gt;节点没有投票权，即：投票时会忽略掉这类型节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也因为这样，所以&lt;code&gt;learner&lt;/code&gt;节点也常被称为&lt;code&gt;non voter&lt;/code&gt;类型的节点。&lt;/p&gt;
&lt;p&gt;那么，什么时候需要&lt;code&gt;learner&lt;/code&gt;节点呢？如果一个节点刚加入集群，此时要追上当前的进度，需要一段时间，但是由于这个新节点的加入，导致集群的不可用风险增加了，即原来三节点的集群，挂了一个还能工作；加入这个新节点之后，新节点还没赶上进度，那么可能挂了一个节点集群就不可用了。&lt;/p&gt;
&lt;p&gt;所以，对于新加入的节点，可以先将它置为&lt;code&gt;learner&lt;/code&gt;类型，即：只同步日志，不参与投票。等到进度追上了，再变成正常的有投票权的节点。&lt;/p&gt;
&lt;p&gt;一个节点，需要添加到集群中变成集群的&lt;code&gt;learner&lt;/code&gt;，或者从原集群的&lt;code&gt;voter&lt;/code&gt;变成&lt;code&gt;learner&lt;/code&gt;，也都不能直接添加，而是必须走前面正常的&lt;code&gt;集群变更&lt;/code&gt;流程，即：集群中的&lt;code&gt;learner&lt;/code&gt;集合也是集群节点配置的一部分。&lt;/p&gt;
&lt;h2 id=&#34;数据结构&#34;&gt;数据结构&lt;/h2&gt;
&lt;h3 id=&#34;每个节点的进度数据progress结构体&#34;&gt;每个节点的进度数据（Progress结构体）&lt;/h3&gt;
&lt;p&gt;etcd中，使用&lt;code&gt;Progress&lt;/code&gt;结构体来存储集群中每个节点当前的进度数据，包括以下成员：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;日志索引类成员：
&lt;ul&gt;
&lt;li&gt;Match索引&lt;/li&gt;
&lt;li&gt;Next索引。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;当前的进度状态：
&lt;ul&gt;
&lt;li&gt;探针状态（probe）：节点刚加入，或者刚恢复都是该状态。&lt;/li&gt;
&lt;li&gt;正常同步状态（replicate）。&lt;/li&gt;
&lt;li&gt;同步快照状态：当前没有在进行日志同步，而是在同步快照。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IsLearner：标记当前该节点是否是&lt;code&gt;learner&lt;/code&gt;状态的节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中，&lt;code&gt;进度状态&lt;/code&gt;类似于TCP协议中的流控，不在这里做阐述了；两个&lt;code&gt;日志索引&lt;/code&gt;也是Raft论文中用于存储节点进度数据的索引，也不在这里阐述了；唯独需要注意的是&lt;code&gt;IsLearner&lt;/code&gt;，该成员标记了该节点是否&lt;code&gt;learner&lt;/code&gt;节点。&lt;/p&gt;
&lt;h3 id=&#34;集群配置config结构体&#34;&gt;集群配置（Config结构体）&lt;/h3&gt;
&lt;p&gt;集群配置使用&lt;code&gt;Config&lt;/code&gt;结构体来保存，其成员如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Voters：包括新旧两个配置。新旧两个配置的节点集合合集，成为当前的所有节点集合。
&lt;ul&gt;
&lt;li&gt;[0]：&lt;code&gt;incoming&lt;/code&gt;配置，新的集群配置。&lt;/li&gt;
&lt;li&gt;[1]：&lt;code&gt;outgoing&lt;/code&gt;配置，旧的集群配置。一般这个集合为空，这个集合不为空时，存储的是变更之前旧的集群配置，因此不为空时表示当前有未提交的&lt;code&gt;joint consensus&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learners：当前的learner集合，learner集合和前面的所有节点集合交集必须为空集。&lt;/li&gt;
&lt;li&gt;LearnersNext：集群配置提交后，从原集群的&lt;code&gt;voter&lt;/code&gt;降级为&lt;code&gt;learner&lt;/code&gt;的节点集合。&lt;/li&gt;
&lt;li&gt;AutoLeave：该配置为true时，自动让新配置生效。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;前面原理的部分，只讲解了新旧配置的变更流程，但是在etcd的实现中，集群配置里除了新旧配置，还多了存储&lt;code&gt;Learner&lt;/code&gt;节点的两种集合，这会让情况变得更复杂一些。&lt;/p&gt;
&lt;p&gt;如果一个节点要在新的集群配置中变成&lt;code&gt;Learner&lt;/code&gt;，需要区分两种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;该节点原先是集群的&lt;code&gt;voter&lt;/code&gt;：并不是直接加入到&lt;code&gt;Learner&lt;/code&gt;集合的，而是首先提交到&lt;code&gt;LearnersNext&lt;/code&gt;集合中，同样也是等待这个新的集群配置被成功之后，才移动到&lt;code&gt;Learner&lt;/code&gt;集合中。否则，如果直接修改加入到&lt;code&gt;Learner&lt;/code&gt;集合中，可能导致集群的安全性受到影响。比如一个三节点{a,b,c}的集群，原先有只挂了一个节点还能继续工作；现在由于各种原因，想将节点c降级为&lt;code&gt;learner&lt;/code&gt;，将节点d加入到集群中，如果直接将c节点降级为&lt;code&gt;learner&lt;/code&gt;，就会导致在这个流程里一旦一个节点不可用，整个集群就不可用了。&lt;/li&gt;
&lt;li&gt;该节点原先不是集群中的成员：这种节点由于之前并不存在，并不影响集群的安全性，这时候可以直接移动到&lt;code&gt;Learner&lt;/code&gt;中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20220101-etcd3.5-joint-Consensus/add-learner.png&#34; alt=&#34;单节点成员变更&#34; title=&#34;单节点成员变更&#34;&gt;&lt;/p&gt;
&lt;p&gt;所以：&lt;code&gt;Voters&lt;/code&gt;两个配置，与两种&lt;code&gt;Learner&lt;/code&gt;集合，必须满足以下的关系（见函数&lt;code&gt;checkInvariants&lt;/code&gt;）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在&lt;code&gt;LearnersNext&lt;/code&gt;中的节点，表示未提交的集群配置中待添加&lt;code&gt;learner&lt;/code&gt;节点集合的节点：
&lt;ul&gt;
&lt;li&gt;必须出现在&lt;code&gt;outgoing&lt;/code&gt;中，即必须出现在旧的集群配置中。&lt;/li&gt;
&lt;li&gt;该节点的进度数据中，&lt;code&gt;IsLearner&lt;/code&gt;为False。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;Learners&lt;/code&gt;中的节点，表示当前集群的&lt;code&gt;learner&lt;/code&gt;节点集合：
&lt;ul&gt;
&lt;li&gt;不能出现在任一个&lt;code&gt;voter&lt;/code&gt;集合中（&lt;code&gt;incoming&lt;/code&gt;和&lt;code&gt;outgoing&lt;/code&gt;）中，即不能出现在新、旧的集群配置中。&lt;/li&gt;
&lt;li&gt;该节点的进度数据中，&lt;code&gt;IsLearner&lt;/code&gt;为True。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;集群整体监控progresstracker结构体&#34;&gt;集群整体监控（ProgressTracker结构体）&lt;/h3&gt;
&lt;p&gt;有了节点的进度数据（Progress结构体），以及集群配置数据（Config结构体），整个集群的进度管控，都放在了结构体&lt;code&gt;ProgressTracker&lt;/code&gt;中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Config：存储当前集群的配置。&lt;/li&gt;
&lt;li&gt;Progress：以节点ID为键，值为&lt;code&gt;Progress结构体&lt;/code&gt;的map。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;负责提交配置流程changer结构体&#34;&gt;负责提交配置流程（Changer结构体）&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Changer&lt;/code&gt;属于提交流程中存储中间状态的数据结构，对其输入：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当前的&lt;code&gt;ProgressTracker结构体&lt;/code&gt;数据，即当前的配置和进度数据。&lt;/li&gt;
&lt;li&gt;要进行的变更数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;输出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要提交的配置数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Raft最终以其输入的配置数据，来生成&lt;code&gt;集群配置类型&lt;/code&gt;的日志，走正常的日志提交流程。提交成功之后，配置生效。&lt;/p&gt;
&lt;h2 id=&#34;流程&#34;&gt;流程&lt;/h2&gt;
&lt;p&gt;按照前面原理部分的分析，&lt;code&gt;多节点联合共识&lt;/code&gt;的提交分为两步：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先提交新旧集合的交集&lt;code&gt;C_{old,new}&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;再提交新节点集合&lt;code&gt;C_new&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实际在etcd中，也是这样做的，分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;EnterJoint：将新旧集合的交集提交。&lt;/li&gt;
&lt;li&gt;LeaveJoint：提交新节点集合。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;enterjoint&#34;&gt;EnterJoint&lt;/h3&gt;
&lt;p&gt;该流程在&lt;code&gt;Changer::EnterJoint&lt;/code&gt;中实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拷贝当前&lt;code&gt;ProgressTracker&lt;/code&gt;结构体当前的进度（&lt;code&gt;Progress&lt;/code&gt;）和配置数据（&lt;code&gt;Config&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;如果当前有在提交的配置，就返回退出，因为同一时间只能有一个未提交的配置变更。如何判断当前是否有未提交的配置？看&lt;code&gt;Config&lt;/code&gt;中的&lt;code&gt;outgoing&lt;/code&gt;（即&lt;code&gt;voters[1]&lt;/code&gt;）是否为空。我们下面再详细解释。&lt;/li&gt;
&lt;li&gt;下面，以第一步拷贝的配置数据，生成新的配置数据：
&lt;ul&gt;
&lt;li&gt;将&lt;code&gt;Config&lt;/code&gt;中的&lt;code&gt;incoming&lt;/code&gt;数据拷贝到&lt;code&gt;outgoing&lt;/code&gt;中，即先保存当前的配置到&lt;code&gt;outgoing&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;遍历需要修改的配置，根据不同的操作类型做操作，生成新的配置：
&lt;ul&gt;
&lt;li&gt;如果要删除某节点，调用&lt;code&gt;Changer::remove&lt;/code&gt;函数：
&lt;ul&gt;
&lt;li&gt;从&lt;code&gt;incoming&lt;/code&gt;中删除该节点。&lt;/li&gt;
&lt;li&gt;从&lt;code&gt;Learner&lt;/code&gt;以及&lt;code&gt;LearnerNext&lt;/code&gt;集合中删除该节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果增加&lt;code&gt;voter&lt;/code&gt;，调用&lt;code&gt;Changer::makeVoter&lt;/code&gt;函数：
&lt;ul&gt;
&lt;li&gt;该节点的进度数据中，&lt;code&gt;IsLearner&lt;/code&gt;变为&lt;code&gt;false&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;从&lt;code&gt;Learner&lt;/code&gt;以及&lt;code&gt;LearnerNext&lt;/code&gt;集合中删除该节点。&lt;/li&gt;
&lt;li&gt;将节点ID加入&lt;code&gt;incoming&lt;/code&gt;集合中。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果增加&lt;code&gt;learner&lt;/code&gt;，调用&lt;code&gt;Changer::makeLearner&lt;/code&gt;函数：
&lt;ul&gt;
&lt;li&gt;调用&lt;code&gt;Changer::remove&lt;/code&gt;函数先删除该节点。&lt;/li&gt;
&lt;li&gt;判断是否在&lt;code&gt;outgoing&lt;/code&gt;配置中有该节点，表示该节点是降级节点：
&lt;ul&gt;
&lt;li&gt;有：表示在新配置下变成了&lt;code&gt;learner&lt;/code&gt;，但是此时并不能直接变成&lt;code&gt;learner&lt;/code&gt;，所以这种情况下该节点加入到了配置的&lt;code&gt;LearnersNext&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;否则，说明是新增节点，直接加入到&lt;code&gt;Learner&lt;/code&gt;集合中。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;上面生成了新旧配置的交集配置，以这个配置数据生成日志来进行提交，生效后应用该配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;leavejoint&#34;&gt;LeaveJoint&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;拷贝当前&lt;code&gt;ProgressTracker&lt;/code&gt;结构体当前的进度（&lt;code&gt;Progress&lt;/code&gt;）和配置数据（&lt;code&gt;Config&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;下面，以第一步拷贝的配置数据，生成新的配置数据：
&lt;ul&gt;
&lt;li&gt;遍历&lt;code&gt;LearnersNext&lt;/code&gt;集合，将其中的节点：
&lt;ul&gt;
&lt;li&gt;加入&lt;code&gt;Learner&lt;/code&gt;集合。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;IsLearner&lt;/code&gt;置为true。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;清空&lt;code&gt;LearnerNext&lt;/code&gt;集合。&lt;/li&gt;
&lt;li&gt;遍历&lt;code&gt;outgoing&lt;/code&gt;节点集合：
&lt;ul&gt;
&lt;li&gt;如果一个节点，既不在&lt;code&gt;incoming&lt;/code&gt;集合中，也不在&lt;code&gt;Learner&lt;/code&gt;集合中，则认为在新的配置中没有该节点了，删除其进度数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;清空&lt;code&gt;outgoing&lt;/code&gt;节点集合。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;上面生成了新旧配置的交集配置，以这个配置数据生成日志来进行提交，生效后应用该配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;例子&#34;&gt;例子&lt;/h3&gt;
&lt;p&gt;以一个例子来说明上面的流程，假设集群当前的配置为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;投票节点：{1,2}。&lt;/li&gt;
&lt;li&gt;Learner节点：{}。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;新提交的配置中有以下三个操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;新增投票节点：{3}。&lt;/li&gt;
&lt;li&gt;降级节点{2}为&lt;code&gt;learner&lt;/code&gt;节点。&lt;/li&gt;
&lt;li&gt;新增Learner节点：{4}。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要再次强调：&lt;strong&gt;无论是&lt;code&gt;EnterJoint&lt;/code&gt;还是&lt;code&gt;LeaveJoint&lt;/code&gt;操作，都并不会让配置马上生效，而是生成了一份待提交的配置，Raft拿到这份配置生成一个提交配置变更的日志，走正常的日志提交流程，待这条日志被半数通过时，才生效该配置。&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;阶段&lt;/th&gt;
&lt;th&gt;incoming节点集合&lt;/th&gt;
&lt;th&gt;outgoing节点集合&lt;/th&gt;
&lt;th&gt;Learner节点集合&lt;/th&gt;
&lt;th&gt;LearnerNext节点集合&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;提交之前&lt;/td&gt;
&lt;td&gt;{1,2}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EnterJoint&lt;/td&gt;
&lt;td&gt;{1,3}&lt;/td&gt;
&lt;td&gt;{1,2}&lt;/td&gt;
&lt;td&gt;{4}&lt;/td&gt;
&lt;td&gt;{2}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LeaveJoint&lt;/td&gt;
&lt;td&gt;{1,3}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;{2,4}&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;读者可以对着上面的流程，以这个例子来理解一下。&lt;/p&gt;
&lt;h2 id=&#34;自动提交&#34;&gt;自动提交&lt;/h2&gt;
&lt;p&gt;这里还有一个细节，即&lt;code&gt;多节点联合共识&lt;/code&gt;是一个两阶段的提交流程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;EnterJoint&lt;/code&gt;之后，&lt;code&gt;outgoing&lt;/code&gt;节点集合变为一个非空集合，这时候不再能提交新的配置，需要到&lt;code&gt;LeaveJoint&lt;/code&gt;之后，才会清空这个集合。&lt;/li&gt;
&lt;li&gt;在etcd中，&lt;code&gt;LeaveJoint&lt;/code&gt;操作，并不见得会自动执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是否在&lt;code&gt;EnterJoint&lt;/code&gt;之后自动执行&lt;code&gt;LeaveJoint&lt;/code&gt;，取决于当前提交的&lt;code&gt;Config&lt;/code&gt;结构体中的&lt;code&gt;AutoLeave&lt;/code&gt;字段，它有两种可能，见&lt;code&gt;ConfChangeTransition&lt;/code&gt;枚举类型的定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ConfChangeTransitionAuto&lt;/code&gt;和&lt;code&gt;ConfChangeTransitionJointImplicit&lt;/code&gt;：如果是这两种情况，都会自动做转换。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ConfChangeTransitionJointExplicit&lt;/code&gt;：需要用户手动执行&lt;code&gt;LeaveJoint&lt;/code&gt;操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（见函数&lt;code&gt;ConfChangeV2::EnterJoint&lt;/code&gt;的实现。）&lt;/p&gt;
&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;《CONSENSUS: BRIDGING THEORY AND PRACTICE》chapter4”Cluster membership changes“&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://etcd.io/docs/v3.3/learning/learner/&#34;&gt;Learner | etcd&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>为什么Raft协议不能提交之前任期的日志？</title>
      <link>https://www.codedump.info/post/20211011-raft-propose-prev-term/</link>
      <pubDate>Mon, 11 Oct 2021 23:14:01 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20211011-raft-propose-prev-term/</guid>
      
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;
&lt;p&gt;在Raft大论文中3.6.2中，有一个细节“不允许提交之前任期的日志”，之前看了几次都理解的不够准确，把这部分内容展开阐述一下。&lt;/p&gt;
&lt;h1 id=&#34;问题&#34;&gt;问题&lt;/h1&gt;
&lt;p&gt;还是先从论文的图例开始解释，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20211011-raft-propose-prev-term/propose-prev-term.png&#34; alt=&#34;论文截图&#34; title=&#34;论文截图&#34;&gt;&lt;/p&gt;
&lt;p&gt;需要特别说明的是，图例中演示的是**“如果允许提交之前任期的日志，将导致什么问题”**，这是大前提，这个前提条件后面会反复强调。&lt;/p&gt;
&lt;p&gt;有了这个前提，下面展开图中的步骤讨论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(a) ：S1 是leader，将黄色的日志2同步到了S2，然后S1崩溃。&lt;/li&gt;
&lt;li&gt;(b) ：S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，将蓝色日志3存储到本地，然后崩溃了。&lt;/li&gt;
&lt;li&gt;(c)：S1重新启动，选举成功。注意在这时，&lt;strong&gt;如果允许“提交之前任期的日志”&lt;/strong&gt;，将首先开始同步过往任期的日志，即将S1上的本地黄色的日志2同步到了S3。这时黄色的节点2已经同步到了集群多数节点，然后S1写了一条新日志4，然后S1又崩溃了。&lt;/li&gt;
&lt;li&gt;接下来，就可能出现两种不同的情况：
&lt;ul&gt;
&lt;li&gt;（d1）：S5重新当选，&lt;strong&gt;如果允许“提交之前任期的日志”&lt;/strong&gt;，就开始同步往期日志，将本地的蓝色日志3同步到所有的节点。结果已经被同步到半数以上节点的黄色日志2被覆盖了。这说明，如果允许“提交之前任期的日志”，会可能出现即便已经同步到半数以上节点的日志被覆盖，这是不允许的。&lt;/li&gt;
&lt;li&gt;（d2）：反之，如果在崩溃之前，S1不去同步往期的日志，而是首先同步自己任期内的日志4到所有节点，就不会导致黄色日志2被覆盖。因为leader同步日志的流程中，会通过不断的向后重试的方式，将日志同步到其他所有follower，只要日志4被复制成功，在它之前的日志2就会被复制成功。（d2）是想说明：不能直接提交过往任期的日志，即便已经被多数通过，但是可以先同步一条自己任内的日志，如果这条日志通过，就能带着前面的日志一起通过，这是（c）和（d2）两个图的区别。图（c）中，S1先去提交过往任期的日志2，图（d2）中，S1先去提交自己任内的日志4。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;再次强调，这里图示想演示的是**“如果允许提交之前任期的日志，将导致什么问题”**。&lt;/p&gt;
&lt;p&gt;我们可以看到的是，如果允许这么做，那么：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(c)中，S1恢复之后，又再次提交在任期2中的黄色日志2。但是，从后面可以看到，即便这个之前任期中的黄色日志2，提交到大部分节点，如果允许“提交之前任期的日志”，仍然存在被覆盖的可能性，因为：&lt;/li&gt;
&lt;li&gt;(d1)中，S5恢复之后，也会提交在自己本地上保存的之前任期3的蓝色日志，这会导致覆盖了前面已经到半数以上节点的黄色日志2。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，“如果允许提交之前任期的日志”，即如同(c)和(d1)演示的那样：重新当选之后，马上提交自己本地保存的、之前任期的日志，就会&lt;strong&gt;可能导致即便已经同步到半数以上节点的日志，被覆盖的情况&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;而“已同步到半数以上节点的日志”，一定在新当选leader上（否则这个节点不可能成为新leader）且达成了一致可提交，即不允许被覆盖。&lt;/p&gt;
&lt;p&gt;这就是矛盾的地方，即允许“提交之前任期的日志”，最终导致了违反协议规则的情况。&lt;/p&gt;
&lt;p&gt;那么，如何确保新当选的leader节点，其本地的未提交日志被正确提交呢？图(d2)展示了正常的情况：即当选之后，不要首先提交本地已有的黄色日志2，而是首先提交一条新日志4，如果这条新日志被提交成功，那么按照Raft日志的匹配规则（log matching property）：日志4如果能提交，它前面的日志也提交了。&lt;/p&gt;
&lt;p&gt;可是，新的问题又出现了，如果在(d2)中，S1重新当选之后，客户端写入没有这条新的日志4，那么前面的日志2是不是永远无法提交了？为了解决这个问题，raft要求每个leader新当选之后，马上写入一条只有任期号和索引、而没有内容的所谓“no-op”日志，以这条日志来驱动在它之前的日志达成一致。&lt;/p&gt;
&lt;p&gt;这就是论文中这部分内容想要表达的。这部分内容之所以比较难理解，是因为经常忽略了这个图示展示的是错误的情况，允许“提交之前任期的日志”可能导致的问题。&lt;/p&gt;
&lt;h1 id=&#34;其他疑问&#34;&gt;其他疑问&lt;/h1&gt;
&lt;h2 id=&#34;c和d2-有什么区别&#34;&gt;(c)和(d2) 有什么区别？&lt;/h2&gt;
&lt;p&gt;看起来，(c)和(d2)一样，S1当选后都提交了日志1、2、4，那么两者的区别在哪里？&lt;/p&gt;
&lt;p&gt;虽然两个场景中，提交的日志都是一样的，但是日志达成一致的顺序并不一致：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(c)：S1成为leader之后，先提交过往任期、本地的日志2，再提交日志4。这就是“提交之前任期日志”的情况。&lt;/li&gt;
&lt;li&gt;(d2)：S1成为leader之后，先提交本次任期的日志4，如果日志4能提交成功，那么它前面的日志2就能提交成功了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于(d2)的这个场景，有可能又存在着下一个疑问：&lt;/p&gt;
&lt;h2 id=&#34;如何理解d2中本任期的日志4提交成功那么它前面的日志2也能提交成功了&#34;&gt;如何理解(d2)中，“本任期的日志4提交成功，那么它前面的日志2也能提交成功了”？&lt;/h2&gt;
&lt;p&gt;这是由raft日志的&lt;code&gt;Log Matching Property&lt;/code&gt;决定的:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If two entries in different logs have the same index and term, then they store the same command.
If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.&lt;/li&gt;
&lt;li&gt;If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第一条性质，说明的是在不同节点上的已提交的日志，如果任期号、索引一样，那么它们的内容肯定一样。这是由leader节点的安全性和leader上的日志只能添加不能覆盖来保证的，这样leader就永远不会在同一个任期，创建两个相同索引的日志。&lt;/p&gt;
&lt;p&gt;第二条性质，说明的是在不同节点上的日志中，如果其中有同样的一条日志（即相同任期和索引）已经达成了一致，那么在这不同节点上在这条日志之前的所有日志都是一样的。&lt;/p&gt;
&lt;p&gt;第二条性质是由leader节点向follower节点上根据&lt;code&gt;AppendEntries&lt;/code&gt;消息同步日志上保证的。leader在&lt;code&gt;AppendEntries&lt;/code&gt;消息中会携带新的新添加entries之前日志的term和index，follower会判断在log中是否存在拥有此term和index的消息，如果没有就会拒绝。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;leader为每一个follower维护一个nextIndex，表示待发送的下一个日志的index。初始化为日志长度。&lt;/li&gt;
&lt;li&gt;leader在follower拒绝&lt;code&gt;AppendEntries&lt;/code&gt;之后会对nextIndex减一，然后继续重试AppendEntries直到两者一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;于是，回到我们开始的问题，(d2)场景中，在添加本任期日志4的时候，会发现有一些节点上并不存在过往任期的日志2，这时候就会相应地计算不同节点的nextIndex索引，来驱动同步日志2到这些节点上。&lt;/p&gt;
&lt;p&gt;总而言之，根据日志的性质，只要本任期的日志4能达成一致，上一条日志2就能达成一致。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Etcd Raft库的日志存储</title>
      <link>https://www.codedump.info/post/20210628-etcd-wal/</link>
      <pubDate>Mon, 28 Jun 2021 17:01:53 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20210628-etcd-wal/</guid>
      
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;
&lt;p&gt;之前看etcd raft实现的时候，由于wal以及日志的落盘存储部分，没有放在raft模块中，对这部分没有扣的特别细致。而且，以前我的观点认为etcd raft把WAL这部分留给了上层的应用去实现，自身通过&lt;code&gt;Ready&lt;/code&gt;结构体来通知应用层落盘的数据，这个观点也有失偏颇，etcd只是没有把这部分代码放在raft模块中，属于代码组织的范畴问题，并不是需要应用层自己来实现。&lt;/p&gt;
&lt;p&gt;于是，决定专门写一篇文章把这部分内容给讲解一下，主要涉及以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;日志（包括快照）文件的格式。&lt;/li&gt;
&lt;li&gt;日志（包括快照）内容的落盘、恢复。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以前的系列文章可以在下面的链接中找到，本文不打算过多重复原理性的内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180921-raft/&#34;&gt;Raft算法原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180922-etcd-raft/&#34;&gt;etcd Raft库解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20181125-etcd-server/&#34;&gt;Etcd存储的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20210515-raft/&#34;&gt;Etcd Raft库的工程化实现 - codedump的网络日志&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;wal及快照文件格式&#34;&gt;WAL及快照文件格式&lt;/h1&gt;
&lt;p&gt;首先来讲解这两种文件的格式，了解了格式才能继续展开下面的讲述。&lt;/p&gt;
&lt;h2 id=&#34;wal文件格式&#34;&gt;WAL文件格式&lt;/h2&gt;
&lt;p&gt;wal文件的文件名格式为：seq-index.wal（见函数&lt;code&gt;walName&lt;/code&gt;）。其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;seq：序列号，从0开始递增。&lt;/li&gt;
&lt;li&gt;index：该wal文件存储的第一条日志数据的索引。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，如果将一个目录下的所有wal文件按照名称排序之后，给定一个日志索引，很快就能知道该索引的日志落在哪个wal文件之中的。&lt;/p&gt;
&lt;p&gt;WAL文件中每条记录的格式如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-proto&#34; data-lang=&#34;proto&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;message&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Record&lt;/span&gt; {&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;int64&lt;/span&gt; type  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint32&lt;/span&gt; crc  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;bytes&lt;/span&gt; data  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt;;&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;}&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;type：记录的类型，下面解释。&lt;/li&gt;
&lt;li&gt;crc：后面data部分数据的crc32校验值。&lt;/li&gt;
&lt;li&gt;data：数据部分，根据类型的不同有不同格式的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;记录数据的类型如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;const&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 以下是WAL存放的数据类型
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 元数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	metadataType &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;int64&lt;/span&gt; = &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;iota&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 日志数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	entryType
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 状态数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	stateType
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 校验初始值
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	crcType
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 快照数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	snapshotType
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下面展开解释。&lt;/p&gt;
&lt;h3 id=&#34;元数据&#34;&gt;元数据&lt;/h3&gt;
&lt;p&gt;元数据就是应用层自定义的数据，需要注意的是，一个服务中如果有多个wal文件，且这些文件中有多份元数据，那么这些元数据都必须一致，否则报错。&lt;/p&gt;
&lt;p&gt;对于etcd这个服务而言，存储的元数据就是节点ID以及集群ID：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	metadata &lt;span style=&#34;color:#666&#34;&gt;:=&lt;/span&gt; pbutil.&lt;span style=&#34;color:#00a000&#34;&gt;MustMarshal&lt;/span&gt;(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#666&#34;&gt;&amp;amp;&lt;/span&gt;pb.Metadata{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;			NodeID:    &lt;span style=&#34;color:#a2f&#34;&gt;uint64&lt;/span&gt;(member.ID),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;			ClusterID: &lt;span style=&#34;color:#a2f&#34;&gt;uint64&lt;/span&gt;(cl.&lt;span style=&#34;color:#00a000&#34;&gt;ID&lt;/span&gt;()),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; w, err = wal.&lt;span style=&#34;color:#00a000&#34;&gt;Create&lt;/span&gt;(cfg.&lt;span style=&#34;color:#00a000&#34;&gt;WALDir&lt;/span&gt;(), metadata); err &lt;span style=&#34;color:#666&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;nil&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		plog.&lt;span style=&#34;color:#00a000&#34;&gt;Fatalf&lt;/span&gt;(&lt;span style=&#34;color:#b44&#34;&gt;&amp;#34;create wal error: %v&amp;#34;&lt;/span&gt;, err)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;日志数据&#34;&gt;日志数据&lt;/h3&gt;
&lt;p&gt;日志数据的格式，就是&lt;code&gt;raft.proto&lt;/code&gt;中&lt;code&gt;Entry&lt;/code&gt;的格式：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-proto&#34; data-lang=&#34;proto&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;message&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Entry&lt;/span&gt; {&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt;     Term  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;]; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// must be 64-bit aligned for atomic operations
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt;     Index &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;]; &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// must be 64-bit aligned for atomic operations
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; EntryType  Type  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;bytes&lt;/span&gt;      Data  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;4&lt;/span&gt;;&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;}&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;状态数据&#34;&gt;状态数据&lt;/h3&gt;
&lt;p&gt;保存当前“硬状态（HardState）”的记录，HardState包括：当前任期号、当前给哪个节点ID投票、当前提交的最大日志索引。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-proto&#34; data-lang=&#34;proto&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;message&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;HardState&lt;/span&gt; {&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt; term   &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt; vote   &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt; commit &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;3&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;}&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;校验初始值&#34;&gt;校验初始值&lt;/h3&gt;
&lt;p&gt;校验数据这一块，挺有意思的，可以展开好好说一下。&lt;/p&gt;
&lt;p&gt;使用CRC算法来计算数据的校验值，除了需要原始数据之外，还需要一个校验初始值（即校验种子seed），在每个wal文件中，类型为&lt;code&gt;校验初始值&lt;/code&gt;的记录就用于存储这个值。其值和使用方式有以下几点需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个wal文件必须有&lt;code&gt;校验初始值&lt;/code&gt;类型的数据，后续所有写入该wal文件的记录，都使用该初始值来计算CRC校验值。&lt;/li&gt;
&lt;li&gt;第一个wal文件，即序列号为0的wal文件，其校验初始值为0（见wal.go的Create函数）。&lt;/li&gt;
&lt;li&gt;当生成下一个wal文件时，以上一个wal文件的最后一条日志数据的CRC校验码来做为该文件的校验初始值，这样就要求类型为&lt;code&gt;校验初始值&lt;/code&gt;的记录，必须存储在同一个wal文件中第一条日志数据的前面，否则计算出来该日志数据的crc校验码就不准。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/wal-crc.png&#34; alt=&#34;wal文件的校验初始值&#34; title=&#34;wal文件的校验初始值&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，通过这个机制，将多个连续的wal文件“串联”了起来：使用上一个wal文件的最后一个日志数据的crc校验值，来做为下一个wal文件的校验初始值，可以有效的校验同一个项目中wal文件的正确性。&lt;/p&gt;
&lt;h3 id=&#34;快照数据&#34;&gt;快照数据&lt;/h3&gt;
&lt;p&gt;在wal文件中存储的快照数据类型的记录，其中仅存储了当前快照的索引和任期号，而快照的详细数据都放到快照数据文件中存储，下面讲到数据恢复时再展开讨论这部分内容：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-proto&#34; data-lang=&#34;proto&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;message&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Snapshot&lt;/span&gt; {&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt; index &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt; term  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;}&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;快照文件格式&#34;&gt;快照文件格式&lt;/h2&gt;
&lt;p&gt;快照文件的文件名格式为：任期号-索引号.snap（见函数&lt;code&gt;Snapshotter::save&lt;/code&gt;）。每次来一个快照数据，都新建一个快照文件，文件中存储快照数据的格式为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-proto&#34; data-lang=&#34;proto&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;message&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;snapshot&lt;/span&gt; {&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint32&lt;/span&gt; crc  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;bytes&lt;/span&gt; data  &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt;;&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;}&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;即：只存储快照数据及其校验值，数据的具体格式由存储快照数据的使用方来解释。在etcd这个服务里，这份快照数据的格式就是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-proto&#34; data-lang=&#34;proto&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;message&lt;/span&gt; &lt;span style=&#34;color:#00f&#34;&gt;Snapshot&lt;/span&gt; {&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;bytes&lt;/span&gt;            data     &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;;&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;optional&lt;/span&gt; SnapshotMetadata metadata &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;2&lt;/span&gt; [(gogoproto.nullable) &lt;span style=&#34;color:#666&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;false&lt;/span&gt;];&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;&#34;&gt;&lt;/span&gt;}&lt;span style=&#34;&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;数据恢复流程&#34;&gt;数据恢复流程&lt;/h1&gt;
&lt;p&gt;日志、快照数据的落盘，都是为了重启时恢复数据，了解了上面wal以及快照文件的格式，可以来看看数据的恢复流程。&lt;/p&gt;
&lt;p&gt;其大体流程如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;到快照目录中取出最新的一份无错的快照文件，首先取出这个文件中存储的快照数据。（见函数&lt;code&gt;Snapshotter::Load&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;此时，从快照数据中可以反序列化出：快照数据、对应的任期号、索引号。&lt;/li&gt;
&lt;li&gt;根据第二步拿到的快照数据，到wal目录中拿到日志索引号在快照数据索引号之后的日志，遍历满足条件的记录进行数据恢复。（见函数&lt;code&gt;WAL::ReadAll&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面具体来看每种wal记录格式数据在进行数据恢复时的流程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;日志数据：由于还可能存在一小部分小于快照索引的日志，所以恢复时会忽略掉这部分数据。&lt;/li&gt;
&lt;li&gt;状态数据：每一条状态数据都会反序列化出来，以最后一条状态数据为准。&lt;/li&gt;
&lt;li&gt;元数据：前面提到过，同一个服务的元数据必须一致，所以这里会校验元数据前后是否一致，不一致将报错退出数据恢复流程。&lt;/li&gt;
&lt;li&gt;校验初始值数据：可以参见前面关于该类型数据的讲解。&lt;/li&gt;
&lt;li&gt;快照数据：下面详细解释。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;举一个例子来描述前面根据快照文件和WAL文件恢复数据的流程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/wal-snap.png&#34; alt=&#34;WAL与快照文件关系&#34; title=&#34;WAL与快照文件关系&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;快照文件集合为&lt;code&gt;[1-50.snap,1-150.snap]&lt;/code&gt;，取最新的快照文件，即&lt;code&gt;1-150.snap&lt;/code&gt;，而&lt;code&gt;1-50.snap&lt;/code&gt;文件的数据为过期数据。&lt;/li&gt;
&lt;li&gt;由于快照文件中存储的日志索引到150，即在此之前的日志已经全部被压缩到了快照文件中，因此wal文件集合中：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;0-100.wal&lt;/code&gt;中的数据已经全部被压缩。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;1-200.wal&lt;/code&gt;中的数据部分被压缩，恢复数据时要忽略日志索引小于150的日志数据。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;3-300.wal&lt;/code&gt;中的数据都没有被压缩，恢复数据时要如实全部重放该文件的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;前面分析快照数据类型的时候，提到过这个类型的数据在wal文件中的记录，只会存储：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当前快照时对应的任期号。&lt;/li&gt;
&lt;li&gt;当前快照时对应的索引号。&lt;/li&gt;
&lt;li&gt;而具体的快照数据内容存储在快照文件中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也就是说，当生成一份新的快照数据时，将会把这份快照数据相关的以上三部分内容存储到wal和快照文件中。&lt;/p&gt;
&lt;p&gt;所以当恢复数据的时候，此时已经反序列化出快照数据了，这时拿着快照数据读wal文件时，如果读到了快照类型的数据，就会去对比起任期号和索引号是否一致，不一致报错停止恢复流程：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;case&lt;/span&gt; snapshotType: &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 快照数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;			&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;var&lt;/span&gt; snap walpb.Snapshot
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;			pbutil.&lt;span style=&#34;color:#00a000&#34;&gt;MustUnmarshal&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;&amp;amp;&lt;/span&gt;snap, rec.Data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;			&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; snap.Index &lt;span style=&#34;color:#666&#34;&gt;==&lt;/span&gt; w.start.Index { &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 两者的索引相同
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;				&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; snap.Term &lt;span style=&#34;color:#666&#34;&gt;!=&lt;/span&gt; w.start.Term { &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 但是任期号不同
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;					state.&lt;span style=&#34;color:#00a000&#34;&gt;Reset&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;					&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 返回ErrSnapshotMismatch错误
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;					&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;nil&lt;/span&gt;, state, &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;nil&lt;/span&gt;, ErrSnapshotMismatch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;				}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;				&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 保存快照数据匹配的标志位
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;				match = &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;			}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上，解释清楚了wal、快照文件的格式，以及数据恢复的流程。&lt;/p&gt;
&lt;p&gt;因为wal文件和快照文件的读写，都与磁盘读写相关，所以在etcd服务中，将这两个结构体，统一到&lt;code&gt;etcdserver/storage.go&lt;/code&gt;的&lt;code&gt;storage&lt;/code&gt;结构体中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;type&lt;/span&gt; storage &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;struct&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;wal.WAL
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;snap.Snapshotter
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由&lt;code&gt;storage&lt;/code&gt;结构体统一对外提供wal、快照文件的读写接口：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;type&lt;/span&gt; Storage &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;interface&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// Save function saves ents and state to the underlying stable storage.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// Save MUST block until st and ents are on stable storage.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#00a000&#34;&gt;Save&lt;/span&gt;(st raftpb.HardState, ents []raftpb.Entry) &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;error&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// SaveSnap function saves snapshot to the underlying stable storage.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#00a000&#34;&gt;SaveSnap&lt;/span&gt;(snap raftpb.Snapshot) &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;error&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// DBFilePath returns the file path of database snapshot saved with given
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// id.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#00a000&#34;&gt;DBFilePath&lt;/span&gt;(id &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt;) (&lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;string&lt;/span&gt;, &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;error&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// Close closes the Storage and performs finalization.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#00a000&#34;&gt;Close&lt;/span&gt;() &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;error&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下面，解释一下写wal文件中需要注意的一些细节。&lt;/p&gt;
&lt;h1 id=&#34;写优化问题&#34;&gt;写优化问题&lt;/h1&gt;
&lt;h2 id=&#34;数据对齐&#34;&gt;数据对齐&lt;/h2&gt;
&lt;p&gt;每条写入wal的记录，都会将其大小向上8字节对齐，多出来的部分填零：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#00a000&#34;&gt;encodeFrameSize&lt;/span&gt;(dataBytes &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;int&lt;/span&gt;) (lenField &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;uint64&lt;/span&gt;, padBytes &lt;span style=&#34;color:#0b0;font-weight:bold&#34;&gt;int&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	lenField = &lt;span style=&#34;color:#a2f&#34;&gt;uint64&lt;/span&gt;(dataBytes)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// force 8 byte alignment so length never gets a torn write
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	padBytes = (&lt;span style=&#34;color:#666&#34;&gt;8&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;-&lt;/span&gt; (dataBytes &lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;8&lt;/span&gt;)) &lt;span style=&#34;color:#666&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;8&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; padBytes &lt;span style=&#34;color:#666&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;0&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		lenField &lt;span style=&#34;color:#666&#34;&gt;|=&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;uint64&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;0x80&lt;/span&gt;|padBytes) &lt;span style=&#34;color:#666&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#666&#34;&gt;56&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/record.png&#34; alt=&#34;WAL记录数据需8字节对齐&#34; title=&#34;WAL记录数据需8字节对齐&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;写缓冲区&#34;&gt;写缓冲区&lt;/h2&gt;
&lt;p&gt;另外，为了缓解写文件的IO负担，etcd做了一个写优化：落盘的数据首先写到一个内存缓冲区中，只有每次填满了一个page的数据才会进行落盘操作。&lt;/p&gt;
&lt;p&gt;etcd中定义了几个常量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;const minSectorSize = 512&lt;/li&gt;
&lt;li&gt;const walPageBytes = 8 * minSectorSize&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中：&lt;code&gt;minSectorSize&lt;/code&gt;表示一个sector的大小，而&lt;code&gt;walPageBytes&lt;/code&gt;必须为&lt;code&gt;minSectorSize&lt;/code&gt;的整数倍。&lt;/p&gt;
&lt;p&gt;etcd中定义了一个&lt;code&gt;PageWriter&lt;/code&gt;结构体，用于实现写入日志的操作，内部定义了一个循环缓冲区，只有填满一个&lt;code&gt;walPageBytes&lt;/code&gt;大小的数据才会进行落盘。&lt;/p&gt;
&lt;p&gt;下图是写入数据落盘后循环缓冲区的变化的示意图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/cyclic-buffer.png&#34; alt=&#34;写入数据落盘后循环缓冲区的变化&#34; title=&#34;写入数据落盘后循环缓冲区的变化&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;黄色方块表示一个page的空闲空间，绿色方块表示待写入数据，红色方块表示当前已经写入数据的缓冲区。&lt;/li&gt;
&lt;li&gt;刚开始，第一个page已经有部分数据写入，还剩余一部分空闲空间。因此，当写入数据时，只会把写入数据凑齐一个页面大小来落盘。&lt;/li&gt;
&lt;li&gt;落盘完毕之后，第一个page重新变成黄色，即空闲页面，而第二个页面存储了写入数据中没有落盘的部分。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码流程见函数&lt;code&gt;PageWriter::Write&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;从上面的写入落盘流程可以看到，一次写入的数据可能会有一部分落盘，一部分还在内存中，这样当系统发生宕机这部分数据就是被损坏（corruption）的数据。&lt;/p&gt;
&lt;p&gt;因此，etcd中还需要有办法来识别和恢复数据。&lt;/p&gt;
&lt;h2 id=&#34;识别部分写入partial-write数据&#34;&gt;识别部分写入（partial write）数据&lt;/h2&gt;
&lt;p&gt;函数&lt;code&gt;decoder::isTornEntry&lt;/code&gt;用于判断一条记录是否为部分写的损坏数据。&lt;/p&gt;
&lt;p&gt;其原理是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次新创建用于写入记录的wal文件，都会将剩余文件清零。&lt;/li&gt;
&lt;li&gt;读入记录的数据之后，将数据根据不大于每个chunk为&lt;code&gt;minSectorSize&lt;/code&gt;大小的方式，存入chunk数组中。&lt;/li&gt;
&lt;li&gt;遍历这些chunk，如果有一个chunk的数据全部是零，则认为这块数据是部分写入的损坏数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个地方要跟前面落盘流程来对照看：因为每次落盘都是以一个page为单位落盘，而page大小又是&lt;code&gt;minSectorSize&lt;/code&gt;的整数倍，因此以&lt;code&gt;minSectorSize&lt;/code&gt;为一个chunk的大小来判断是否损坏。&lt;/p&gt;
&lt;h2 id=&#34;修复wal文件流程&#34;&gt;修复wal文件流程&lt;/h2&gt;
&lt;p&gt;当进行数据恢复时，可能会出现前面的部分写导致数据损坏问题，etcd会进行如下的修复操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;部分写导致数据损坏都只会出现在最后一个wal文件，因此打开最后一个wal文件进行处理（见函数&lt;code&gt;openLast&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;出现部分写导致损坏的记录，解析过程中都会返回&lt;code&gt;ErrUnexpectedEOF&lt;/code&gt;错误，对于这样的文件：
&lt;ul&gt;
&lt;li&gt;将损坏的文件重命名为&lt;code&gt;原文件名.broken&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;记录下来最后一个无损记录的偏移量，将损坏之后的数据都截断（Truncate）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;只读和只写文件的区别&#34;&gt;只读和只写文件的区别&lt;/h2&gt;
&lt;p&gt;在etcd中，wal文件有两种并不能同时共存的模式：对于同一个wal文件而言，要么处于只读模式，要么处于append写模式，这两种模式不能同时存在。见&lt;code&gt;WAL&lt;/code&gt;结构体的注释：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// WAL is a logical representation of the stable storage.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// WAL is either in read mode or append mode but not both.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// A newly created WAL is in append mode, and ready for appending records.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// A just opened WAL is in read mode, and ready for reading records.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// The WAL will be ready for appending after reading out all the previous records.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;根据上面可能使用缓冲区优化写操作可知，两种模式下在读记录时能容忍的错误级别也不一样：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读模式：读模式下可能读到部分写的数据，所以可以容忍这种错误。&lt;/li&gt;
&lt;li&gt;写模式：写模式下，不能容忍读到部分写的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;switch&lt;/span&gt; w.&lt;span style=&#34;color:#00a000&#34;&gt;tail&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;case&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;nil&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// We do not have to read out all entries in read mode.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;		&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// The last record maybe a partial written one, so
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;		&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// ErrunexpectedEOF might be returned.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;		&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 在只读模式下，可能没有读完全部的记录。最后一条记录可能是只写了一部分，此时就会返回ErrunexpectedEOF错误
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;		&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; err &lt;span style=&#34;color:#666&#34;&gt;!=&lt;/span&gt; io.EOF &lt;span style=&#34;color:#666&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; err &lt;span style=&#34;color:#666&#34;&gt;!=&lt;/span&gt; io.ErrUnexpectedEOF { &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 如果不是EOF以及ErrunexpectedEOF错误的情况就返回错误
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;			state.&lt;span style=&#34;color:#00a000&#34;&gt;Reset&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;			&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;nil&lt;/span&gt;, state, &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;nil&lt;/span&gt;, err
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;default&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 写模式下必须读完全部的记录
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;		&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// We must read all of the entries if WAL is opened in write mode.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;		&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;if&lt;/span&gt; err &lt;span style=&#34;color:#666&#34;&gt;!=&lt;/span&gt; io.EOF { &lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 如果不是EOF错误，说明没有读完数据就报错了，这种情况也是返回错误
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;			state.&lt;span style=&#34;color:#00a000&#34;&gt;Reset&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;			&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;nil&lt;/span&gt;, state, &lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;nil&lt;/span&gt;, err
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;数据落盘的全流程&#34;&gt;数据落盘的全流程&lt;/h1&gt;
&lt;p&gt;以上了解了wal、快照文件的格式，以及写入流程，这里把之前写的不够好的数据落盘流程重新梳理一下。&lt;/p&gt;
&lt;p&gt;在 &lt;a href=&#34;https://www.codedump.info/post/20180922-etcd-raft/#%E8%BE%93%E5%85%A5%E5%8F%8A%E8%BE%93%E5%87%BA&#34;&gt;etcd Raft库解析 - codedump的网络日志&lt;/a&gt;中，曾经指出etcd raft库是通过&lt;code&gt;Ready&lt;/code&gt;结构体，来通知应用层的当前的数据的，不清楚的话可以回看一下之前的内容。在这里，只解释该结构体中与数据落盘相关的几个成员的数据走向流程，即日志数据（成员&lt;code&gt;Entries&lt;/code&gt;）、快照数据（&lt;code&gt;Snapshot&lt;/code&gt;）、已提交日志（&lt;code&gt;CommittedEntries&lt;/code&gt;）。&lt;/p&gt;
&lt;h2 id=&#34;日志数据-1&#34;&gt;日志数据&lt;/h2&gt;
&lt;p&gt;日志数据从客户端提交到落盘的走向是这样的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由客户端提交给服务器（注：只有leader节点才能接收客户端提交的日志数据，其他节点需转发给leader）。&lt;/li&gt;
&lt;li&gt;服务器收到之后，首先调用&lt;code&gt;raftLog.append&lt;/code&gt;函数保存到&lt;code&gt;unstable_log&lt;/code&gt;中，此时日志还是在内存中的，并未落地。&lt;/li&gt;
&lt;li&gt;通过&lt;code&gt;newReady&lt;/code&gt;函数构建&lt;code&gt;Ready&lt;/code&gt;结构体时，将上一步保存下来的日志数据保存到&lt;code&gt;Ready&lt;/code&gt;结构体的&lt;code&gt;Entries&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;应用层收到&lt;code&gt;Ready&lt;/code&gt;结构体之后，调用wal的&lt;code&gt;WAL.Save&lt;/code&gt;接口保存日志数据。这一步做完之后，可以认为日志数据已经落盘了。&lt;/li&gt;
&lt;li&gt;由于数据已经落盘到WAL日志中，所以在应用层通过&lt;code&gt;Node.Advance&lt;/code&gt;接口回调通知raft库时，暂存在&lt;code&gt;unstable_log&lt;/code&gt;中的日志就可以通过函数&lt;code&gt;raftLog.stableTo&lt;/code&gt;删除了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/log-flow.png&#34; alt=&#34;日志数据从提交到落盘的走向&#34; title=&#34;日志数据从提交到落盘的走向&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;已提交日志&#34;&gt;已提交日志&lt;/h2&gt;
&lt;p&gt;raft日志中，需要保存两个日志索引：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;appliedIndex：通知到应用层目前为止最大的日志索引；&lt;/li&gt;
&lt;li&gt;commitIndex：当前已提交日志的最大索引。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这里，总有&lt;code&gt;appliedIndex &amp;lt;= commitIndex&lt;/code&gt;条件成立，即日志总是先被提交成功（即达成一致），才会通知给应用层。&lt;/p&gt;
&lt;p&gt;通知应用层已提交日志的流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调用&lt;code&gt;raftLog.nextEnts()&lt;/code&gt;函数获得当前满足&lt;code&gt;appliedIndex &amp;lt;= commitIndex&lt;/code&gt;条件的日志，存入到&lt;code&gt;Ready.CommittedEntries&lt;/code&gt;通知应用层。&lt;/li&gt;
&lt;li&gt;应用层处理这部分已提交日志。&lt;/li&gt;
&lt;li&gt;调用&lt;code&gt;raftLog.appliedTo()&lt;/code&gt;函数，这里会修改&lt;code&gt;appliedIndex = commitIndex&lt;/code&gt;，即所有日志都已通知应用层。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/appliedIndex.png&#34; alt=&#34;通知应用层已提交日志流程&#34; title=&#34;通知应用层已提交日志流程&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;快照数据-1&#34;&gt;快照数据&lt;/h2&gt;
&lt;p&gt;快照数据由应用层生成，然后将生成的快照数据、当前appliedIndex、配置状态一起交给存储层，保存之后就可以把在该快照之前的数据给删除了：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a2f;font-weight:bold&#34;&gt;func&lt;/span&gt; (rc &lt;span style=&#34;color:#666&#34;&gt;*&lt;/span&gt;raftNode) &lt;span style=&#34;color:#00a000&#34;&gt;maybeTriggerSnapshot&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 生成快照数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	data, err &lt;span style=&#34;color:#666&#34;&gt;:=&lt;/span&gt; rc.&lt;span style=&#34;color:#00a000&#34;&gt;getSnapshot&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 通知存储层快照数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	rc.raftStorage.&lt;span style=&#34;color:#00a000&#34;&gt;CreateSnapshot&lt;/span&gt;(rc.appliedIndex, &lt;span style=&#34;color:#666&#34;&gt;&amp;amp;&lt;/span&gt;rc.confState, data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 保存快照数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	rc.&lt;span style=&#34;color:#00a000&#34;&gt;saveSnap&lt;/span&gt;(snap)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 将快照之前的数据压缩
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	compactIndex &lt;span style=&#34;color:#666&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a2f&#34;&gt;uint64&lt;/span&gt;(&lt;span style=&#34;color:#666&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	rc.raftStorage.&lt;span style=&#34;color:#00a000&#34;&gt;Compact&lt;/span&gt;(compactIndex)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;// 更新快照数据索引，以便下一次生成新的快照数据
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#080;font-style:italic&#34;&gt;&lt;/span&gt;	rc.snapshotIndex = rc.appliedIndex
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;数据的修复&#34;&gt;数据的修复&lt;/h2&gt;
&lt;p&gt;从上面的分析中可以看到，日志数据是在客户端提交之后，就马上落盘到WAL文件中的，不会等到日志在集群中达成一致。&lt;/p&gt;
&lt;p&gt;这样会带来一个问题，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点A认为自己还是集群的leader节点，此时收到客户端日志之后，将数据落盘到WAL文件中。&lt;/li&gt;
&lt;li&gt;落盘之后，节点A将日志同步给集群的其它节点，但是发现自己已经不再是集群的leader节点了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这种情况下，显然第一步已经落盘的日志是无效的，需要进行修复，这时候是怎么操作的呢？&lt;/p&gt;
&lt;p&gt;etcd raft的做法是不回退日志，继续走正常的流程，用新的、正确的日志添加在错误的日志后面，这样回放数据的时候恢复数据。&lt;/p&gt;
&lt;p&gt;继续以上面的例子为例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点A在认为自己是leader的情况下落盘日志到本地WAL中，落盘完毕之后同步给集群内其他节点。&lt;/li&gt;
&lt;li&gt;同步到集群其他节点的过程中，才发现节点A已经不是集群的leader，此时节点A降级为follower节点，并开始从正确的集群节点那里同步日志。&lt;/li&gt;
&lt;li&gt;同步日志的流程中，节点A将收到来自leader节点的正确日志，这些日志也将落盘到节点A的WAL中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第二步中同步日志的流程可以参见 &lt;a href=&#34;https://www.codedump.info/post/20180921-raft/#%E6%96%B0leader%E4%B8%8Efollower%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE&#34;&gt;Raft算法原理 - codedump的网络日志&lt;/a&gt;，这里不再阐述。&lt;/p&gt;
&lt;p&gt;上面的流程之后，节点A的WAL中将存在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;认为自己是leader时已落盘的日志；&lt;/li&gt;
&lt;li&gt;集群leader纠正节点A同步过来的日志。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样，当重启恢复时，会一并将这些日志重放，应用层只要按顺序回放日志即可。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210628-etcd-wal/wal-failback.png&#34; alt=&#34;WAL日志的纠错机制&#34; title=&#34;WAL日志的纠错机制&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点认为自己是leader节点时，落盘到WAL文件中的日志是&lt;code&gt;[(1,10),(1,11)]&lt;/code&gt;，列表中的二元组数据中，第一个元素是任期号，第二个元素是日志索引号。&lt;/li&gt;
&lt;li&gt;在落盘日志之后，节点将数据广播到集群，才发现自己已经不是集群的leader节点，此时集群的leader节点发现从日志10开始，该节点的数据就是不对的，开始同步正确的日志给节点，于是把正确的日志&lt;code&gt;[(2,10),(2,11)]&lt;/code&gt;同步给了节点，这部分日志会添加到前面错误的日志之后。&lt;/li&gt;
&lt;li&gt;假设节点重启恢复，那么会依次重放前面这四条日志，其中前两条日志是错误的日志，但是由于有后面的两条正确日志，最终节点的状态还是会恢复正确状态。&lt;/li&gt;
&lt;li&gt;随着后面日志数据压缩成快照文件，冗余的错误日志的磁盘占用将被解决。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;读者不妨在这里就着这个流程多思考一个问题：做为follower的节点，是什么时候将日志落盘到WAL文件中，是在收到leader节点同步过来的日志时，还是在leader节点通知某个日志已经在集群达成一致？为什么以及流程是怎样的？&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;etcd的wal模块，虽然并没有和raft模块放在一起，但并不是说这一部分就需要应用者来自己实现，这两部分其实是一起打包做为整个etcd raft算法库提供给使用者的。可以认为raft模块提供算法，wal和快照模块提供日志存储读写的接口。&lt;/li&gt;
&lt;li&gt;日志落盘部分，包括wal文件以及快照文件读写这两部分内容，etcd将这两部分统一到&lt;code&gt;Storage&lt;/code&gt;接口统一对外服务。&lt;/li&gt;
&lt;li&gt;raft算法是在收到客户端日志之后就理解落盘日志到wal文件中保存的，如果后面发现出错，就走正常的同步正确日志的流程，将正确的日志添加到后面，这样恢复时重放整个日志，最终节点达成一致的正确状态。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Etcd Raft库的工程化实现</title>
      <link>https://www.codedump.info/post/20210515-raft/</link>
      <pubDate>Sat, 15 May 2021 13:52:08 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20210515-raft/</guid>
      
      <description>&lt;p&gt;最近回顾前几年写的Raft、etcd raft的实现文章，以及重新阅读Raft论文、etcd raft代码，发现之前有些理解不够准确、深刻，但是不打算在原文上做修正，于是写这篇补充的文章做一些另外角度的解释，以前的系列文章可以在下面的链接中找到，本文不打算过多重复原理性的内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180921-raft/&#34;&gt;Raft算法原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20180922-etcd-raft/&#34;&gt;etcd Raft库解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codedump.info/post/20181125-etcd-server/&#34;&gt;Etcd存储的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;
&lt;p&gt;在开始展开讨论前，先介绍这个Raft论文中的示意图，我认为能理解这幅图才能对一致性算法有个全貌的了解：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/statemachine.jpeg&#34; alt=&#34;Etcd Raft与应用层的交互&#34; title=&#34;Etcd Raft与应用层的交互&#34;&gt;&lt;/p&gt;
&lt;p&gt;图中分为两种进程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;server进程：server进程中运行着一致性算法模块、持久化保存的日志、以及按照日志提交的顺序来进行顺序操作的状态机。&lt;/li&gt;
&lt;li&gt;client进程：用于向server提交日志的进程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要说明的是，两种进程都用叠加的矩形来表示，意指系统中这两类进程不止一个。&lt;/p&gt;
&lt;p&gt;一个日志要被正确的提交，图中划分了几步：&lt;/p&gt;
&lt;p&gt;1、client进程提交数据到server进程，server进程将收到的日志数据灌入一致性模块。&lt;/p&gt;
&lt;p&gt;2、一致性模块将日志写入本地WAL，然后同步给集群中其他server进程。&lt;/p&gt;
&lt;p&gt;3、多个节点对某条日志达成一致之后，将修改本地的提交日志索引（commit index）；落盘后的日志按照顺序灌入状态机，只要保证所有server进程上的日志顺序，那么最后状态机的状态肯定就是一致的了。&lt;/p&gt;
&lt;p&gt;4、灌入状态机之后，server进程可以应答客户端。&lt;/p&gt;
&lt;p&gt;所以，本质上，一个使用了一致性算法的库，划分了成了两个不同的模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一致性算法库，这里泛指Raft、Paxos、Zab等一致性协议。这类一致性算法库主要做如下的事情：
&lt;ul&gt;
&lt;li&gt;用户输入库中日志（log），由库根据各自的算法来检测日志的正确性，并且通知上层的应用层。
&lt;ul&gt;
&lt;li&gt;输入到库中的日志维护和管理，算法库中需要知道哪些日志提交、提交成功、以及上层的应用层已经applied过的。当发生错误的时候，某些日志还会进行回滚（rollback）操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;日志的网络收发，这部分属于可选功能。有一些库，比如braft把这个事情也揽过来自己做了，优点是使用者不需要关注这部分功能，缺点是braft和它自带的网络库brpc耦合的很紧密，不可能拆开来使用；另一些raft实现，比如这里重点提到etcd raft实现，并不自己完成网络数据收发的工作，而是通知应用层，由应用层自己实现。&lt;/li&gt;
&lt;li&gt;日志的持久化存储：这部分也属于可选功能。前面说过，一致性算法库中维护了未达成一致的日志缓冲区，达成一致的日志才通知应用层，因此在这里不同的算法库又有了分歧，braft也是自己完成了日志持久化的工作，etcd raft则是将这部分工作交给了应用层。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;应用层：即工作在一致性算法之上的库使用者，这个就比上图中的“状态机”：只有达成一致并且落盘的数据才灌入应用层，只要保证灌入应用层的日志顺序一致那么最后的状态就是一致的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总体来看，一个一致性算法库有以下必选和可选功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入日志进行处理的算法（必选）。&lt;/li&gt;
&lt;li&gt;日志的维护和管理（必选）。&lt;/li&gt;
&lt;li&gt;日志（包括快照）数据的网络收发（可选）。&lt;/li&gt;
&lt;li&gt;日志（包括快照）的持久化存储（可选）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要特别说明的是，即便是后面两个工作是可选的，但是可选还是必选的区别在于，这部分工作是一致性算法库自己完成，还是由算法库通知给上面的应用层去完成，并不代表这部分工作可以完全不做。&lt;/p&gt;
&lt;p&gt;在下表中列列举了etcd raft和braft在这几个特性之间的区别：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;th&gt;etcd raft&lt;/th&gt;
&lt;th&gt;braft&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;raft一致性算法&lt;/td&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;日志的维护和管理&lt;/td&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;日志数据的网络收发&lt;/td&gt;
&lt;td&gt;交由应用层&lt;/td&gt;
&lt;td&gt;自己实现&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;日志数据的持久化存储&lt;/td&gt;
&lt;td&gt;交由应用层&lt;/td&gt;
&lt;td&gt;自己实现&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;优缺点&lt;/td&gt;
&lt;td&gt;松耦合，易于验证、测试；需要应用者做更多的事情&lt;/td&gt;
&lt;td&gt;与其rpc库紧耦合，难拆分；应用层做的事情不多，易于用来做服务&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;两种实现各有自己的优缺点，braft类实现更适合提供一个需要集成raft的服务时，可以直接用来实现服务；etcd raft类的实现，由于与网络、存储层耦合不紧密，易于进行测试，更适合拿来做为库使用。&lt;/p&gt;
&lt;p&gt;如果把前面的一致性算法的几个特性做一个抽象，我认为一致性算法库本质上就是一个“维护操作日志的算法库，只要大家都按照相同的顺序将日志灌入应用层”就好，其工作原理大体如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/co-algo.png&#34; alt=&#34;一致性算法的本质&#34; title=&#34;一致性算法的本质&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果把问题抽象成这样的话，那么本质上，所谓的“一致性算法库”跟一个经常看到的tcp、kcp甚至是一个应用层的协议栈也就没有什么区别了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大家都要维护一个数据区：只有确认过正确的，才会抛给上一层。以TCP协议算法来说，比如发送但未确认的数据由协议栈的缓冲区维护，如果超时还未等到对端的确认，将发起超时重传等，这些都是每种协议算法的具体细节，但是本质上这些协议都要维护一个未确认数据的缓冲区。一致性算法在数据的维护上会更复杂一些，一是参与确认的节点不止通信的C/S两端，需要集群中半数以上节点的确认；同时，在未确认之前日志需要首先落盘，在提交成功之后再抛给应用层。&lt;/li&gt;
&lt;li&gt;只要保证所有参与的节点，都以相同的数据灌入日志给应用层，那么得到的结果将最终一致。&lt;/li&gt;
&lt;li&gt;确认的流程是可以pipeline异步化的，提交日志的进程并不需要一直等待日志被提交成功，而是提交之后等待。不妨以下面的流程来做解释：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/pipeline.png&#34; alt=&#34;流水线异步化的日志提交流程&#34; title=&#34;流水线异步化的日志提交流程&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clientA和clientB分别提交了两条日志数据，但是并没有阻塞等待日志提交成功，而是提交之后就继续别的操作了。&lt;/li&gt;
&lt;li&gt;server将两条日志数据同步出去，达成一致之后再分别通知两个client日志提交成功。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这里，client上通知日志提交成功的机制可以有很多，以etcd来说，会给每个提交的日志对应一个channel，提交成功之后会通过这个channel进行通知，也会给这个日志加一个定时器，超过时间仍未收到通知则认为提交失败。&lt;/p&gt;
&lt;h1 id=&#34;etcd-raft的实现&#34;&gt;etcd raft的实现&lt;/h1&gt;
&lt;p&gt;有了上面对一致性算法库的大体了解，下面可以详细看看etcd raft的实现了。&lt;/p&gt;
&lt;h2 id=&#34;概述-1&#34;&gt;概述&lt;/h2&gt;
&lt;p&gt;前面提到过，etcd raft库的实现中，并不自己实现网络数据收发、提交成功的数据持久化等工作，这些工作留给了应用层来自己实现，所以需要一个机制来通知应用层。etcd raft中将需要通知给应用层的数据封装在&lt;code&gt;Ready&lt;/code&gt;结构体中，其中包括如下的成员：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;成员名称&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;类型&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;SoftState&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;SoftState&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;软状态，软状态易变且不需要保存在WAL日志中的状态数据，包括：集群leader、节点的当前状态&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;HardState&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;HardState&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;硬状态，与软状态相反，需要写入持久化存储中，包括：节点当前Term、Vote、Commit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;ReadStates&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;[]ReadStates&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;用于读一致性的数据，后续会详细介绍&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Entries&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;[]pb.Entry&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;在向其他集群发送消息之前需要先写入持久化存储的日志数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Snapshot&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;pb.Snapshot&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;需要写入持久化存储中的快照数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CommittedEntries&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;[]pb.Entry&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;需要输入到状态机中的数据，这些数据之前已经被保存到持久化存储中了&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Messages&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;[]pb.Message&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;需要发送出去的数据&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;有了数据，还需要raft线程与上面的应用层线程交互的机制，这部分封装在&lt;code&gt;node&lt;/code&gt;结构体中。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;node&lt;/code&gt;结构体实现&lt;code&gt;Node&lt;/code&gt;接口，该接口用于表示Raft集群中的一个节点。在&lt;code&gt;node&lt;/code&gt;结构体中，实现了以下几个核心的channel，由于与外界进行通信：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;propc chan pb.Message：用于本地提交日志数据的channel。&lt;/li&gt;
&lt;li&gt;recvc chan pb.Message：用于接收来自集群中其他节点日志数据的channel。&lt;/li&gt;
&lt;li&gt;readyc chan Ready：用于本地Raft库通知应用层哪些数据已经准备好了，因此应用层需要关注readyc这个channel才能获得从Raft线程中提交的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;去掉一些不太重要的接口，&lt;code&gt;Node&lt;/code&gt;接口中有如下的核心函数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tick()：应用层每次tick时需要调用该函数，将会由这里驱动raft的一些操作比如选举等，至于tick的单位是多少由应用层自己决定，只要保证是恒定时间都会来调用一次就好了。&lt;/li&gt;
&lt;li&gt;Propose(ctx context.Context, data []byte) error：提议写入数据到日志中，可能会返回错误。&lt;/li&gt;
&lt;li&gt;Step(ctx context.Context, msg pb.Message) error：将消息msg灌入状态机。&lt;/li&gt;
&lt;li&gt;Ready() &amp;lt;-chan Ready：返回通知&lt;code&gt;Ready&lt;/code&gt;结构体变更的channel，应用层需要关注这个channel，当发生变更时将其中的数据进行操作。&lt;/li&gt;
&lt;li&gt;Advance()：Advance函数是当使用者已经将上一次Ready数据处理之后，调用该函数告诉raft库可以进行下一步的操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在&lt;code&gt;node&lt;/code&gt;结构体的实现中，无论是通过&lt;code&gt;Propose&lt;/code&gt;函数还是&lt;code&gt;Step&lt;/code&gt;函数提交到Raft算法库的消息，最终都是调用内部的&lt;code&gt;step&lt;/code&gt;函数的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/etcd-raft.png&#34; alt=&#34;Etcd Raft与应用层的交互&#34; title=&#34;Etcd Raft与应用层的交互&#34;&gt;&lt;/p&gt;
&lt;p&gt;以上图来说明应用层与raft之间的交互流程，注意：etcd的实现中，raft是一个独立的线程，与应用层之间通过上面介绍的几个channel进行交互。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先看最中间的部分，本地提交的数据通过&lt;code&gt;propc&lt;/code&gt;channel通知raft线程，而应用层从外部网络接收到的日志数据通过&lt;code&gt;recvc&lt;/code&gt;通知raft线程。但是不管是哪个channel，最终都是通过上面提到的&lt;code&gt;step&lt;/code&gt;函数将日志数据灌入raft线程中。&lt;/li&gt;
&lt;li&gt;最右边是raft线程通知应用线程有哪些日志数据已经确认提交完毕等（&lt;code&gt;Ready&lt;/code&gt;结构体中不限于确认提交数据，该类型数据在上面已经列举出来），应用层可以通过&lt;code&gt;Ready&lt;/code&gt;数据来持久化数据等操作。&lt;/li&gt;
&lt;li&gt;最左边表示应用层线程要通过&lt;code&gt;Advance&lt;/code&gt;函数通知raft线程自己已经持久化了某些数据，这时候可以推动raft线程库中的日志缓冲区的变更。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以一个简单的消息流程来继续解释上面的流程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用层收到索引为N的消息，此时通过&lt;code&gt;recvc&lt;/code&gt;channel提交给Raft线程。&lt;/li&gt;
&lt;li&gt;Raft线程验证消息是正确的，于是需要广播给集群中的其他节点，此时会：
&lt;ul&gt;
&lt;li&gt;首先在Raft的日志缓冲区中保存下来这个消息，因为这个日志还未提交成功。&lt;/li&gt;
&lt;li&gt;将日志消息放入&lt;code&gt;Ready&lt;/code&gt;结构体的&lt;code&gt;Messages&lt;/code&gt;成员中，通知应用层，这样应用层就将该成员中的消息转发给集群中的其他节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Raft线程继续获得从应用层下发下来的消息，当发现下发的消息中，索引为N的消息已经被集群中半数以上的节点确认过，此时就可以认为该消息能被持久化了，将日志消息放入&lt;code&gt;Ready&lt;/code&gt;结构体的&lt;code&gt;CommittedEntries&lt;/code&gt;成员中，以通知应用层该消息可以被持久化了。&lt;/li&gt;
&lt;li&gt;每次应用层持久化了某些消息之后，都会通过&lt;code&gt;Advance&lt;/code&gt;函数通知Raft线程，这样Raft线程可以将这部分已经被持久化的消息从消息缓冲区中删除，因为前面提到过消息缓冲区仅仅是用来保存还未持久化的消息的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个工作流程是pipeline化，即应用层某一次提交了索引为N的消息，并不需要一直等待该消息提交成功，而是可以返回继续做别的事情，当raft线程判断消息可以被提交时，再通过&lt;code&gt;Ready&lt;/code&gt;结构体来通知应用层。&lt;/p&gt;
&lt;p&gt;以上大体描述了etcd中，应用层线程与raft线程的交互流程，下面详细看看raft线程的实现。&lt;/p&gt;
&lt;h2 id=&#34;raft算法&#34;&gt;Raft算法&lt;/h2&gt;
&lt;p&gt;raft算法中，有不同的角色存在：candidate、follower、leader，本质上Raft算法是输入日志数据进行处理，而每种角色对不同类型的日志数据需要有不同的处理。&lt;/p&gt;
&lt;p&gt;所以，etcd raft的实现中，针对三种不同的角色，通过修改函数指针的方式在切换了不同角色时的处理，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/role-algo.png&#34; alt=&#34;不同角色的Raft算法处理&#34; title=&#34;不同角色的Raft算法处理&#34;&gt;&lt;/p&gt;
&lt;p&gt;具体的算法细节，不打算在本文中展开，可以回头上上面给出来的几篇文章。&lt;/p&gt;
&lt;h2 id=&#34;数据管理&#34;&gt;数据管理&lt;/h2&gt;
&lt;p&gt;数据管理分为以下几部分阐述：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;未持久化数据缓冲区&lt;/li&gt;
&lt;li&gt;持久化数据内存映像&lt;/li&gt;
&lt;li&gt;数据的持久化&lt;/li&gt;
&lt;li&gt;数据流动的全流程&lt;/li&gt;
&lt;li&gt;节点进度的管理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面一一展开。&lt;/p&gt;
&lt;h3 id=&#34;未持久化数据缓冲区&#34;&gt;未持久化数据缓冲区&lt;/h3&gt;
&lt;p&gt;前面提到过，Raft算法中还必须要做的是维护未确认数据的缓冲区数据，每当其中的一部分数据被确认，缓冲区的窗口随之发生移动，这就类似TCP协议算法中的滑动窗口。&lt;/p&gt;
&lt;p&gt;etcd raft中，管理未确认数据放在了&lt;code&gt;unstable&lt;/code&gt;结构体（log_unstable.go）中，其内部维护三个成员：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;snapshot *pb.Snapshot：保存还没有持久化的快照数据&lt;/li&gt;
&lt;li&gt;entries []pb.Entry：保存还未持久化的日志数据。&lt;/li&gt;
&lt;li&gt;offset uint64：保存快照和日志数组的分界线。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，未持久化数据分为两部分：一部分是快照数据snapshot，另一部分就是日志数据数组。两者不会同时存在，快照数据只会在启动时进行快照数据恢复时存在，当应用层使用快照数据进行恢复之后，raft切换为可以接收日志数据的状态，后续的日志数据都会写到&lt;code&gt;entrise&lt;/code&gt;数组中了，而两者的分界线就是&lt;code&gt;offset&lt;/code&gt;变量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/unstable.png&#34; alt=&#34;未持久化数据&#34; title=&#34;未持久化数据&#34;&gt;&lt;/p&gt;
&lt;p&gt;由于是”未持久化数据的缓冲区“，因此这其中的数据可能会发生回滚（rollback）现象，因此&lt;code&gt;unstable&lt;/code&gt;结构体需要支持能回滚的操作，见函数&lt;code&gt;truncateAndAppend&lt;/code&gt;：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;func (u *unstable) truncateAndAppend(ents []pb.Entry) {
	// 先拿到这些数据的第一个索引
	after := ents[0].Index
	switch {
	case after == u.offset+uint64(len(u.entries)):
		// 如果正好是紧接着当前数据的，就直接append
		// after is the next index in the u.entries
		// directly append
		u.entries = append(u.entries, ents...)
	case after &amp;lt;= u.offset:
		u.logger.Infof(&amp;#34;replace the unstable entries from index %d&amp;#34;, after)
		// The log is being truncated to before our current offset
		// portion, so set the offset and replace the entries
		// 如果比当前偏移量小，那用新的数据替换当前数据，需要同时更改offset和entries
		u.offset = after
		u.entries = ents
	default:
		// truncate to after and copy to u.entries
		// then append
		// 到了这里，说明 u.offset &amp;lt; after &amp;lt; u.offset+uint64(len(u.entries))
		// 那么新的entries需要拼接而成
		u.logger.Infof(&amp;#34;truncate the unstable entries before index %d&amp;#34;, after)
		u.entries = append([]pb.Entry{}, u.slice(u.offset, after)...)
		u.entries = append(u.entries, ents...)
	}
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;函数中分为三种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果传入的日志数据，刚好跟当前数据紧挨着（after == u.offset+uint64(len(u.entries))），就可以直接进行append操作。&lt;/li&gt;
&lt;li&gt;如果传入的日志数据的第一条数据索引不大于当前的offset（after &amp;lt;= u.offset），说明数据发生了回滚，直接用新的数据替换旧的数据。&lt;/li&gt;
&lt;li&gt;其他情况，说明u.offset &amp;lt; after &amp;lt; u.offset+uint64(len(u.entries))，这是新的未持久化数据由这两部分数据各取其中一部分数据拼装而成。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;持久化数据内存映像&#34;&gt;持久化数据内存映像&lt;/h3&gt;
&lt;p&gt;但是，仅仅有未持久化数据还不够，有时候有一些数据已经落盘，但是还需要进行查询、读取等操作。于是，etcd raft又提供了一个&lt;code&gt;Storage&lt;/code&gt;接口，该接口有面对不同的组件有不同的行为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于Raft库，该接口仅仅只有读操作。（如下图中的黄色函数）&lt;/li&gt;
&lt;li&gt;对于etcd 服务来说，还提供了写操作，包括：增加日志数据、生成快照、压缩数据。（如下图中的蓝色函数）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，这个接口及其默认实现&lt;code&gt;MemoryStorage&lt;/code&gt;，呈现了稍微不太一样的行为，以致于我最开始没有完全理解：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/stable.png&#34; alt=&#34;持久化数据的内存映像&#34; title=&#34;持久化数据的内存映像&#34;&gt;&lt;/p&gt;
&lt;p&gt;因为持久化数据的内存映像，提供给Raft库的仅仅只需要读操作，所以&lt;code&gt;Storage&lt;/code&gt;接口就只有读操作，多出来的写操作只会在应用层中才会用到，因此这些写接口并没有放在公用的接口中。&lt;/p&gt;
&lt;p&gt;了解了持久化和未持久化数据的表示之后，etcd raft库将两者统一到&lt;code&gt;raftLog&lt;/code&gt;这个结构体中：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/raftlog.png&#34; alt=&#34;不同视角下的raftlog&#34; title=&#34;不同视角下的raftlog&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据的持久化&#34;&gt;数据的持久化&lt;/h3&gt;
&lt;p&gt;以上解释两种缓冲区的作用，数据最终还是需要持久化到磁盘上的，那么，这个持久化数据的时机在哪里？&lt;/p&gt;
&lt;p&gt;答案：当客户端提交数据时，etcd Raft库就通过&lt;code&gt;Ready&lt;/code&gt;结构体的&lt;code&gt;Entries&lt;/code&gt;成员通知应用层，将这些提交的数据进行持久化了。&lt;/p&gt;
&lt;p&gt;有代码为证。&lt;/p&gt;
&lt;p&gt;首先来看&lt;code&gt;raft&lt;/code&gt;中如何生成&lt;code&gt;Ready&lt;/code&gt;数据：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;func newReady(r *raft, prevSoftSt *SoftState, prevHardSt pb.HardState) Ready {
	rd := Ready{
		// entries保存的是没有持久化的数据数组
		Entries:          r.raftLog.unstableEntries(),
		// 保存committed但是还没有applied的数据数组
		CommittedEntries: r.raftLog.nextEnts(),
		// 保存待发送的消息
		Messages:         r.msgs,
	}
	// ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到，&lt;code&gt;raft&lt;/code&gt;库中将未持久化数据塞到了&lt;code&gt;Entries&lt;/code&gt;数组中，而已经达成一致可以提交的日志数据放入到&lt;code&gt;CommittedEntries&lt;/code&gt;数组中。&lt;/p&gt;
&lt;p&gt;以&lt;code&gt;etcd&lt;/code&gt;代码中自带的&lt;code&gt;raftexample&lt;/code&gt;目录中的例子代码来看应用层在收到&lt;code&gt;Ready&lt;/code&gt;数据后的做法：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;func (rc *raftNode) serveChannels() {
		case rd := &amp;lt;-rc.node.Ready():
			// 将HardState，entries写入持久化存储中
			rc.wal.Save(rd.HardState, rd.Entries)
			if !raft.IsEmptySnap(rd.Snapshot) {
				// 如果快照数据不为空，也需要保存快照数据到持久化存储中
				rc.saveSnap(rd.Snapshot)
				rc.raftStorage.ApplySnapshot(rd.Snapshot)
				rc.publishSnapshot(rd.Snapshot)
			}
			rc.raftStorage.Append(rd.Entries)
			rc.transport.Send(rd.Messages)
			if ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok {
				rc.stop()
				return
			}
			rc.maybeTriggerSnapshot()
			rc.node.Advance()
	// ....
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rc.wal.Save(rd.HardState, rd.Entries)：将客户端提交数据的数据写入wal中。&lt;/li&gt;
&lt;li&gt;rc.raftStorage.Append(rd.Entries)：这里的&lt;code&gt;raftStorage&lt;/code&gt;即前面提到的持久化数据缓冲区的&lt;code&gt;Storage&lt;/code&gt;接口，由&lt;code&gt;MemoryStorage&lt;/code&gt;接口实现，这一步将这些客户端提交的数据也写入持久化缓冲区的内部映像。&lt;/li&gt;
&lt;li&gt;rc.publishEntries(rc.entriesToApply(rd.CommittedEntries))：这个调用分为两步，第一步调用&lt;code&gt;entriesToApply&lt;/code&gt;是要从已达成一致的日志数据中过滤出真正可以进行apply的日志，因为里面的一些日志可能已经被应用层apply过，第二步将第一步过滤出来的日志数据通知给应用层。在&lt;code&gt;raftexample&lt;/code&gt;这个示例代码中，最终这些已经达成一致的数据，会被遍历生成KV内存数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里有一个问题：客户端提交过来的数据，还未达成集群内半数节点的一致，这时候就去做落盘操作，如果提交过程中发现出了问题，实际这条数据并不能最终达成一致，那么已落盘的数据怎么办？&lt;/p&gt;
&lt;p&gt;在这里，&lt;code&gt;etcd&lt;/code&gt;落盘客户端提交的数据时，是写入到WAL文件中的，后面发生了错误，如leader变成了follower时，日志需要进行了回滚操作等，也还是将那些正确的日志继续添加到WAL日志后面，服务如果重启，就是把这些日志按照顺序重放（replay）一遍，这里不可避免的会有一些冗余的操作，但是随着快照文件的产生，这个问题已经不大了。&lt;/p&gt;
&lt;p&gt;其次，不论是前面提到的&lt;code&gt;未持久化数据缓冲区&lt;/code&gt;，还是&lt;code&gt;持久化数据缓冲区&lt;/code&gt;，在往缓冲区中添加日志的函数实现中，都会去判断日志是否发生了回滚，会将当前传入的日志按照正确的日志索引放到缓冲区合适的位置。&lt;code&gt;未持久化数据缓冲区&lt;/code&gt;这部分操作在函数&lt;code&gt;unstable.truncateAndAppend&lt;/code&gt;中，&lt;code&gt;持久化数据缓冲区&lt;/code&gt;这部分操作在函数&lt;code&gt;MemoryStorage.Append&lt;/code&gt;中，感兴趣的可以去看看具体的实现，在这里就不再展开了。&lt;/p&gt;
&lt;h3 id=&#34;数据流动的全流程&#34;&gt;数据流动的全流程&lt;/h3&gt;
&lt;p&gt;以上解释了客户端提交的数据在两个缓冲区、持久化存储、以及最终达成一致之后给应用层的过程，下面以例子分别来解释客户端提交数据的流程以及快照数据恢复的流程。&lt;/p&gt;
&lt;h4 id=&#34;客户端提交数据的流程&#34;&gt;客户端提交数据的流程&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/wal.png&#34; alt=&#34;客户端提交数据的流动&#34; title=&#34;客户端提交数据的流动&#34;&gt;&lt;/p&gt;
&lt;p&gt;1、客户端提交数据给服务器。&lt;/p&gt;
&lt;p&gt;2、接着看这条数据走过的”存储“路径：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1、首先，`raft`库会首先将日志数据写入`未持久化数据缓冲区`。

2、由于`未持久化数据缓冲区`中有新增的数据，会通过`Ready`结构体通知给应用层。

3、应用层收到`Ready`结构体之后，将其中的数据写入WAL持久化存储，然后更新这块数据到`已持久化数据缓冲区`。

4.1、持久化完毕后，应用层通过`Advance`接口通知`Raft`库这些数据已经持久化，于是raft库修改`未持久化数据缓冲区`将客户端刚提交的数据从这个缓冲区中删除。

4.2、持久化完毕之后，除了通知删除`未持久化数据缓冲区`，还讲数据通过网络同步给集群中其他节点。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、集群中半数节点对该提交数据达成了一致，可以应答给客户端了。&lt;/p&gt;
&lt;h4 id=&#34;启动时使用快照数据恢复流程&#34;&gt;启动时使用快照数据恢复流程&lt;/h4&gt;
&lt;p&gt;下面以例子来实际解释etcd raft中数据在未持久化缓存、wal日志、持久化数据内容映像中的流动：&lt;/p&gt;
&lt;p&gt;1、节点N启动，加入到集群中，此时发现N上面没有数据，于是集群中的leader节点会首先通过rpc消息将快照数据发送给节点N。&lt;/p&gt;
&lt;p&gt;2、节点N收到快照数据，首先会保存到未持久化数据缓存中。&lt;/p&gt;
&lt;p&gt;3、Raft通过&lt;code&gt;Ready&lt;/code&gt;结构体通知应用层有快照数据。&lt;/p&gt;
&lt;p&gt;4、应用层（也就是etcdserver）将快照数据写入wal持久化存储中，这一步可以理解为将快照数据落盘。&lt;/p&gt;
&lt;p&gt;5、落盘之后，调用&lt;code&gt;MemoryStorage&lt;/code&gt;结构体的&lt;code&gt;ApplySnapshot&lt;/code&gt;将快照数据保存到持久化数据内存映像中。&lt;/p&gt;
&lt;p&gt;6、（图中未给出）调用Raft库的&lt;code&gt;Advance&lt;/code&gt;接口通知raft库传递过来的&lt;code&gt;Ready&lt;/code&gt;结构体数据已经操作完毕，这时候对应的，raft库就会把第二步中保存到未持久化数据缓存的快照数据给删除了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/snapshot.png&#34; alt=&#34;快照数据的流动&#34; title=&#34;快照数据的流动&#34;&gt;&lt;/p&gt;
&lt;p&gt;以上是快照数据的流动过程，在节点N接收并持久化快照数据后，后面就可以接收正常的日志了，日志数据的流动过程跟快照数据实际是差不多的，就不再阐述了。&lt;/p&gt;
&lt;p&gt;从上面的流程中也可以看出，应用层也就是etcdserver的持久化数据，只有wal日志而已，情况确实是这样的，其接口和实现如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;type Storage interface {
	// Save function saves ents and state to the underlying stable storage.
	// Save MUST block until st and ents are on stable storage.
	Save(st raftpb.HardState, ents []raftpb.Entry) error
	// SaveSnap function saves snapshot to the underlying stable storage.
	SaveSnap(snap raftpb.Snapshot) error
	// DBFilePath returns the file path of database snapshot saved with given
	// id.
	DBFilePath(id uint64) (string, error)
	// Close closes the Storage and performs finalization.
	Close() error
}

type storage struct {
	*wal.WAL
	*snap.Snapshotter
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;Storage&lt;/code&gt;接口是etcdserver持久化数据的接口，其保存的数据有两个接口：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Save(st raftpb.HardState, ents []raftpb.Entry) error：保存日志数据。&lt;/li&gt;
&lt;li&gt;SaveSnap(snap raftpb.Snapshot) error：保存快照数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而&lt;code&gt;Storage&lt;/code&gt;接口由下面的&lt;code&gt;storage&lt;/code&gt;结构体来实现，其又分为两部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wal：用于实现WAL日志的读写。&lt;/li&gt;
&lt;li&gt;snap：用于实现快照数据的读写。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里就不展开讨论了。&lt;/p&gt;
&lt;h3 id=&#34;节点进度的管理&#34;&gt;节点进度的管理&lt;/h3&gt;
&lt;p&gt;前面提到过，一致性算法与TCP之类的协议，本质上都需要管理未确认数据的缓冲区，但是不同的是，参与一致性算法确认的成员，不会像一般的点对点通信协议那样只有两个，在raft算法中，leader节点除了要维护未持久化缓冲区之外，还需要维护一个数据结构，用于保存集群中其他节点的进度，这部分数据在etcd raft中保存在结构体&lt;code&gt;Progress&lt;/code&gt;中，我将我之前阅读过程中加上的注释一并贴出来：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 该数据结构用于在leader中保存每个follower的状态信息，leader将根据这些信息决定发送给节点的日志
// Progress represents a follower’s progress in the view of the leader. Leader maintains
// progresses of all followers, and sends entries to the follower based on its progress.
type Progress struct {
	// Next保存的是下一次leader发送append消息时传送过来的日志索引
	// 当选举出新的leader时，首先初始化Next为该leader最后一条日志+1
	// 如果向该节点append日志失败，则递减Next回退日志，一直回退到索引匹配为止

	// Match保存在该节点上保存的日志的最大索引，初始化为0
	// 正常情况下，Next = Match + 1
	// 以下情况下不是上面这种情况：
	// 1. 切换到Probe状态时，如果上一个状态是Snapshot状态，即正在接收快照，那么Next = max(pr.Match+1, pendingSnapshot+1)
	// 2. 当该follower不在Replicate状态时，说明不是正常的接收副本状态。
	//    此时当leader与follower同步leader上的日志时，可能出现覆盖的情况，即此时follower上面假设Match为3，但是索引为3的数据会被
	//    leader覆盖，此时Next指针可能会一直回溯到与leader上日志匹配的位置，再开始正常同步日志，此时也会出现Next != Match + 1的情况出现
	Match, Next uint64
	// State defines how the leader should interact with the follower.
	//
	// When in ProgressStateProbe, leader sends at most one replication message
	// per heartbeat interval. It also probes actual progress of the follower.
	//
	// When in ProgressStateReplicate, leader optimistically increases next
	// to the latest entry sent after sending replication message. This is
	// an optimized state for fast replicating log entries to the follower.
	//
	// When in ProgressStateSnapshot, leader should have sent out snapshot
	// before and stops sending any replication message.

	// ProgressStateProbe：在每次heartbeat消息间隔期最多发一条同步日志消息给该节点
	// ProgressStateReplicate：正常的接受副本数据状态。当处于该状态时，leader在发送副本消息之后，
	// 就修改该节点的next索引为发送消息的最大索引+1
	// ProgressStateSnapshot：接收副本状态
	State ProgressStateType
	// Paused is used in ProgressStateProbe.
	// When Paused is true, raft should pause sending replication message to this peer.
	// 在状态切换到Probe状态以后，该follower就标记为Paused，此时将暂停同步日志到该节点
	Paused bool

	// PendingSnapshot is used in ProgressStateSnapshot.
	// If there is a pending snapshot, the pendingSnapshot will be set to the
	// index of the snapshot. If pendingSnapshot is set, the replication process of
	// this Progress will be paused. raft will not resend snapshot until the pending one
	// is reported to be failed.
	// 如果向该节点发送快照消息，PendingSnapshot用于保存快照消息的索引
	// 当PendingSnapshot不为0时，该节点也被标记为暂停状态。
	// raft只有在这个正在进行中的快照同步失败以后，才会重传快照消息
	PendingSnapshot uint64

	// RecentActive is true if the progress is recently active. Receiving any messages
	// from the corresponding follower indicates the progress is active.
	// RecentActive can be reset to false after an election timeout.
	RecentActive bool

	// inflights is a sliding window for the inflight messages.
	// Each inflight message contains one or more log entries.
	// The max number of entries per message is defined in raft config as MaxSizePerMsg.
	// Thus inflight effectively limits both the number of inflight messages
	// and the bandwidth each Progress can use.
	// When inflights is full, no more message should be sent.
	// When a leader sends out a message, the index of the last
	// entry should be added to inflights. The index MUST be added
	// into inflights in order.
	// When a leader receives a reply, the previous inflights should
	// be freed by calling inflights.freeTo with the index of the last
	// received entry.
	// 用于实现滑动窗口，用来做流量控制
	ins *inflights
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;总结来说，&lt;code&gt;Progress&lt;/code&gt;结构体做的工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维护follower节点的match、next索引，以便知道下一次从哪里开始同步数据。&lt;/li&gt;
&lt;li&gt;维护着follower节点当前的状态。&lt;/li&gt;
&lt;li&gt;同步快照数据的状态。&lt;/li&gt;
&lt;li&gt;流量控制，避免follower节点超载。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体的算法细节，就不在这里贴出了。&lt;/p&gt;
&lt;h2 id=&#34;网络数据的收发以及日志的持久化&#34;&gt;网络数据的收发以及日志的持久化&lt;/h2&gt;
&lt;p&gt;网络数据的收发以及日志的持久化，这两部分在etcd raft库中，并不是由raft库来实现，而是通过&lt;code&gt;Ready&lt;/code&gt;结构体来通知应用层，由应用层来完成。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;这里将上面的几部分总结如下，有了整体的理解才能更好的了解细节：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20210515-raft/summary.png&#34; alt=&#34;Raft算法几要素在etcd raft中的实现&#34; title=&#34;Raft算法几要素在etcd raft中的实现&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>服务调用的演进历史</title>
      <link>https://www.codedump.info/post/20190629-service-history/</link>
      <pubDate>Sat, 29 Jun 2019 12:47:07 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20190629-service-history/</guid>
      
      <description>&lt;blockquote&gt;
&lt;p&gt;这是2019年给组内分享时整理的一篇服务调用演进历史的科普文。写作本文的时候，我自己最大的感受是：如果能清楚理解演化历史中的一些原则和思路，就会发现现在的变化并不新鲜。它们不是今天才有，也不会止于今天的演化。在技术大发展的今天，更多的关注本质才能让我们不至于在变化中失去方向。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个题目稍微有点大，纯粹是一篇科普文，将我所了解到的解决“服务调用”相关的技术演进历史简述一下，本文专注于演化过程中每一步的为什么（Why）和是什么（What）上面，尽量不在技术细节（How）上面做太多深入。&lt;/p&gt;
&lt;h1 id=&#34;服务的三要素&#34;&gt;服务的三要素&lt;/h1&gt;
&lt;p&gt;一般而言，一个网络服务包括以下的三个要素：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;地址：调用方根据地址访问到网络接口。地址包括以下要素：IP地址、服务端口、服务协议（TCP、UDP，etc）。&lt;/li&gt;
&lt;li&gt;协议格式：协议格式指的是该协议都有哪些字段，由接口提供者与协议调用者协商之后确定下来。&lt;/li&gt;
&lt;li&gt;协议名称：或者叫协议类型，因为在同一个服务监听端口上面，可能同时提供多种接口服务于调用方，这时候需要协议类型（名称）来区分不同的网络接口。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要说明在服务地址中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP地址提供了在互联网上找到这台机器的凭证。&lt;/li&gt;
&lt;li&gt;协议以及服务端口提供了在这台机器上找到提供服务的进程的凭证。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/service-address.png&#34; alt=&#34;service-address&#34; title=&#34;service address&#34;&gt;&lt;/p&gt;
&lt;p&gt;这都属于TCPIP协议栈的知识点，不在这里深入详述。&lt;/p&gt;
&lt;p&gt;下图中，以最简单的一个HTTP请求，来拆解请求URL中的服务要素：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/http-request.png&#34; alt=&#34;http-request&#34; title=&#34;http-request&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;http：指明使用的是哪种应用层协议，同类型的还有“https”、“ftp”等。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.abc.com&#34;&gt;www.abc.com&lt;/a&gt;：域名地址，最终会由DNS域名解析服务器解析成数字的IP地址。&lt;/li&gt;
&lt;li&gt;8080：前面解析成数字化的IP地址之后，就可以访问到具体提供服务的机器上，但是上面提供服务的进程可能有很多，这时候就需要端口号来告诉协议栈到底是访问哪个进程提供的服务了。&lt;/li&gt;
&lt;li&gt;hello：该服务进程中，可能提供多个接口供访问，所以需要接口名+协议（即前面的http）告诉进程访问哪个协议的哪个接口。&lt;/li&gt;
&lt;li&gt;msg=world：不同的接口，需要的参数不同，最后跟上的查询参数（query param）告诉服务请求该接口服务时传入的参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上，简单的把网络服务的几个要素进行了描述。&lt;/p&gt;
&lt;p&gt;这里还需要对涉及到服务相关的一些名词做解释。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务实例：服务对应的IP地址加端口的简称。需要访问服务的时候，需要先寻址知道该服务每个运行实例的地址加端口，然后才能建立连接进行访问。&lt;/li&gt;
&lt;li&gt;服务注册：某个服务实例宣称自己提供了哪些服务，即某个IP地址+端口都提供了哪些服务接口。&lt;/li&gt;
&lt;li&gt;服务发现：调用方通过某种方式找到服务提供方，即知道服务运行的IP地址加端口。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;基于ip地址的调用&#34;&gt;基于IP地址的调用&lt;/h1&gt;
&lt;p&gt;最初的网络服务，通过原始的IP地址暴露给调用者。这种方式有以下的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP地址是难于记忆并且无意义的。&lt;/li&gt;
&lt;li&gt;另外，从上面的服务三要素可以看到，IP地址其实是一个很底层的概念，直接对应了一台机器上的一个网络接口，如果直接使用IP地址进行寻址，更换机器就变的很麻烦。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“尽量不使用过于底层的概念来提供服务”，是这个演化流程中的重要原则，好比在今天已经很少能够看到直接用汇编语言编写代码的场景了，取而代之的，就是越来越多的抽象，本文中就展现了服务调用这一领域在这个过程中的演进流程。&lt;/p&gt;
&lt;p&gt;在现在除非是测试阶段，否则已经不能直接以IP地址的形式将服务提供出去了。&lt;/p&gt;
&lt;h1 id=&#34;域名系统&#34;&gt;域名系统&lt;/h1&gt;
&lt;p&gt;前面的IP地址是给主机做为路由器寻址的数字型标识，并不好记忆。此时产生了域名系统，与单纯提供IP地址相比，域名系统由于使用有意义的域名来标识服务，所以更容易记忆。另外，还可以更改域名所对应的IP地址，这为变换机器提供了便利。有了域名之后，调用方需要访问某个网络服务时，首先到域名地址服务中，根据DNS协议将域名解析为相应的IP地址，再根据返回的IP地址来访问服务。&lt;/p&gt;
&lt;p&gt;从这里可以看到，由于多了一步到域名地址服务查询映射IP地址的流程，所以多了一步解析，为了减少这一步带来的影响，调用方会缓存解析之后的结果，在一段时间内不过期，这样就省去了这一步查询的代价。&lt;/p&gt;
&lt;h1 id=&#34;协议的接收与解析&#34;&gt;协议的接收与解析&lt;/h1&gt;
&lt;p&gt;以上通过域名系统，已经解决了服务IP地址难以记忆的问题，下面来看协议格式解析方面的演进。&lt;/p&gt;
&lt;p&gt;一般而言，一个网络协议包括两部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;协议包头：这里存储协议的元信息（meta infomation），其中可能会包括协议类型、报体长度、协议格式等。需要说明的是，包头一般为固定大小，或者有明确的边界（如HTTP协议中的\r\n结束符），否则无法知道包头何时结束。&lt;/li&gt;
&lt;li&gt;协议包体：具体的协议内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;无论是HTTP协议，又或者是自定义的二进制网络协议，大体都由这两部分组成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/protocol-format.png&#34; alt=&#34;protocol-format&#34; title=&#34;protocol format&#34;&gt;&lt;/p&gt;
&lt;p&gt;由于很多时候不能一口气接收完毕客户端的协议数据，因此在接收协议数据时，一般采用状态机来做协议数据的接收：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/protocol-statemachine.png&#34; alt=&#34;protocol-statemachine&#34; title=&#34;protocol statemachine&#34;&gt;&lt;/p&gt;
&lt;p&gt;接收完毕了网络数据，在协议解析方面却长期停滞不前。一个协议，有多个字段（field），而这些不同的字段有不同的类型，简单的raw类型（如整型、字符串）还好说，但是遇到复杂的类型如字典、数组等就比较麻烦。&lt;/p&gt;
&lt;p&gt;当时常见的手段有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用json或者xml这样的数据格式。好处是可视性强，表达起上面的复杂类型也方便，缺陷是容易被破解，传输过去的数据较大。&lt;/li&gt;
&lt;li&gt;自定义二进制协议。每个公司做大了，在这一块难免有几个类似的轮子。笔者见过比较典型的是所谓的TLV格式（Type-Length-Value），自定义二进制格式最大的问题出现在协议联调与协商的时候，由于可视性比较弱，有可能这边少了一个字段那边多了一个字段，给联调流程带来麻烦。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面的问题一直到Google的Protocol Buffer（以下简称PB）出现之后才得到很大的改善。PB出现之后，也有很多类似的技术出现，如Thrift、MsgPack等，不在这里阐述，将这一类技术都以PB来描述。&lt;/p&gt;
&lt;p&gt;与前面的两种手段相比，PB具有以下的优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用proto格式文件来定义协议格式，proto文件是一个典型的DSL（domain-specific language）文件，文件中描述了协议的具体格式，每个字段都是什么类型，哪些是可选字段哪些是必选字段。有了proto文件之后，C\S两端是通过这个文件来进行协议的沟通交流的，而不是具体的技术细节。&lt;/li&gt;
&lt;li&gt;PB能通过proto文件生成各种语言对应的序列化反序列化代码，给跨语言调用提供了方便。&lt;/li&gt;
&lt;li&gt;PB自己能够对特定类型进行数据压缩，减少数据大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/pb.png&#34; alt=&#34;pb&#34; title=&#34;pb&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;服务网关&#34;&gt;服务网关&lt;/h1&gt;
&lt;p&gt;有了前面的演化之后，写一个简单的单机服务器已经不难。然而，当随着访问量的增大，一台机器已经不足以支撑所有的请求，此时就需要横向扩展多加一些业务服务器。&lt;/p&gt;
&lt;p&gt;而前面通过域名访问服务的架构就遇到了问题：如果有多个服务实例可以提供相同的服务，那么势必需要在DNS的域名解析中将域名与多个地址进行绑定。这样的方案就有如下的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何检查这些实例的健康情况，同时在发现出现问题的时候增删服务实例地址？即所谓的服务高可用问题。&lt;/li&gt;
&lt;li&gt;把这些服务实例地址都暴露到外网，会不会涉及到安全问题？即使可以解决安全问题，那么也需要每台机器都做安全策略。&lt;/li&gt;
&lt;li&gt;由于DNS协议的特点，增删服务实例并不是实时的，有时候会影响到业务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了解决这些问题，就引入了反向代理网关这一组件。它提供如下的功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负载均衡功能：根据某些算法将请求分派到服务实例上。&lt;/li&gt;
&lt;li&gt;提供管理功能，可以给运维管理员增减服务实例。&lt;/li&gt;
&lt;li&gt;由于它决定了服务请求流量的走向，因此还可以做更多的其他功能：灰度引流、安全防攻击(如访问黑白名单、卸载SSL证书)等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/gateway.png&#34; alt=&#34;gateway&#34; title=&#34;gateway&#34;&gt;&lt;/p&gt;
&lt;p&gt;有四层和七层负载均衡软件，其中四层负载均衡这里介绍LVS，七层负载均衡介绍Nginx。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/tcpip.png&#34; alt=&#34;tcpip&#34; title=&#34;tcpip&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图是简易的TCPIP协议栈层次图，其中LVS工作在四层，即请求来到LVS这里时是根据四层协议来决定请求最终走到哪个服务实例；而Nginx工作在七层，主要用于HTTP协议，即根据HTTP协议本身来决定请求的走向。需要说明的是，Nginx也可以工作在四层，但是这么用的地方不是很多，可以参考nginx的stream模块。&lt;/p&gt;
&lt;h2 id=&#34;做为四层负载均衡的lvs&#34;&gt;做为四层负载均衡的LVS&lt;/h2&gt;
&lt;p&gt;（由于LVS有好几种工作模式，并不是每一种我都很清楚，以下表述仅针对Full NAT模式，下面的表述或者有误）&lt;/p&gt;
&lt;p&gt;LVS有如下的组成部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Direct Server（以下简称DS）：前端暴露给客户端进行负载均衡的服务器。&lt;/li&gt;
&lt;li&gt;Virtual Ip地址（以下简称VIP）：DS暴露出去的IP地址，做为客户端请求的地址。&lt;/li&gt;
&lt;li&gt;Direct Ip地址（以下简称DIP）：DS用于与Real Server交互的IP地址。&lt;/li&gt;
&lt;li&gt;Real Server（以下简称RS）：后端真正进行工作的服务器，可以横向扩展。&lt;/li&gt;
&lt;li&gt;Real IP地址（以下简称RIP）：RS的地址。&lt;/li&gt;
&lt;li&gt;Client IP地址（以下简称CIP）：Client的地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/lvs.png&#34; alt=&#34;lvs&#34; title=&#34;lvs&#34;&gt;&lt;/p&gt;
&lt;p&gt;客户端进行请求时，流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用VIP地址访问DS，此时的地址二元组为&amp;lt;src:CIP,dst:VIP&amp;gt;。&lt;/li&gt;
&lt;li&gt;DS根据自己的负载均衡算法，选择一个RS将请求转发过去，在转发过去的时候，修改请求的源IP地址为DIP地址，让RS看上去认为是DS在访问它，此时的地址二元组为&amp;lt;src:DIP,dst:RIP A&amp;gt;。&lt;/li&gt;
&lt;li&gt;RS处理并且应答该请求，这个回报的源地址为RS的RIP地址，目的地址为DIP地址，此时的地址二元组为&amp;lt;src:RIP A,dst:DIP&amp;gt;。&lt;/li&gt;
&lt;li&gt;DS在收到该应答包之后，将报文应答客户端，此时修改应答报文的源地址为VIP地址，目的地址为CIP地址，此时的地址二元组为&amp;lt;src:VIP,dst:CIP&amp;gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;做为七层负载均衡的nginx&#34;&gt;做为七层负载均衡的Nginx&lt;/h2&gt;
&lt;p&gt;在开始展开讨论之前，需要简单说一下正向代理和反向代理。&lt;/p&gt;
&lt;p&gt;所谓的正向代理（proxy），我的理解就是在客户端处的代理。如浏览器中的可以配置的访问某些网站的代理，就属于正向代理，但是一般而言不会说正向代理而是代理，即默认代理都是正向的。&lt;/p&gt;
&lt;p&gt;而反向代理（reverse proxy）就是挡在服务器端前面的代理，比如前面LVS中的DS服务器就属于一种反向代理。为什么需要反向代理，大体的原因有以下的考量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负载均衡：希望在这个反向代理的服务器中，将请求均衡的分发到后面的服务器中。&lt;/li&gt;
&lt;li&gt;安全：不想向客户端暴露太多的服务器地址，统一接入到这个反向代理服务器中，在这里做限流、安全控制等。&lt;/li&gt;
&lt;li&gt;由于统一接入了客户端的请求，所以在反向代理的接入层可以做更多的控制策略，比如灰度流量发布、权重控制等等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;反向代理与所谓的gateway、网关等，我认为没有太多的差异，只是叫法不同而已，做的事情都是类似的。&lt;/p&gt;
&lt;p&gt;Nginx应该是现在用的最多的HTTP 七层负载均衡软件，在Nginx中，可以通过在配置的server块中定义一个域名，然后将该域名的请求绑定到对应的Upstream中，而实现转发请求到这些Upstream的效果。&lt;/p&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;upstream hello {
       server A:11001;
       server B:11001;
}

location / {
            root   html;
            index  index.html index.htm;
            proxy_pass http://hello;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是最简单的Nginx反向代理配置，实际线上一个接入层背后可能有多个域名，如果配置变动的很大，每次域名以及对应的Upstream的配置修改都需要人工干预，效率会很慢。这时候就要提到一个叫DevOps的名词了，我的理解就是开发各种便于自动化运维工具的工程师。&lt;/p&gt;
&lt;p&gt;有了上面的分析，此时一个提供七层HTTP访问接口的服务架构大体是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/gate.png&#34; alt=&#34;gate&#34; title=&#34;gate&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;服务发现与rpc&#34;&gt;服务发现与RPC&lt;/h1&gt;
&lt;p&gt;前面已经解决单机服务器对外提供服务的大部分问题，来简单回顾：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;域名系统解决了需要记住复杂的数字IP地址的问题。&lt;/li&gt;
&lt;li&gt;PB类软件库的出现解决协议定义解析的痛点。&lt;/li&gt;
&lt;li&gt;网关类组件解决客户端接入以及服务器横向扩展等一系列问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然而一个服务，通常并不见得只由本身提供服务就可以，服务过程中可能还涉及到查询其他服务的流程，常见的如数据类服务如Mysql、Redis等，这一类供服务内调用查询的服务被成为内部的服务，通常并不直接暴露到外网去。&lt;/p&gt;
&lt;p&gt;面向公网的服务，一般都是以域名的形式提供给外部调用者，然而对于服务内部之间的互相调用，域名形式还不够，其原因在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DNS服务发现的粒度太粗，只能到IP地址级别，而服务的端口还需要用户自己维护。&lt;/li&gt;
&lt;li&gt;对于服务的健康状况的检查，DNS的检查还不够，需要运维的参与。&lt;/li&gt;
&lt;li&gt;DNS对于服务状态的收集很欠缺，而服务状态最终应该是反过来影响服务被调用情况的。&lt;/li&gt;
&lt;li&gt;DNS的变更需要人工的参与，不够智能以及自动化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上，内网间的服务调用，通常而言会自己实现一套“服务发现”类的系统，其包括以下几个组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务发现系统：用于提供服务的寻址、注册能力，以及对服务状态进行统计汇总，根据服务情况更改服务的调用情况。比如，某个服务实例的响应慢了，此时分配给该实例的流量响应的就会少一些。而由于这个系统能提供服务的寻址能力，所以一些寻址策略就可以在这里做，比如灰度某些特定的流量只能到某些特定的实例上，比如可以配置每个实例的流量权重等。&lt;/li&gt;
&lt;li&gt;一套与该服务系统搭配使用的RPC库，其提供以下功能：
&lt;ul&gt;
&lt;li&gt;服务提供方：使用RPC库注册自己的服务到服务发现系统，另外上报自己的服务情况。&lt;/li&gt;
&lt;li&gt;服务调用方：使用RPC库进行服务寻址，实时从服务发现系统那边获取最新的服务调度策略。&lt;/li&gt;
&lt;li&gt;提供协议的序列化、反序列化功能，负载均衡的调用策略、熔断限流等安全访问策略，这部分对于服务的提供方以及调用方都适用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/name-system.png&#34; alt=&#34;name-system&#34; title=&#34;name system&#34;&gt;&lt;/p&gt;
&lt;p&gt;有了这套服务发现系统以及搭配使用的RPC库之后，来看看现在的服务调用是什么样的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;写业务逻辑的，再也不用关注服务地址、协议解析、服务调度、自身服务情况上报等等与业务逻辑本身并没有太多关系的工作，专注于业务逻辑即可。&lt;/li&gt;
&lt;li&gt;服务发现系统一般还有与之搭配的管理后台界面，可以通过这里对服务的策略进行修改查看等操作。&lt;/li&gt;
&lt;li&gt;对应的还会有服务监控系统，对应的这是一台实时采集服务数据进行计算的系统，有了这套系统服务质量如何一目了然。&lt;/li&gt;
&lt;li&gt;服务健康状态的检查完全自动化，在状况不好的时候对服务进行降级处理，人工干预变少，更加智能以及自动化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在服务的架构又演进成了这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/arch.png&#34; alt=&#34;arch&#34; title=&#34;arch&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;servicemesh&#34;&gt;ServiceMesh&lt;/h1&gt;
&lt;p&gt;架构发展到上面的程度，实际上已经能够解决大部分的问题了。这两年又出现了一个很火的概念：ServiceMesh，中文翻译为“服务网格”，来看看它又能解决什么问题。&lt;/p&gt;
&lt;p&gt;前面的服务发现系统中，需要一个与之配套的RPC库，然而这又会有如下的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果需要支持多语言，该怎么做？每个语言实现一个对应的RPC库吗？&lt;/li&gt;
&lt;li&gt;库的升级很麻烦，比如RPC库本身出了安全漏洞，比如需要升级版本，一般推动业务方去做这个升级是很难的，尤其是系统做大了之后。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，由于RPC库是嵌入到进程之中的组件，所以以上问题很麻烦，于是就想出了一个办法：将原先的一个进程拆分成两个进程，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190629-service-history/servicemesh.png&#34; alt=&#34;servicemesh&#34; title=&#34;servicemesh&#34;&gt;&lt;/p&gt;
&lt;p&gt;在服务mesh化之前，服务调用方实例通过自己内部的RPC库来与服务提供方实例进行通信。&lt;/p&gt;
&lt;p&gt;在服务mesh化之后，会与服务调用方同机部署一个local Proxy也就是ServiceMesh的proxy，此时服务调用的流量会先走到这个proxy，再由它完成原先RPC库响应的工作。至于如何实现这个流量的劫持，答案是采用iptables，将特定端口的流量转发到proxy上面即可。&lt;/p&gt;
&lt;p&gt;有了这一层的分拆，将业务服务与负责RPC库作用的Proxy分开来，上面的两个痛点问题就变成了对每台物理机上面的mesh proxy的升级维护问题，多语言也不是问题了，因为都是通过网络调用完成的RPC通信，而不是进程内使用RPC库。&lt;/p&gt;
&lt;p&gt;然而这个方案并不是什么问题都没有的，最大的问题在于，多了这一层的调用之后，势必有影响原来的响应时间。&lt;/p&gt;
&lt;p&gt;截止目前（2019.6月），ServiceMesh仍然还是一个概念大于实际的产品。&lt;/p&gt;
&lt;p&gt;从上面的演进历史可以看到，所谓的“中间层理论”，即“Any problem in computer science can be solved by another layer of indirection（计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决）”在这个过程中被广泛使用，比如为了解决IP地址难于记忆的问题，引入了域名系统，比如为了解决负载均衡问题引入了网关，等等。然而每引入一个中间层，势必带来另外的影响，比如ServiceMesh多一次到Proxy的调用，如何权衡又是另外的问题了。&lt;/p&gt;
&lt;p&gt;另外，回到最开始的服务三要素中，可以看到整个演化的历史也是逐渐屏蔽了下层组件的流程，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;域名的出现屏蔽了IP地址。&lt;/li&gt;
&lt;li&gt;服务发现系统屏蔽协议及端口号。&lt;/li&gt;
&lt;li&gt;PB类序列化库屏蔽了使用者自己对协议的解析。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，演进流程让业务开发者更加专注在业务逻辑上，这类的演进流程不只发生在今天，也不会仅仅发生在今天，未来类似的演进也将再次发生。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>《数据密集型应用系统设计》第九章《一致性与共识》笔记</title>
      <link>https://www.codedump.info/post/20190406-ddia-chapter09-consistency-and-consensus/</link>
      <pubDate>Thu, 18 Apr 2019 08:40:34 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20190406-ddia-chapter09-consistency-and-consensus/</guid>
      
      <description>&lt;h1 id=&#34;一致性保证&#34;&gt;一致性保证&lt;/h1&gt;
&lt;p&gt;最终一致性（eventual consistency）：如果停止更新数据，等待一段时间（时间长度未知），则最终所有读请求将返回相同的内容。&lt;/p&gt;
&lt;p&gt;然而最终一致性是一种非常弱的一致性保证，因为无法知道何时（when）系统会收敛。而在收敛之前，读请求都可能返回任何值。&lt;/p&gt;
&lt;h1 id=&#34;可线性化linearizability&#34;&gt;可线性化（Linearizability）&lt;/h1&gt;
&lt;p&gt;可线性化（Lineariazability），也被称为原子一致性（atomic consistency）、强一致性（strong consistency），其基本的思想是让一个系统看起来好像只有一个数据副本，且所有的操作都是原子的。有了这个保证，应用程序不需要再关系系统内部有多少个副本。&lt;/p&gt;
&lt;p&gt;在一个可线性化的系统中，一旦客户端成功提交写请求，所有客户端的读请求一定能看到刚刚写入的值。这一保证让客户端认为只有一个副本，这样任何一次读取都能读到最新的值，而不是过期的数据。&lt;/p&gt;
&lt;p&gt;下图来解释在一个非线性化的系统中，可能出现什么问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190406-ddia-chapter09-consistency-and-consensus/9-1.jpg&#34; alt=&#34;9-1&#34; title=&#34;9-1&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，alice和bob同时等待2014年世界杯决赛的结果。在宣布最终比分之后，alice看到了最终的结果，然后将此结果告诉了bob，bob马上在自己的手机上刷新想看最新的结果，但是却返回了过期的数据，显示当前比赛还在进行中。&lt;/p&gt;
&lt;h2 id=&#34;如何实现可线性化&#34;&gt;如何实现可线性化？&lt;/h2&gt;
&lt;p&gt;前面只是简单介绍了可线性化的思想：使系统看起来只有一个数据副本。为了更好的理解可线性化，看下面的图示例子。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190406-ddia-chapter09-consistency-and-consensus/9-2.jpg&#34; alt=&#34;9-2&#34; title=&#34;9-2&#34;&gt;&lt;/p&gt;
&lt;p&gt;在上图中，分为两种操作：针对某个值进行read和write操作。&lt;/p&gt;
&lt;p&gt;客户端A的第一次和最后一次read操作，分别返回0和1，这没有问题，因为在这两次操作中间有客户端C的write操作将数据x更新为了1。&lt;/p&gt;
&lt;p&gt;但是，在写操作还在进行的时候，如果读操作返回的值会来回的跳变，即某次读请求返回的是旧值，而某一次又返回的是新值，这对于一个可线性化系统而言是不可接受的。&lt;/p&gt;
&lt;p&gt;为此，需要加入一个约束条件，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190406-ddia-chapter09-consistency-and-consensus/9-3.jpg&#34; alt=&#34;9-3&#34; title=&#34;9-3&#34;&gt;&lt;/p&gt;
&lt;p&gt;在上图中，箭头表示时序依赖关系。即先有客户端A的第二次read(x)操作，再有客户端B的第二次read(x)操作。客户端A的第二次读请求返回了x的新值1，而客户端B在这次读请求之后也去读x的值，此时应该返回的也是新值1。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;即：在一个可线性化的系统中，有一个很重要的约束条件，在写操作开始和结束之间必然存在一个时间段，此时读到x的值会在旧值与新值之间跳变。但是，如果某个客户端的读请求返回了新值，那么即使这时写操作还未真正完成，后续的所有读请求也应该返回新值。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以下的例子进一步解释可线性化的操作，除了读写之外又引入另一种操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cas(x, old, new)：表示一次原子的比较-设置操作（compare-and-set，简称CAS），如果此时x的值为old，则原子设置这个值为new；否则保留原有值不变，这个操作的返回值表示这次x原有的值是否为old，即设置操作是否发生。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190406-ddia-chapter09-consistency-and-consensus/9-4.jpg&#34; alt=&#34;9-4&#34; title=&#34;9-4&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中的每个操作都有一个竖线，表示可能的执行时间点。可线性化要求，连接这些标记的竖线，必须总是按时间（即从左到右）向前移动，而不能向后移动。因此，一旦新值被写入或读取，所有后续的值读到的都是新值，直到被覆盖。&lt;/p&gt;
&lt;p&gt;在上图中，有一些细节需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端B首先read(x)，接下来客户端D write(x,0)，然后客户端A在write(x,1)，而最终返回给客户端B的值是1（客户端A写入的值）。这个结果是可能的，这意味着数据库执行的顺序是：先处理客户端D的写请求，然后是A的写入操作，最后才是B的读请求。虽然这个顺序并不是上面请求的顺序，但是考虑到请求有网络延迟的情况，比如可能B的请求延迟很大，导致在两次写请求之后才打到数据库，因此只能返回最后A写入的值。&lt;/li&gt;
&lt;li&gt;客户端A在收到写请求的应答之前，B就收到了新的值1，这表明写入成功。这也是可能的，这并不意味着B的读请求在A的写请求之前发生，只是意味着由于网络延迟等原因导致A稍后才收到响应。&lt;/li&gt;
&lt;li&gt;客户端的最后一次读取不满足线性化。因为在此之前，A已经读到了由C进行cas(x,2,4)操作设置的新值4，B的最后一次读请求在A读取到4之后，因此B不能读到旧值2了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意可线性化（Lineariazability）和可串行化（Serializability）的区别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可串行化：可串行化是事务的隔离属性，其中每个事务可以读写多个对象。用来确保事务执行的结果与串行执行的结果完全相同，即使串行执行的顺序可能与事务实际执行顺序不同。&lt;/li&gt;
&lt;li&gt;可线性化：可线性化是读写寄存器（单个对象）的最新值保证，并不要求将操作组合到事务中，因此无法避免写倾斜等问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数据库可以同时支持可串行化与可线性化，这种组合又被称为严格的可串行化或者强的单副本可串行化（strong one-copy Serializability）。&lt;/p&gt;
&lt;h2 id=&#34;线性化的依赖条件&#34;&gt;线性化的依赖条件&lt;/h2&gt;
&lt;h1 id=&#34;实现线性化系统&#34;&gt;实现线性化系统&lt;/h1&gt;
&lt;p&gt;由于线性化本质上意味着“表现的好像只有一个数据副本，其上的操作都是原子操作”。最简单的方案就是只用一个数据副本，但是这样无法容错。&lt;/p&gt;
&lt;p&gt;系统容错最常见的方法是采用复制机制，回顾一下之前的多种复制方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主从复制（部分支持可线性化）：主从复制系统中，只有主节点写入数据，而从节点保存副本数据。如果从主节点或者同步更新的从节点读取数据，则可以满足线性化。&lt;/li&gt;
&lt;li&gt;共识算法（可线性化）。&lt;/li&gt;
&lt;li&gt;多主复制（不可线性化）：用于同时在多个节点上执行写入操作，并将数据异步复制到其他节点，因此可能产生写入冲突。&lt;/li&gt;
&lt;li&gt;无主复制（可能不可线性化）：对于无主节点复制的系统，依赖于具体的quorum配置，以及如何定义强一致性，可能并不能保证线性化。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;线性化与quorum&#34;&gt;线性化与quorum&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190406-ddia-chapter09-consistency-and-consensus/9-6.jpg&#34; alt=&#34;9-6&#34; title=&#34;9-6&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，x的初始值为0，写客户端向所有三副本（n=3，w=3）写入更新x为1。而客户端A从两个节点（r=2）读数据，其中一个节点返回1，而客户端B则从两个节点都得到了0。&lt;/p&gt;
&lt;p&gt;显然这是违反线性化要求的：客户端B在客户端A之后读取数据，但是仍然得到了旧值。&lt;/p&gt;
&lt;p&gt;总而言之，最安全的假定是类似Dynamo风格的无主复制系统无法保证线性化。&lt;/p&gt;
&lt;h2 id=&#34;线性化的代价&#34;&gt;线性化的代价&lt;/h2&gt;
&lt;h3 id=&#34;cap理论&#34;&gt;CAP理论&lt;/h3&gt;
&lt;p&gt;在一个数据中心内部，主要存在不可靠的网络，就可能会违背线性化的风险，需要做出权衡考虑：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果应用要求线性化，但是由于网络的原因，某些副本和其他副本断开连接之后无法继续处理请求，就必须等待网络恢复，或者直接返回错误。无论哪种方式，结果都是服务不可用。&lt;/li&gt;
&lt;li&gt;如果应用不要求线性化，那么断开连接之后，每个副本可独立处理请求，此时服务可用但是行为不符合线性化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，不要求线性化的应用更能容忍网络故障。这种思路称为“CAP定力”。&lt;/p&gt;
&lt;p&gt;CAP定理，表示一致性、可用性、分区容错性，三者之间只能同时满足两个特性。不过，这种表示具有误导性，因为网络分区是一种故障，不管喜欢与否，都可能发生，而无法选择或者逃避这个问题。&lt;/p&gt;
&lt;p&gt;网络在发生故障以后，必须从一致性和可用性之间做出选择。因此，更准确的应该是“网络分区情况下，选择一致还是可用”。&lt;/p&gt;
&lt;h1 id=&#34;顺序保证&#34;&gt;顺序保证&lt;/h1&gt;
&lt;p&gt;因果关系对所发生的事件施加了某种顺序：发送消息先于收到消息，问题出现在答案之前等。&lt;/p&gt;
&lt;p&gt;如果系统满足因果关系所规定的顺序，称之为“因果一致性（causally consistent）”。&lt;/p&gt;
&lt;h2 id=&#34;因果顺序并非全序&#34;&gt;因果顺序并非全序&lt;/h2&gt;
&lt;p&gt;全序关系（total order）支持任何两个元素之间进行比较，即对于任意元素，总是可以指出哪个大哪个小。&lt;/p&gt;
&lt;p&gt;但是有些集合并不符合全序关系，例如集合{a,b}大于集合{b,c}么？因为它们都不是对方的子集，所以无法直接进行比较。这种情况称之为不可比较（incomparable），数学集合只能是偏序关系（partially ordered）。&lt;/p&gt;
&lt;p&gt;全序和偏序的差异也体现在数据库一致性问题中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可线性化：在一个可线性化的系统中，存在全序操作关系。系统的行为好像就只有一个数据副本，且每个操作都是原子的，这意味着任何两个操作，都可以指出操作的先后顺序来。&lt;/li&gt;
&lt;li&gt;因果关系：如果两个操作都没有发送在对方之前，那么两个操作是并发关系（concurrent）。即，如果两个事件是因果关系，那么这两个事件就可以被排序；而并发的事件则无法排序比较。因此因果关系是偏序，而非全序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据上面的定义，在可线性化的系统中不存在并发操作。一定有一个时间线将所有操作都全序执行，可能存在多个请求处于等待处理的状态，但是数据存储保证了在特定的时间点执行特定的操作，所以是单个时间轴、单个数据副本，没有并发。&lt;/p&gt;
&lt;p&gt;并发意味着时间线会出现分支和合并，而不同分支上的操作无法直接比较，一定有一个时间线将所有操作都全序执行。&lt;/p&gt;
&lt;h2 id=&#34;可线性化强于因果一致性&#34;&gt;可线性化强于因果一致性&lt;/h2&gt;
&lt;p&gt;可线性化意味着一定满足因果关系，任何可线性化的系统一定能够正确满足因果关系。&lt;/p&gt;
&lt;p&gt;在许多情况下，系统只要能够满足因果一致性就足够了，可线性化的代价太高。&lt;/p&gt;
&lt;h2 id=&#34;序列号排序&#34;&gt;序列号排序&lt;/h2&gt;
&lt;p&gt;可以使用序列号或时间戳来排序事件。时间戳不一定来自物理时钟，可以只是逻辑时钟。&lt;/p&gt;
&lt;p&gt;特别地，还可以按照与因果关系一致的顺序来创建序列号：保证如果操作A发生在B之前，那么A的序列号一定比B更小。&lt;/p&gt;
&lt;p&gt;在主从复制数据库中，复制日志中可以定义与因果关系一致的写全序关系，即由主节点为每个操作递增计数器，从而系统中的每个操作都赋值一个单调递增的序列号。&lt;/p&gt;
&lt;p&gt;但是如果系统中不存在唯一的主节点，比如是多主或无主类型的数据库，可以采用以下的方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个节点独立生成自己的一组序列号，比如两个节点一个节点生成奇数，另一个节点生成偶数。另外还可以在序列号中加入所属节点的唯一标识，确保不同的节点用于不会生成相同的序列号。&lt;/li&gt;
&lt;li&gt;可以把时间戳信息（物理时钟）加到每个操作上。&lt;/li&gt;
&lt;li&gt;可以预先分配序列号的区间范围。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lamport时间戳&#34;&gt;Lamport时间戳&lt;/h2&gt;
&lt;p&gt;如下图所示，每个节点都有唯一的标识符，且每个节点都有一个计数器来记录自己处理的请求总数，Lamport时间戳是一个值对：（计数器，节点ID），这样就能确保每个Lamport时间戳都是唯一的。&lt;/p&gt;
&lt;p&gt;给定两个Lamport时间戳，可以这样来对比得到全序关系：计数器大的时间戳大，如果计数器相同，那么节点ID大的时间戳更大。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190406-ddia-chapter09-consistency-and-consensus/9-8.jpg&#34; alt=&#34;9-8&#34; title=&#34;9-8&#34;&gt;&lt;/p&gt;
&lt;p&gt;Lamport时间戳与版本向量的区别在于：版本向量用于区分两个操作是并发的还是因果依赖的，而Lamport时间戳用于确保全序关系。即使Lamport时间戳不能用于区分两个操作属于并发关系，还是因果依赖关系。&lt;/p&gt;
&lt;p&gt;但是，即便有了全序的时间戳排序，有一些问题仍然无法解决。&lt;/p&gt;
&lt;p&gt;比如注册一个网站时，要求用户名需要唯一，虽然两个同样名字的创建用户请求过来，可以根据全序关系来决定究竟哪个请求在先抢占了这个用户名，但是这并不够，因为这个是在请求写入之后才进行的判断，在应答写请求时无法立刻知道结果，因为还需要查询所有节点，如果有节点失败的情况下还需要等待，等等。&lt;/p&gt;
&lt;p&gt;为了解决类似的问题，就需要引入”全序关系广播“这个概念了。&lt;/p&gt;
&lt;h2 id=&#34;全序关系广播total-oder-broadcast&#34;&gt;全序关系广播（Total Oder Broadcast）&lt;/h2&gt;
&lt;p&gt;全序关系广播指节点间交换消息的某种协议，要求满足以下两个基本安全属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可靠发送：没有消息丢失，如果消息发送到了一个节点，也必须要发送到其他节点。&lt;/li&gt;
&lt;li&gt;严格有序：消息总是以相同的顺序发送给每个节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;即使节点或者网络发生故障，全序关系广播算法的正确实现也必须保证上述两条。在网络中断时发送失败的消息，在恢复之后要继续重试。&lt;/p&gt;
&lt;p&gt;全序关系广播正是数据库复制所需要的：如果每条消息代表数据库写请求，并且每个副本都按照相同的顺序处理这些写请求，那么所有副本可以保持一致。该原则称为“状态机复制”，ZK和etcd这样的服务就实现了全序关系广播。&lt;/p&gt;
&lt;p&gt;理解全序关系广播的另一种方式是将其视为日志（如复制日志），传递消息就像追加方式更新日志。由于所有节点必须以相同的顺序发送消息，因此所有节点都可以获取日志并看到相同的消息序列。&lt;/p&gt;
&lt;h1 id=&#34;分布式事务与共识&#34;&gt;分布式事务与共识&lt;/h1&gt;
&lt;h3 id=&#34;两阶段提交two-phase-commit简称2pc&#34;&gt;两阶段提交（two-phase commit，简称2PC）&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190406-ddia-chapter09-consistency-and-consensus/9-9.jpg&#34; alt=&#34;9-9&#34; title=&#34;9-9&#34;&gt;&lt;/p&gt;
&lt;p&gt;以上是简单的2PC的操作示意图，图中引入了一个协调者（Coordinator）的角色。当应用程序开始提交事务时，协调者开始阶段1：发送一个准备请求给事务中的参与者，询问是否可以提交。协调者然后跟踪参与者的回应：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果所有参与者都应答”是“，表示它们已经准备好提交，协调者接下来在阶段2发出提交请求，提交才开始执行。&lt;/li&gt;
&lt;li&gt;如果任何参与者回答了”否“，则协调者在阶段2中向所有节点发送放弃请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果参与者在2PC期间失败，那么协调者将中断事务提交；如果在第二阶段发送提交时失败，协调者将无限期重试。&lt;/p&gt;
&lt;h3 id=&#34;2pc的原理&#34;&gt;2PC的原理&lt;/h3&gt;
&lt;p&gt;以下详细分解2PC流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;启动分布式事务时，首先向协调者请求事务ID，该ID全局唯一。&lt;/li&gt;
&lt;li&gt;在每个参与节点上执行单节点事务，并将全局唯一事务ID附加到事务上。此时，读写都是在单节点内完成的，如果这个阶段出现问题，如节点崩溃或者请求超时，则协调者和其他参与者都可以安全中止。&lt;/li&gt;
&lt;li&gt;当准备提交事务时，协调者向所有参与者发送准备请求，并附带全局事务ID，如果准备请求有任何一个发生问题，协调者可以通知参与者放弃事务。&lt;/li&gt;
&lt;li&gt;参与者在收到准备请求之后，确保在任何情况下都可以提交事务，包括安全地将事务数据写入磁盘。一旦协调者回答“是”，节点就提交事务。&lt;/li&gt;
&lt;li&gt;当协调者收到所有准备请求的答复时，就是否提交（或放弃） 事务做出明确的决定（即只有所有参与者都投赞成票时才会提交）。协调者将最后的决定写入磁盘，这个时刻称为“提交点（commit point）”。&lt;/li&gt;
&lt;li&gt;协调者决定写入磁盘之后，向所有参与者发送提交请求。如果请求失败，就需要一直重试。此时，所有节点不允许有任何反悔。一旦做出了决定，就必须执行，即使需要重试。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由此可见，该协议两个关键的“不归路”：首先，当参与者投票“是”时，做了肯定提交的承诺；其次，协调者做了提交的决定之后，这个决定也是不可撤销的。&lt;/p&gt;
&lt;p&gt;正是以上两点保证了2PC的原子性，而单节点事务提交实际上将两个事件合二为一，写入事务日志即提交。&lt;/p&gt;
&lt;h3 id=&#34;协调者发生故障&#34;&gt;协调者发生故障&lt;/h3&gt;
&lt;p&gt;但是，如果是协调者自身发生了故障，后面的行为无法预计，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190406-ddia-chapter09-consistency-and-consensus/9-10.jpg&#34; alt=&#34;9-10&#34; title=&#34;9-10&#34;&gt;&lt;/p&gt;
&lt;p&gt;2PC能够顺利完成的唯一方法是等待协调者恢复，这就是为什么协调者必须在向参与者发送提交请求之前需要先写入磁盘事务的日志：这是因为一旦协调者崩溃，恢复之后可以根据读取事务日志来确定所有未决的事务。&lt;/p&gt;
&lt;h1 id=&#34;支持容错的共识算法&#34;&gt;支持容错的共识算法&lt;/h1&gt;
&lt;p&gt;所有支持容错的共识算法都有以下的性质：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;协商一致性（Uniform agreement）：所有的节点都接受相同的决议。&lt;/li&gt;
&lt;li&gt;诚实性（Integrity）：所有节点都不能反悔，即对一项决议不能有两次不同的结果。&lt;/li&gt;
&lt;li&gt;合法性（Validity）：如果决定了v值，则v一定是某个节点所提议的。即：不能有一个凭空的决议产生。&lt;/li&gt;
&lt;li&gt;可终止性（Termination）：节点如果不崩溃则最终一定可以达成协议。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;协商一致性和诚实性属性定义了共识算法的核心思想：决定一致的结果，而一旦决定就不能再变更决定。
有效性属性排除了无意义的方案。&lt;/p&gt;
&lt;p&gt;如果不考虑容错性，以上三点很容易实现：强行指定某个节点为”独裁者“，由它做出所有的决定。但是，如果该节点失败，系统就无法再继续做出任何决定。这就是在2PC时看到的：如果协调者失败了，那些处于不确定状态的参与者无从知道应该怎么做。&lt;/p&gt;
&lt;p&gt;可终止性引入了容错的思想。它强调一个共识算法不能原地空转，永远不做事情。即使某些节点出现了故障，其它节点也必须最终做出决定。&lt;/p&gt;
&lt;p&gt;因此，可终止性属于一种活性属性（liveness property），而其它三个性质属于安全性方面的属性。&lt;/p&gt;
&lt;p&gt;任何共识性算法，都需要至少大部分节点正确运行才能保证终止性，这个”大多数节点“又被称为”quorum“。&lt;/p&gt;
&lt;p&gt;因此，可终止性的前提是，发生崩溃或者不可用的节点必须小于小半数节点。另外，共识算法也界定系统不存在拜占庭错误。&lt;/p&gt;
&lt;h2 id=&#34;共识算法与全序广播&#34;&gt;共识算法与全序广播&lt;/h2&gt;
&lt;p&gt;共识算法一般都是：决定了一系列值，然后采用全序关系广播算法传播数据。&lt;/p&gt;
&lt;p&gt;全序广播的要点是：消息按照相同的顺序发送到所有节点，有且只有一次。&lt;/p&gt;
&lt;p&gt;所以，全序广播算法相当于持续的多轮共识：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由于协商一致性，所有节点决定以相同顺序发送相同的消息。&lt;/li&gt;
&lt;li&gt;由于诚实性：消息不能重复。&lt;/li&gt;
&lt;li&gt;由于合法性，消息不能被破坏和捏造。&lt;/li&gt;
&lt;li&gt;由于可终止性，消息不能丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;主从复制与共识&#34;&gt;主从复制与共识&lt;/h2&gt;
&lt;p&gt;主从复制，也是所有写入操作由主节点负责，并以相同顺序发送到从节点来保持副本数据更新，为什么那时候没有考虑共识问题？&lt;/p&gt;
&lt;p&gt;如果主节点由人手动选择和配置，那就是一个独裁性质的一致性算法，出现故障的时候需要人工干预。&lt;/p&gt;
&lt;p&gt;然而，共识算法由需要首先选择出一个主节点来，否则会出现脑裂问题。如何选举主节点呢？&lt;/p&gt;
&lt;h2 id=&#34;epoch和quorum&#34;&gt;epoch和quorum&lt;/h2&gt;
&lt;p&gt;共识算法中，每个协议会定义一个世代编号（epoch number），这个编号是递增唯一的，对应于paxos中的ballot number、vsp中的view number、raft中的term number。&lt;/p&gt;
&lt;p&gt;当主节点失效时，马上进行一轮新的投票来选举出新的主节点。选举会赋予一个单调递增的epoch号，如果出现不同的主节点，那么就看谁的epoch号更大的胜出。&lt;/p&gt;
&lt;p&gt;在主节点做出任何决定之前，必须首先检查是否存在比它更高的epoch号，如何检查呢？基于前面做分布式系统的一个准则”真理由多数决定“，节点不能依靠自己掌握的信息来决策，而应该从quorum节点中收集投票。节点只有当没有发现更高epoch的主节点存在的情况下，才会对当前的提议进行投票。&lt;/p&gt;
&lt;p&gt;因此实际上这里是两轮不同的投票：首先投票决定谁是主节点，然后是对主节点的提议进行投票。&lt;/p&gt;
&lt;p&gt;投票过程看起来像2PC，区别在于：2PC的协调者不是依靠选举产生；另外共识算法只需要收到quorum节点的应答就可以通过决议，而2PC需要所有参与者都通过才能通过决议。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>《数据密集型应用系统设计》第八章《分布式系统的挑战》笔记</title>
      <link>https://www.codedump.info/post/20190405-ddia-chapter08-the-trouble-with-distributed-system/</link>
      <pubDate>Tue, 16 Apr 2019 21:03:16 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20190405-ddia-chapter08-the-trouble-with-distributed-system/</guid>
      
      <description>&lt;p&gt;本章描述分布式系统中可能出现的各种问题。&lt;/p&gt;
&lt;h1 id=&#34;故障与部分失效&#34;&gt;故障与部分失效&lt;/h1&gt;
&lt;p&gt;单机上的程序，以一种确定性的方式运行：要么工作，要么出错。&lt;/p&gt;
&lt;p&gt;然而涉及到多台节点时，会出现系统的一部分正常，一部分异常的情况，称为“部分故障（partial failure）”。&lt;/p&gt;
&lt;p&gt;正是由于这种不确定性和部分失效大大提高了分布式系统的复杂性。&lt;/p&gt;
&lt;h1 id=&#34;不可靠的网络&#34;&gt;不可靠的网络&lt;/h1&gt;
&lt;p&gt;分布式系统中的多个节点以网络进行通信，但是网络并不保证什么时候到达以及是否一定到达。等待响应的过程中，很多事情可能出错：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请求可能丢失。&lt;/li&gt;
&lt;li&gt;请求在某个队列里等待，无法马上发送。&lt;/li&gt;
&lt;li&gt;远程节点因为崩溃、宕机等原因已经失效。&lt;/li&gt;
&lt;li&gt;远程节点因为某些原因暂时无法响应。&lt;/li&gt;
&lt;li&gt;远程节点接收并且处理了请求，但是回复却丢失了。&lt;/li&gt;
&lt;li&gt;远程节点已经完成了请求，但是回复被延迟了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190405-ddia-chapter08-the-trouble-with-distributed-system/8-1.jpg&#34; alt=&#34;8-1&#34; title=&#34;8-1&#34;&gt;&lt;/p&gt;
&lt;p&gt;在上图中，请求没有得到响应，但是无法区分是因为什么原因，可能有：请求丢失、远程节点关闭、响应丢失等情况。&lt;/p&gt;
&lt;p&gt;从以上可以知道，异步网络中的消息没有得到响应，但是无法判断具体的原因。&lt;/p&gt;
&lt;p&gt;处理这种问题通常采用超时机制：在等待一段时间之后，如果没有收到回复则选择放弃，并且认为响应不会到达。&lt;/p&gt;
&lt;h2 id=&#34;检测网络故障&#34;&gt;检测网络故障&lt;/h2&gt;
&lt;p&gt;如果超时是检测网络故障的唯一可行方法，那么这个超时时间应该如何选择？&lt;/p&gt;
&lt;p&gt;太小：出现误判的情况。太大：意味着要很长时间才能宣布节点失效了。&lt;/p&gt;
&lt;p&gt;假设有一个虚拟的系统，网络可以保证数据报在一个最大延迟范围内：要么在时间d内交付完成，要么丢失。此外，非故障节点在时间r内完成请求的处理。此时，就可以确定成功的请求总是在2d+r时间内完成，因此这个时间是一个理想超时时间。&lt;/p&gt;
&lt;h2 id=&#34;同步网络和异步网络&#34;&gt;同步网络和异步网络&lt;/h2&gt;
&lt;p&gt;既然同步网络可以在规定的延迟时间内完成数据的发送，且不会丢失数据包，那么为什么分布式系统没有选择同步网络，在硬件层面就解决网络问题？&lt;/p&gt;
&lt;p&gt;原因在于，固定电话网络中的电路与TCP连接存在很大的不同：电路方式总是预留固定带宽，在电路建立之后其他人无法使用；而TCP连接的数据包则会尝试使用所有可用的网络带宽。TCP可以传送任意大小可变的数据块，会尽力在最短时间内完成数据传送。&lt;/p&gt;
&lt;h1 id=&#34;不可靠的时钟&#34;&gt;不可靠的时钟&lt;/h1&gt;
&lt;p&gt;很多操作依赖时间，但是时间也是靠不住的，本节就是说这部分的内容。&lt;/p&gt;
&lt;p&gt;计算机的时钟分为两种，墙上时钟（time-of-day clock）和单调时钟（monotonic clock），但是两者在使用上是有区别的。&lt;/p&gt;
&lt;p&gt;墙上时钟根据某个日历（也称为墙上时间，wall-clock time）返回当前的日期和时间。比如Linux的系统调用clock_gettime(CLOCK_REALTIME)返回自1970年1月1日以来的秒数和毫秒数。&lt;/p&gt;
&lt;p&gt;单调时钟更适合用于测试持续时间段（时间间隔），Linux的系统调用clock_gettime(CLOCK_MONITONIC)返回的就是单调时钟。单调时钟的名字源于它们总是保证向前走而不会出现回拨现象。&lt;/p&gt;
&lt;p&gt;可以在一个时间点读取单调时钟的值，完成某项工作然后再次检查时钟，时钟之间的插值就是两次检查的时间间隔。&lt;/p&gt;
&lt;p&gt;但是，单调时钟的绝对值没有任何意义。&lt;/p&gt;
&lt;p&gt;单调时钟不需要同步，而墙上时钟需要根据NTP服务器或外部时间源做调整。&lt;/p&gt;
&lt;h2 id=&#34;依赖时钟的同步&#34;&gt;依赖时钟的同步&lt;/h2&gt;
&lt;p&gt;某些操作强依赖时钟的同步，这里往往容易出现问题，这一节就是列举这些问题。&lt;/p&gt;
&lt;h3 id=&#34;时间戳与事件顺序&#34;&gt;时间戳与事件顺序&lt;/h3&gt;
&lt;p&gt;一个常见的功能：跨节点的事件排序，如果高度依赖时钟计时，就存在一定的技术风险。比如，两个客户端同时写入数据库，谁先到达，哪个操作是最新的？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190405-ddia-chapter08-the-trouble-with-distributed-system/8-3.jpg&#34; alt=&#34;8-3&#34; title=&#34;8-3&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，客户端A写入x=1的时间是42.004秒，而客户端B写入x+=1即x=2虽然在后面发生但是时间是42.003秒。节点2在收到这两个事件时，会根据时间戳错误的认为x=1是最新的值，丢弃了x=2的值。&lt;/p&gt;
&lt;p&gt;这种冲突解决方式称为“最后写入获胜（Last Write Win）”，但是这样保持“最新”值并丢弃其他值的做法，由于“最新”的定义强依赖于墙上时钟，则会引入偏差。&lt;/p&gt;
&lt;h3 id=&#34;时钟的置信区间&#34;&gt;时钟的置信区间&lt;/h3&gt;
&lt;p&gt;不应该把墙上时间视为一个精确的时间点，而更应该被视为带有置信区间的时间范围。比如，系统有95%的置信度认为目前时间在[10.3,10.5]秒之间。&lt;/p&gt;
&lt;p&gt;比如Google Spanner中的TrueTime API，在查询当前时间时，会得到两个值：[不早于，不晚于]分别代表误差的最大偏差范围。&lt;/p&gt;
&lt;h2 id=&#34;进程暂停&#34;&gt;进程暂停&lt;/h2&gt;
&lt;p&gt;另外一个分布式系统中危险使用时钟的例子：假设数据库每个分区只有一个主节点，只有主节点可以接收写入，那么其它节点该如何确信该节点没有被宣告失效，可以继续安全写入呢？&lt;/p&gt;
&lt;p&gt;一种思路是主节点从其它节点获得一个租约，类似一个带有超时的锁。某一个时间只有一个节点可以拿到租约，某节点获得租约之后，在租约到期之前，它就是这段时间内的主节点。为了维持主节点的身份，节点必须在到期之前定期去更新租约。如果节点发生了故障，则续约失败，这样另一个节点到期之后就可以接管。&lt;/p&gt;
&lt;p&gt;典型流程类似这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190405-ddia-chapter08-the-trouble-with-distributed-system/8-renew-lease.jpg&#34; alt=&#34;8-renew-lease&#34; title=&#34;8-renew-lease&#34;&gt;&lt;/p&gt;
&lt;p&gt;这段代码有几个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;依赖于同步的时钟，租约到期时间由另一台机器锁设置，并和本地时间进行比较。如果两者有比较大的误差则可能出现问题。&lt;/li&gt;
&lt;li&gt;代码中假定了检查点的system.currentTimeMillis()和请求处理process(request)间隔很短。但是，如果进程由于GC等原因被暂停，也有可能发生问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;知识真相与谎言&#34;&gt;知识、真相与谎言&lt;/h1&gt;
&lt;p&gt;以上阐述了分布式系统中的网络、时钟都不是很靠谱，那么分布式系统中什么信息才具有较大的可信度呢？&lt;/p&gt;
&lt;p&gt;在分布式系统中，我们可以明确列出对系统行为（系统模型）的若干假设，然后以满足这些假设条件来为目标构建实际运行的系统。在给定系统模型下，可以验证算法的正确性。这也意味着即使底层模型仅提供少数几个保证，也可以在系统软件层面实现可靠的行为保证。&lt;/p&gt;
&lt;h2 id=&#34;真相由多数决定&#34;&gt;真相由多数决定&lt;/h2&gt;
&lt;p&gt;节点不能根据自己的信息来判断自身的状态。由于节点可能随时会失效，可能会暂停、假死，甚至最终无法恢复，因此分布式系统不能完全依赖于单个节点。目前，许多分布式算法都依靠法定票数，即在节点之间进行投票。任何决策都需要来自多个节点的最小投票数，从而减少对特定节点的依赖。&lt;/p&gt;
&lt;p&gt;这其中也包括宣告某个节点失效。如果有法定数量的节点声明另一个节点失效，即使该节点仍然感觉自己存活，也必须接受失效的裁定进行下线操作。&lt;/p&gt;
&lt;h2 id=&#34;主节点与锁&#34;&gt;主节点与锁&lt;/h2&gt;
&lt;p&gt;有很多情况下，需要在系统范围内确保只有一个实例，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只允许一个节点做为数据库分区的主节点，以防止出现脑裂现象。&lt;/li&gt;
&lt;li&gt;只允许一个事务或客户端持有特定资源的锁，以防止同时写入。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在分布式系统中，即使某个节点自认为自己是“唯一的那个”，但并不一定系统中的多数节点都这么认为。当系统中的多数节点认为某节点已经失效，但是该节点还继续充当“唯一的那个”节点工作时，就可能出现问题。&lt;/p&gt;
&lt;p&gt;如下图中所示，客户端1的锁租约已经到期，但是仍然自认为有效，导致了数据被破坏。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190405-ddia-chapter08-the-trouble-with-distributed-system/8-4.jpg&#34; alt=&#34;8-4&#34; title=&#34;8-4&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;fencing与锁&#34;&gt;Fencing与锁&lt;/h2&gt;
&lt;p&gt;当使用锁和租约机制来保护资源的并发访问时，必须确保过期的“唯一的那个”节点不影响其他正常部分。要实现这一点，可以使用fencing（栅栏，隔离之意）技术。&lt;/p&gt;
&lt;p&gt;假设每次锁服务在授予锁或租约时，还会返回一个fencing令牌，该令牌每次授予都会递增。然后，客户端每次向存储系统发起写请求时，都必须包含所持有的fencing令牌。&lt;/p&gt;
&lt;p&gt;如下图所示，客户端1获得锁租约的时候得到了令牌33，随后陷入长时间暂停直到租约到期。此时客户端2获得了新的锁租约和令牌34。客户端1恢复之后尝试进行写请求，但是此时带上的令牌33小于34，所以被拒绝写操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190405-ddia-chapter08-the-trouble-with-distributed-system/8-5.jpg&#34; alt=&#34;8-5&#34; title=&#34;8-5&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;拜占庭故障&#34;&gt;拜占庭故障&lt;/h2&gt;
&lt;p&gt;fencing令牌可以用于检测并阻止无意的误操作，但是当节点有意故意破坏系统时，在发送消息时就可以故意伪造令牌了。&lt;/p&gt;
&lt;p&gt;在不信任的环境中需要达成共识的问题被称为拜占庭将军问题。&lt;/p&gt;
&lt;h1 id=&#34;理论系统模型与现实&#34;&gt;理论系统模型与现实&lt;/h1&gt;
&lt;p&gt;算法的实现不能过分依赖特定的硬件和软件配置。这就要求我们对预期的系统错误进行形式化描述，通过定义一些系统模型来形式化描述算法的前提条件。&lt;/p&gt;
&lt;p&gt;在计时方面，有三种常见的模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同步模型：同步模型假定有上界的网络延迟，有上界的进程暂停和有上界的时钟误差。注意，这并不意味着完全同步的时钟或网络延迟为0.只是意味着清楚的了解网络延迟、暂停和时钟漂移不会超过某个固定的上界。&lt;/li&gt;
&lt;li&gt;部分同步模型：部分同步意味着系统在大多数情况下像一个同步系统一样运行，但有时候会超出网络延时，进程暂停和时钟漂移的预期上界。这是一个比较现实的模型：大多数情况下，网络和进程比较稳定，但是必须考虑到任何关于时机的假设都有偶尔违背的情况，而一旦发生，网络延迟、暂停和时钟偏差都可能会变得非常大。&lt;/li&gt;
&lt;li&gt;异步模型：在这个模型中，一个算法不会对时机做任何假设，甚至里面根本没有时钟（也没有超时机制）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了计时模型，还需要考虑到节点失效，有以下三种常见的节点失效系统模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;崩溃中止模型：在这个模型中，算法假设一个节点以一种方式发生故障，即遭遇系统崩溃。这意味着节点可能在任何时候突然停止响应，且该节点以后永远消失，无法恢复。&lt;/li&gt;
&lt;li&gt;崩溃恢复模型：节点可能在任何时候发生崩溃，且可能在一段（未知的）时间之后得到恢复并再次响应。在崩溃恢复模型中，节点上持久化存储的数据会在崩溃之后保存，而内存中的状态会丢失。&lt;/li&gt;
&lt;li&gt;拜占庭失效模型：节点可能发生任何问题，包括试图作弊和欺骗其它节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;算法的正确性&#34;&gt;算法的正确性&lt;/h2&gt;
&lt;p&gt;为了定义算法的正确性，需要描述它的属性信息，例如对于fencing令牌生成算法，有如下属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;唯一性：两个令牌请求不能获得相同的值。&lt;/li&gt;
&lt;li&gt;单调递增：如果请求x返回了令牌t1，请求y返回了令牌t2，且x在y开始之前先完成，那么t1&amp;lt;t2。&lt;/li&gt;
&lt;li&gt;可用性：请求令牌的节点如果不发生崩溃那么一定能收到响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;安全性safety和活性liveness&#34;&gt;安全性（safety）和活性（liveness）&lt;/h3&gt;
&lt;p&gt;有必要区分两种不同的属性：安全性和活性。在上面的例子中，唯一性和单调递增属于安全性，可用性属于活性。&lt;/p&gt;
&lt;p&gt;两种性质有何区别？活性的定义中通常包含暗示“最终”一词（最终一致性就是一种活性）。&lt;/p&gt;
&lt;p&gt;安全性可以理解为“没有发生意外”，活性类似“预期的事情最终一定会发生”。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果违反了安全性，可以明确指向发生的特定的时间点（例如，唯一性如果被违反，可以定位到具体哪个操作产生了重复令牌）。且一旦违反了安全性，违规行为无法撤销，破坏已实际发生。&lt;/li&gt;
&lt;li&gt;活性则反过来，可能无法明确某个具体的时间点（例如一个节点发送了一个请求，但还没有收到回应），但总是希望在未来某个时间点可以满足要求（即收到回复）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;区分安全性和活性的一个好处是可以帮助简化处理一些具有挑战性的系统模型。通常对于分布式算法，要求在所有可能的系统模型中，都必须满足安全性。也就是说，即使所有节点发生崩溃，或者整个网络中断，算法确保不能返回错误的结果。&lt;/p&gt;
&lt;p&gt;而对于活性，则存在一些必要条件。例如，只有在系统多数节点没有崩溃，以及网络最终可以恢复的前提下，才能保证可以收到响应。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>《数据密集型应用系统设计》第七章《事务》笔记</title>
      <link>https://www.codedump.info/post/20190403-ddia-chapter07-transaction/</link>
      <pubDate>Wed, 03 Apr 2019 22:33:58 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20190403-ddia-chapter07-transaction/</guid>
      
      <description>&lt;p&gt;事务提供了一种机制，应用程序可以把一组读和写操作放在一个逻辑单元里，所有在一个事务的读和写操作会被视为一个操作：要么全部失败，要么全部成功，因此应用程序不需要担心部分失败（partial failure）问题，可以安全的重试。&lt;/p&gt;
&lt;h1 id=&#34;深入理解事务&#34;&gt;深入理解事务&lt;/h1&gt;
&lt;p&gt;事务提供的安全性保证即所谓的&lt;code&gt;ACID&lt;/code&gt;，它包括以下四个要求：&lt;/p&gt;
&lt;h2 id=&#34;acid&#34;&gt;ACID&lt;/h2&gt;
&lt;h3 id=&#34;原子性atomicity&#34;&gt;原子性（Atomicity）&lt;/h3&gt;
&lt;p&gt;A（Atomicity，原子性）：在一个事务中的所有操作，要么全部成功，要么全部失败，不存在部分成功或者部分失败的情况。在出错时中断事务，前面成功的操作都会被丢弃。&lt;/p&gt;
&lt;h3 id=&#34;一致性consistency&#34;&gt;一致性（consistency）&lt;/h3&gt;
&lt;p&gt;C（Consistency，一致性）：对数据有特定的预期状态，任何数据修改必须满足这些状态约束，比如针对一个账号，账号上的款项必须保持平衡。&lt;/p&gt;
&lt;h3 id=&#34;隔离性isolation&#34;&gt;隔离性（isolation）&lt;/h3&gt;
&lt;p&gt;I（Isolation，隔离性）：并发执行的多个事务，不会相互影响。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190403-ddia-chapter07-transaction/7-1.jpg&#34; alt=&#34;7-1&#34; title=&#34;7-1&#34;&gt;
如上图中所示，两个客户端同时增加数据库的计时器，由于没有做好隔离，导致最终的结果是43而不是正确的44。&lt;/p&gt;
&lt;p&gt;ACID语义中的隔离性意味着并发执行的多个事务相互隔离，不能交叉运行。经典的数据库教材将隔离性定义为可串行化（serializability），这就意味着可以假装它是数据库上运行的唯一事务。&lt;/p&gt;
&lt;p&gt;然而实践中，由于性能问题很少使用串行化隔离。&lt;/p&gt;
&lt;h3 id=&#34;持久性durability&#34;&gt;持久性（Durability）&lt;/h3&gt;
&lt;p&gt;D（Durability，持久性）：一旦事务提交，数据将被持久化存储起来。&lt;/p&gt;
&lt;h1 id=&#34;弱隔离级别&#34;&gt;弱隔离级别&lt;/h1&gt;
&lt;p&gt;可串行化的隔离会影响性能，而很多业务不愿意牺牲性能，因而倾向于使用更弱的隔离级别。&lt;/p&gt;
&lt;p&gt;以下介绍几个常见的弱隔离级别（非串行化）。&lt;/p&gt;
&lt;h2 id=&#34;读提交read-committed&#34;&gt;读提交（read committed）&lt;/h2&gt;
&lt;p&gt;读提交是最基本的事务级别，提供两个保证：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;读数据库时，只能读到被提交成功的数据（不会读到脏数据）。&lt;/li&gt;
&lt;li&gt;写数据库时，只会覆盖已被提交成功的数据（不会脏写）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;防止脏读&#34;&gt;防止脏读&lt;/h3&gt;
&lt;p&gt;如果一个事务被中断或者没有提交成功，而另一个事务能读取到这部分没有提交成功的数据，这就是“脏读”。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190403-ddia-chapter07-transaction/7-4.jpg&#34; alt=&#34;7-4&#34; title=&#34;7-4&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图，用户2仅在用户1的事务提交成功之后，才能读取到这次事务修改的新值x=3。&lt;/p&gt;
&lt;h3 id=&#34;防止脏写&#34;&gt;防止脏写&lt;/h3&gt;
&lt;p&gt;如果先前写入的数据是尚未提交事务的一部分，而被另一个事务的写操作覆盖了，这就是脏写。通常防止脏写的办法是推迟第二个写请求，等到前面的事务操作提交。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190403-ddia-chapter07-transaction/7-5.jpg&#34; alt=&#34;7-5&#34; title=&#34;7-5&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图，alice和bob两人试图购买同一辆车。购买时需要两次数据库写入：网站需要更新买主为新买家，而同时发票也需要随之更新。
但是在上图中，车主被改成了bob，但是发票上面写的却是alice。&lt;/p&gt;
&lt;h3 id=&#34;实现读提交&#34;&gt;实现读提交&lt;/h3&gt;
&lt;p&gt;实现防脏写：数据库通常使用行级锁来防止脏写，事务想修改某个对象，必须首先获得该对象的锁，直到事务结束。&lt;/p&gt;
&lt;p&gt;实现防脏读：也可以使用前面的防脏写来实现防脏读，但是这样代价太大了。一般的方式是保存这个值的两个版本，事务没有提交之前返回旧的值，提交之后才返回新的值。&lt;/p&gt;
&lt;p&gt;然而，读锁在实际中并不可行，原因在于运行时间较长的事务导致了许多只读事务等待太长的时间。&lt;/p&gt;
&lt;p&gt;因此，大部分数据库使用7-4中的方式来防止脏读：对于每个待更新的对象，数据库都会维护其旧值和当前持有锁事务将要设置的新值两个版本。在事务提交之前返回的是旧值；仅当事务提交之后，才会切换到新的值。&lt;/p&gt;
&lt;h3 id=&#34;快照隔离级别snapshot-isolation和重复读&#34;&gt;快照隔离级别（Snapshot isolation）和重复读&lt;/h3&gt;
&lt;p&gt;尽管上面的读提交已经能解决一部分问题，但是还是有一些问题不能解决的，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190403-ddia-chapter07-transaction/7-6.jpg&#34; alt=&#34;7-6&#34; title=&#34;7-6&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，alice有两个账号，但是如果alice在转账过程中去查看账户，会发现少了100美元。&lt;/p&gt;
&lt;p&gt;原因在于：alice对两个账户的两次读操作是同一个事务，而在这两次读操作之间，还有两次写操作，在这两次写操作完成之后才进行的第二次读操作，这样读出来的数据就不一致了。&lt;/p&gt;
&lt;p&gt;这种异常现象称为”不可重复读取（nonrepeatable read）“或者”读倾斜（read skew）“问题。&lt;/p&gt;
&lt;p&gt;以上问题，并不是一个永久性问题，因为alice的账号最终会一致，然而某些场景下这种过程中的不一致现象不能接受，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;备份数据：如果备份过程中的数据不一致，就会导致永久的不一致。&lt;/li&gt;
&lt;li&gt;分析查询与完整性检查场景：如果这些查询在不同的时间点返回不一致的结果，则结果也无意义。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;快照隔离级别是解决以上问题的常见手段。每个事物都从数据库的一致性快照中读取，事务一开始看到的是最近所提交的数据，即使数据随后可能被另一个事务修改，但保证事务都只能看到该特定时间点的旧数据。&lt;/p&gt;
&lt;p&gt;快照隔离级别对于长时间运行的只读查询（如备份和分析）非常有用。如果数据在查询的同时还在发生变化，那么查询结果对应的物理含义就难以理清。而如果查询的是数据库在某时刻点所冻结的一致性快照，则查询结果非常明确。&lt;/p&gt;
&lt;h3 id=&#34;实现快照隔离级别&#34;&gt;实现快照隔离级别&lt;/h3&gt;
&lt;p&gt;快照级隔离的实现通常采用写锁来防止脏写，这意味着正在进行写操作的事务会阻止同一对象上其他事务。而读锁则不需要加锁了。从性能角度，快照级别隔离的关键点就是读操作不会阻止写操作，反之亦然。这使得数据库可以在处理正常写入的同时，在一致性快照上执行长时间的只读查询，且两者之间没有锁的竞争。&lt;/p&gt;
&lt;p&gt;考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以数据库保留了对象的多个不同的提交版本，称为MVCC（Multi Version Concurrency Control）。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190403-ddia-chapter07-transaction/7-7.jpg&#34; alt=&#34;7-7&#34; title=&#34;7-7&#34;&gt;&lt;/p&gt;
&lt;p&gt;给每个事务一个唯一的、单调递增的事务ID（txid），每当事务写入新数据的时候，所写的数据都会带上写入者的事务ID。表中的每一行的created_by字段，用于保存创建该行的事务ID；deleted_by初始为空，用于保存请求删除该行的事务ID，仅用于标记为删除。事后，仅当确认没有其他事务引用该删除行的时候，才执行真正的删除操作。&lt;/p&gt;
&lt;p&gt;上图中，账号1的最后一次写操作由事务ID 3完成，账号2的最后一次写操作由事务ID 5完成。事务ID 13的操作修改两个账号数据的时候，会同时设置上这一行的旧数据被事务13删除，同时新的数据由事务13创建。这样，事务12的针对账号2的读操作，返回的就是两个版本的数据：由事务5创建而由事务13删除的数据500，和由事务13创建的数据400，这样修改和未完成的读事务两者就被隔离而不会互相影响。&lt;/p&gt;
&lt;h3 id=&#34;一致性快照的可见性原则&#34;&gt;一致性快照的可见性原则&lt;/h3&gt;
&lt;p&gt;当事务读数据库时，通过事务ID可以决定哪些对象可见和不可见。要想对上层应用维护良好的快照一致性，需要静心考虑数据的可见性规则。如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每笔事务开始时，数据库列出所有当时尚在进行中的其他事务，然后忽略这些事务完成的部分写入，即不可见。&lt;/li&gt;
&lt;li&gt;所有中止事务所做的修改全部不可见。&lt;/li&gt;
&lt;li&gt;较晚事务ID（即晚于当前事务）所做的任何修改不可见。&lt;/li&gt;
&lt;li&gt;除此之外，其他所有的写入都对应用查询可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;换言之，仅当以下两个条件都成立，则该数据对象对事务可见：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事务开始的时刻，创建该对象的事务已经完成了提交。&lt;/li&gt;
&lt;li&gt;对象还没有被标记为删除，或者即使标记了，但是删除事务在当前事务开始时还没有完成提交。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;防止更新丢失&#34;&gt;防止更新丢失&lt;/h2&gt;
&lt;p&gt;更新丢失的典型场景：应用从数据库读取某些值，根据逻辑进行修改，然后写入新值（read-modify-write）。当有两个事务在同样的数据对象上执行类似操作时，由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一个事务修改后写入的值丢失。&lt;/p&gt;
&lt;p&gt;比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;递增计数器，或更新账户余额。&lt;/li&gt;
&lt;li&gt;对某个复杂对象的一部分内容进行修改。&lt;/li&gt;
&lt;li&gt;两个用户同时编辑一个文档。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有以下几种解决方案：&lt;/p&gt;
&lt;h3 id=&#34;原子写操作&#34;&gt;原子写操作&lt;/h3&gt;
&lt;p&gt;使用数据库提供的原子操作，比如：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  UPDATE counters SET value = value + 1 WHERE key = &amp;#39;foo&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;显示加锁&#34;&gt;显示加锁&lt;/h3&gt;
&lt;h3 id=&#34;自动检测更新丢失&#34;&gt;自动检测更新丢失&lt;/h3&gt;
&lt;p&gt;上面的原子写操作和锁都是通过强制“读-修改-写回”操作序列化串行执行来防止丢失更新，另一种思路是先让它们并发执行，但是如果检测到更新丢失，则会终止当前事务，强制回退到安全的“读-修改-写回”方式。&lt;/p&gt;
&lt;h4 id=&#34;原子比较和设置&#34;&gt;原子比较和设置&lt;/h4&gt;
&lt;p&gt;采用类似CAS（Compare-And-Swap）方式，只有在上次读取的数据没有发生变化时才允许更新，如果发生了变化，则回退到“读-修改-写回方式”。&lt;/p&gt;
&lt;p&gt;比如为了避免两人同时编辑文档，采用以下的sql更新语句：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  UPDATE wiki_pages SET content = &amp;#39;new content&amp;#39; where id = 1234 AND content = &amp;#39;old content&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;写倾斜和幻读&#34;&gt;写倾斜和幻读&lt;/h2&gt;
&lt;p&gt;当多个事务同时写入同一对象时引发了两种竞争条件，然而这些并不是并发写所引起的所有问题。&lt;/p&gt;
&lt;p&gt;如下图所示，开发一个医院轮班系统，在保证至少有一个医生在值班的情况下，可以申请休假，但是这还是会出现问题：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20190403-ddia-chapter07-transaction/7-8.jpg&#34; alt=&#34;7-8&#34; title=&#34;7-8&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图中，alice和bob是两位值班医生，两人碰巧都遇到身体不适决定请假，但是几乎同一个时刻点击了调班按钮，于是发生了上图的事情。&lt;/p&gt;
&lt;p&gt;每笔事务总是首先检查是否至少有两名医生在值班。而由于数据库使用的是快照级隔离，因此两个事务的检查都返回了两名医生，这样两个事务都得以继续执行。接着两人都更新自己的值班记录离开，两个事务都成功提交，最后的结果就是没有任何一个医生在岗。&lt;/p&gt;
&lt;h3 id=&#34;定义写倾斜&#34;&gt;定义写倾斜&lt;/h3&gt;
&lt;p&gt;这种情况称为”写倾斜“，既不是脏写，也没有导致数据丢失。两次事务更新的是不同的对象（alice和bob的值班记录），写冲突并不那么直接。&lt;/p&gt;
&lt;p&gt;可以将写倾斜问题视为一种更加广泛的更新丢失问题：即如果两个事务读取相同的一组对象，然后更新其中一部分：不同的事务可能更新不同的对象，则可能发生写倾斜；而如果不同的事务更新的是同一个对象，则可能发生脏写或更新丢失（具体取决于事件窗口）。&lt;/p&gt;
&lt;h3 id=&#34;更多写倾斜例子&#34;&gt;更多写倾斜例子&lt;/h3&gt;
&lt;h3 id=&#34;为何产生写倾斜&#34;&gt;为何产生写倾斜&lt;/h3&gt;
&lt;p&gt;写倾斜都有类似的模式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;输入一些条件，按照条件查询出满足条件的行。&lt;/li&gt;
&lt;li&gt;根据查询结果，应用层决定下一步操作。&lt;/li&gt;
&lt;li&gt;应用程序需要更新一部分数据，而这个更新操作会改变步骤2的做出决定的前提条件，即写入之后再执行步骤1的查询操作将得到不同的结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这种在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读（phantom）。&lt;/p&gt;
&lt;h3 id=&#34;实体化冲突&#34;&gt;实体化冲突&lt;/h3&gt;
&lt;h2 id=&#34;串行化&#34;&gt;串行化&lt;/h2&gt;
&lt;h2 id=&#34;可串行化的快照隔离serializability-snapshot-isolation简称ssi&#34;&gt;可串行化的快照隔离（serializability Snapshot Isolation，简称SSI）&lt;/h2&gt;
&lt;h3 id=&#34;悲观与乐观的并发控制&#34;&gt;悲观与乐观的并发控制&lt;/h3&gt;
&lt;p&gt;两阶段加锁是典型的悲观并发控制机制。基于这样的设计原则：如果某些操作可能出错，那么直接放弃，采用等待方式直到绝对安全。这与多线程编程中的互斥锁一样。&lt;/p&gt;
&lt;p&gt;某种意义上来说，串行执行是极端悲观的选择：事务执行期间，等价于事务对整个数据库持有互斥锁。&lt;/p&gt;
&lt;p&gt;相比之下，可串行化的快照隔离则是一种乐观并发控制。在这种情况下，如果可能发生潜在冲突，事务会继续执行而不是中止，寄希望于一切相安无事；而当事务提交时，数据库会检查是否确实发生了冲突，如果是的话中止事务再进行重试。&lt;/p&gt;
&lt;h3 id=&#34;基于过期的条件做决定&#34;&gt;基于过期的条件做决定&lt;/h3&gt;
&lt;p&gt;事务是基于某些前提条件而决定采取行动，在事务开始时条件成立。&lt;/p&gt;
&lt;p&gt;那么数据库如何知道查询结果是否发生了变化？可以分为以下两种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读取是否作用于一个（即将）过期的MVCC对象。&lt;/li&gt;
&lt;li&gt;检查写入是否影响即将完成的读取。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;检测是否读取了过期的mvcc对象&#34;&gt;检测是否读取了过期的MVCC对象&lt;/h4&gt;
</description>
      
    </item>
    
    <item>
      <title>《数据密集型应用系统设计》第六章数据分区笔记</title>
      <link>https://www.codedump.info/post/20181124-ddia-chapter06-partitioning/</link>
      <pubDate>Tue, 02 Apr 2019 22:17:24 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20181124-ddia-chapter06-partitioning/</guid>
      
      <description>&lt;h1 id=&#34;键值数据的分区&#34;&gt;键值数据的分区&lt;/h1&gt;
&lt;h2 id=&#34;基于关键字区间的分区&#34;&gt;基于关键字区间的分区&lt;/h2&gt;
&lt;p&gt;给每个分区分配一段连续的关键字或者关键字区间（以最小值和最大值来指示），从关键字区间的上下限可以确定哪个分区包含这些关键字。&lt;/p&gt;
&lt;p&gt;关键字的区间段不一定要均匀分布，这是因为数据本身可能就不是均匀的。比如，某些分区包含以A和B开头字母的键，而某些分区包含了T、U、V、X、Y和Z开始的单词。&lt;/p&gt;
&lt;p&gt;基于关键字的区间分区的缺点是某些访问模式会导致热点（hot spot）。比如关键字是时间戳，分区对应一个时间范围，那么可能会出现所有的写入操作都集中在同一个分区（比如当天的分区），而其他分区始终处于空闲状态。&lt;/p&gt;
&lt;p&gt;为了避免类似的问题，需要使用时间戳以外的其他内容作为关键字的第一项。&lt;/p&gt;
&lt;h2 id=&#34;基于关键字hash值分区&#34;&gt;基于关键字Hash值分区&lt;/h2&gt;
&lt;p&gt;基于关键字Hash值分区，可以解决上面提到的数据倾斜和热点问题，但是丧失了良好的区间查询特性。&lt;/p&gt;
&lt;h2 id=&#34;负载倾斜和热点&#34;&gt;负载倾斜和热点&lt;/h2&gt;
&lt;p&gt;基于关键字Hash值分区的办法，可以减轻数据热点问题，但是不能完全避免这类问题。一种常见的极端场景是，社交网络上某个名人有几百万的粉丝，当其发布一些热点事件时可能会引起访问风暴。此时，Hash起不到任何分流的作用。&lt;/p&gt;
&lt;p&gt;大部分系统解决不了这个问题，只能通过应用层来解决这类问题。比如某个关键字被确认是热点，一个简单的技术就是在关键字的开头或结尾处添加随机数，这样将访问分配到不同的分区上。但是随之而来的问题就是，之后的任何读取都需要额外的工作，必须将这些分区上的读取数据进行合并。&lt;/p&gt;
&lt;h1 id=&#34;分区与二级索引&#34;&gt;分区与二级索引&lt;/h1&gt;
&lt;p&gt;键值类数据库的分区相对还简单一些，但是如果涉及到二级索引就变得复杂了。二级索引主要的挑战在于：它们不能规整的映射到分区中。&lt;/p&gt;
&lt;h2 id=&#34;基于文档分区的二级索引&#34;&gt;基于文档分区的二级索引&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181124-ddia-chapter06-partitioning/figure6-4.jpg&#34; alt=&#34;figure 6-4&#34; title=&#34;figure 6-4&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，数据根据ID 进行分区，但是实际查询的时候，还可以按照颜色和厂商进行过滤，所以每个分区上面还创建了颜色和厂商的索引。每次往分区中写入新数据时，自动创建这些二级索引。&lt;/p&gt;
&lt;p&gt;在这种索引方式中，每个分区完全独立。各自维护自己的二级索引。因此文档索引也成为本地索引，而不是全局索引。&lt;/p&gt;
&lt;p&gt;但是读取的时候，需要查询所有的分区数据然后进行合并才返回给客户端，这种叫分散/聚集（scatter/gather）。&lt;/p&gt;
&lt;h2 id=&#34;基于词条的二级索引&#34;&gt;基于词条的二级索引&lt;/h2&gt;
&lt;p&gt;可以对所有的数据构建全局索引，而不是每个分区维护自己的本地索引。而且吧，为了避免成为瓶颈，不能将全局索引放在一个节点上，否则又破坏了分区均衡的目标，因此全局索引数据也需要进行分区。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181124-ddia-chapter06-partitioning/figure6-5.jpg&#34; alt=&#34;figure 6-5&#34; title=&#34;figure 6-5&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，所有数据分区中的颜色进行了分区，比如从a到r开始的颜色放在了分区0中，从s到z的颜色放在了分区1中，类似的，厂商索引也被分区。这种索引方式成为词条分区（term-partitioned）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：读取高效，不需要采用scatter/gather方式对所有分区都进行查询；&lt;/li&gt;
&lt;li&gt;缺点：写入速度慢并且非常复杂，主要是因为单个文档需要更新的时候，里面可能涉及多个二级索引，而二级索引又放在不同的节点上。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在实践中，对全局二级索引数据的更新一般都是异步进行的。&lt;/p&gt;
&lt;h1 id=&#34;分区再平衡rebalancing-partitions&#34;&gt;分区再平衡（Rebalancing Partitions）&lt;/h1&gt;
&lt;p&gt;实际中，数据会发生某些变化，这时候需要将数据和请求从一个节点转移到另一个节点。这样的一个迁移负载的过程称为再平衡（rebalance）。&lt;/p&gt;
&lt;p&gt;分区再平衡至少需要满足：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平衡之后，负载、数据存储、读写请求能够在集群范围内更均匀分布。&lt;/li&gt;
&lt;li&gt;再平衡过程中，数据库可以继续处理客户端的读写请求。&lt;/li&gt;
&lt;li&gt;避免不必要的负载迁移。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面谈各种再平衡策略。&lt;/p&gt;
&lt;h2 id=&#34;为什么不能用取模&#34;&gt;为什么不能用取模？&lt;/h2&gt;
&lt;p&gt;对节点数进行取模的方式，最大的问题在于如果节点的数据发生了变化，会导致很多关键字从现有的节点迁移到另一个节点。&lt;/p&gt;
&lt;h2 id=&#34;固定数量的分区&#34;&gt;固定数量的分区&lt;/h2&gt;
&lt;p&gt;创建远超实际节点数的分区数，然后给每个节点分配多个分区。比如只有10个节点的集群，划分了1000个逻辑分区。&lt;/p&gt;
&lt;p&gt;如果集群中添加了一个新节点，该新节点就可以从每个现有节点上匀走几个分区，直到分区再次达到全局平衡。&lt;/p&gt;
&lt;p&gt;这个方式的优点在于，关键字与逻辑分区的映射关系一开始就固定下来了，节点数量的变更只是改变了逻辑分区分布在哪些节点上。节点间迁移分区数据需要时间，这个过程中，就分区依然可以处理客户端的读写请求。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181124-ddia-chapter06-partitioning/figure6-6.jpg&#34; alt=&#34;figure 6-6&#34; title=&#34;figure 6-6&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;动态分区&#34;&gt;动态分区&lt;/h2&gt;
&lt;h2 id=&#34;按节点比例分区&#34;&gt;按节点比例分区&lt;/h2&gt;
&lt;h1 id=&#34;自动与手动再平衡操作&#34;&gt;自动与手动再平衡操作&lt;/h1&gt;
&lt;h1 id=&#34;请求路由&#34;&gt;请求路由&lt;/h1&gt;
&lt;p&gt;当客户端需要发起请求时，如果知道应该连接哪个节点？如果发生了分区再平衡，分区与节点的对应关系发生了变化。&lt;/p&gt;
&lt;p&gt;这类问题属于典型的服务发现（service discover）问题。服务发现问题不限于数据库中，任何需要通过网络访问的系统都有这样的需求，尤其是服务目标需要支持高可用时。&lt;/p&gt;
&lt;p&gt;一般有以下三种处理策略。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端可以发送请求给任意节点，如果节点不能处理请求则路由到可以处理该请求的分区，应答之后再回复客户端。&lt;/li&gt;
&lt;li&gt;所有客户端的请求发送到一个路由层，由该路由层决定请求应该转发到哪个分区。&lt;/li&gt;
&lt;li&gt;客户端需要感知分区与节点之间的映射关系。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是不管是上面的哪种方案，核心问题都是：做为路由决策的组件，如何知道分区与节点的对应关系以及其变化情况？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181124-ddia-chapter06-partitioning/figure6-7.jpg&#34; alt=&#34;figure 6-7&#34; title=&#34;figure 6-7&#34;&gt;&lt;/p&gt;
&lt;p&gt;很多分布式系统依赖于独立的协调服务（比如zookeeper、etcd等）跟踪集群范围内的元数据（metadata）。如下图所示，每个节点都像zookeeper注册自己，zookeeper维护了分区到节点的最终映射关系。而其他参与者（比如路由层或者分区感知的客户端）向zookeeper订阅此信息。当分区信息发生了增删时，zookeeper会主动通知，这样就能够保持最新的状态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181124-ddia-chapter06-partitioning/figure6-8.jpg&#34; alt=&#34;figure 6-8&#34; title=&#34;figure 6-8&#34;&gt;&lt;/p&gt;
&lt;p&gt;还有另一种策略，在节点之间使用gossip协议来同步集群状态的变化，请求可以发送到任何节点，由该节点负责将其转发到正确的节点上。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>《数据密集型应用系统设计》第五章数据复制笔记</title>
      <link>https://www.codedump.info/post/20181118-ddia-chapter05-replication/</link>
      <pubDate>Mon, 01 Apr 2019 18:19:22 +0800</pubDate>
      
      <guid>https://www.codedump.info/post/20181118-ddia-chapter05-replication/</guid>
      
      <description>&lt;h1 id=&#34;主从复制&#34;&gt;主从复制&lt;/h1&gt;
&lt;p&gt;集群中有一个主节点，写操作都必须经过主节点完成，读操作主从节点都可以处理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181118-ddia-chapter05-replication/figure5-1.jpg&#34; alt=&#34;figure 5-1&#34; title=&#34;figure 5-1&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;同步复制和异步复制&#34;&gt;同步复制和异步复制&lt;/h2&gt;
&lt;h3 id=&#34;同步复制&#34;&gt;同步复制&lt;/h3&gt;
&lt;p&gt;数据在副本上落盘才返回。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：保证在副本上的数据是最新数据。&lt;/li&gt;
&lt;li&gt;缺点：延迟高，响应慢。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;异步复制&#34;&gt;异步复制&lt;/h3&gt;
&lt;p&gt;数据不保证在副本上落盘。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：延迟低&lt;/li&gt;
&lt;li&gt;不能保证在副本上的数据最新。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不能把集群中所有节点设置为同步节点，因为这样的话任何一个节点的停滞都会导致整个集群的不可用。像Paxos、Raft算法，都要求集群中大多数节点返回就可以了。部分同步、部分异步的集群配置成为半同步（semi-sync）的集群配置。&lt;/p&gt;
&lt;h2 id=&#34;新增新的从节点&#34;&gt;新增新的从节点&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;主节点生成快照数据&lt;/li&gt;
&lt;li&gt;主节点将快照数据发送到从节点。&lt;/li&gt;
&lt;li&gt;从节点请求主节点快照数据之后的数据。&lt;/li&gt;
&lt;li&gt;重复上面三步直到从节点追上主节点的进度。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;处理节点失效&#34;&gt;处理节点失效&lt;/h2&gt;
&lt;h3 id=&#34;从节点失效&#34;&gt;从节点失效&lt;/h3&gt;
&lt;p&gt;从节点崩溃恢复之后按照前面新增新的从节点的步骤来追上主节点的数据进度。&lt;/p&gt;
&lt;h3 id=&#34;主节点失效&#34;&gt;主节点失效&lt;/h3&gt;
&lt;p&gt;主节点失败时需要提升某个从节点为新的主节点，同时需要通知客户端新的主节点。&lt;/p&gt;
&lt;p&gt;自动切换主节点的步骤通常如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;确认主节点失效。大部分系统采用基于超时的机制，主从节点直接发送心跳消息，主节点在某个时间内都没有响应，则认为主节点已经失效。&lt;/li&gt;
&lt;li&gt;选举新的主节点。通过选举的方式（超过半数以上的从节点达成共识）来选举新的主节点，新的主节点是与旧的主节点数据差异最小的一个，最小化数据丢失的风险。&lt;/li&gt;
&lt;li&gt;重新配置使新的主节点上线。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;除了以上步骤之外，还有以下问题需要考虑：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果使用异步复制机制，而且在失效之前，新的主节点并没有收到旧的主节点的所有数据，那么在旧的主节点重新上线之后，未完成复制的数据将被丢弃。&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;可能会出现集群同时存在两个主节点的情况，也就是所谓的脑裂（split brain）现象，此时两个主节点都认为自己是主节点并且都能接收客户端的写数据请求，会导致数据丢失或者破坏。&lt;/li&gt;
&lt;li&gt;如何设置合理的超时时间来判断主节点失效？如果太大意味着总体恢复时间长，如果太小意味着某些情况下可能主节点并未失效但是被误判为失效了，比如网络峰值导致延迟高等原因，这样会导致很多不必要的主节点切换。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述的问题，包括节点失效、网络不可靠、副本一致性、持久性、可用性与延迟之间的各种细微的权衡，正是分布式系统核心的基本问题。&lt;/p&gt;
&lt;h2 id=&#34;复制日志的实现&#34;&gt;复制日志的实现&lt;/h2&gt;
&lt;h3 id=&#34;基于语句的复制&#34;&gt;基于语句的复制&lt;/h3&gt;
&lt;p&gt;主节点记录所执行的每个写请求并将该语句做为日志发送给从节点。但是有些场景并不适合这么做，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调用任何非确定函数的语句，比如NOW()获得当前时间，RAND()返回一个随机数。&lt;/li&gt;
&lt;li&gt;语句中使用了自增列，或者依赖于当前数据库的数据。&lt;/li&gt;
&lt;li&gt;有副作用的语句，在每个副本上面执行的效果不一样。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;基于预写日志wal&#34;&gt;基于预写日志(WAL)&lt;/h3&gt;
&lt;p&gt;将对数据库的操作写入日志，传送到从节点上然后执行，得到与主节点相同的数据副本。&lt;/p&gt;
&lt;h3 id=&#34;基于行的逻辑日志复制&#34;&gt;基于行的逻辑日志复制&lt;/h3&gt;
&lt;p&gt;所谓的逻辑日志，就是复制与存储引擎采用不同的日志格式，这样复制与存储逻辑剥离，这种日志称为逻辑日志，与物理存储引擎的数据区分开。由于逻辑日志与存储引擎逻辑上解耦，因此可以更好的向后兼容，也更好的能被外部程序解析。&lt;/p&gt;
&lt;p&gt;对于关系型数据库，其逻辑日志是一系列用来描述数据表行级别的写请求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;插入行：日志包括所有相关列的新值。&lt;/li&gt;
&lt;li&gt;删除行：日志中保证要有足够的信息来唯一标识待删除的行，通常是主键。&lt;/li&gt;
&lt;li&gt;更新行：日志中保证要有足够的信息来唯一标识待更新的行，同时也有所有列的新值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;复制滞后replication-lag问题&#34;&gt;复制滞后（replication lag）问题&lt;/h1&gt;
&lt;p&gt;如果一个应用正好从一个异步复制的从节点上读取数据，则可能读取不到最新的数据，这是因为主从节点的数据不一致导致的。理论上不一致状态在时间上并没有上限。以下描述几个复制滞后导致的问题。&lt;/p&gt;
&lt;h2 id=&#34;读自己的写reading-your-own-writes&#34;&gt;读自己的写（reading your own writes）&lt;/h2&gt;
&lt;p&gt;用户在写入数据不久就马上查看数据，而新数据并未到达从节点，这样在用户看来可能读到了旧的数据。这样情况需要“写后读一致性（read-after-write consistency）”，该机制保证每次用户读到的都是自己最近的更新数据，但是对其他用户则没有任何保证。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181118-ddia-chapter05-replication/figure5-3.jpg&#34; alt=&#34;figure 5-3&#34; title=&#34;figure 5-3&#34;&gt;&lt;/p&gt;
&lt;p&gt;在上图中，用户1234首先向主节点写入数据，SQL执行成功之后返回，而此时用户再次向从节点2发起读刚才写入数据的请求，但是却读到了旧的数据。&lt;/p&gt;
&lt;p&gt;有以下方案实现写后读一致性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果用户访问可能会被修改的内容，从主节点读取。比如社交网络的本用户首页信息只会被本人修改，访问用户自己的首页信息通过主节点，而访问其他用户的首页信息则走的从节点。&lt;/li&gt;
&lt;li&gt;如果应用大部分内容都可能被所有用户修改，则上述方法不太适用。此时需要其他机制来判断哪些请求需要走主节点，比如更新后一分钟之内的请求都走的主节点。&lt;/li&gt;
&lt;li&gt;客户端可以记住自己最近更新数据的时间戳，在请求数据时带上时间戳，如果副本上没有至少包含该时间戳的数据则转发给其他副本处理，直到能处理为止。但是在这里，“时间戳”可以是逻辑时钟（比如用来指示写入数据的日志序列号）或者实际系统时钟（而使用系统时间又将时间同步变成了一个关键点）。&lt;/li&gt;
&lt;li&gt;如果副本分布在多数据中心，必须将请求路由到主节点所在的数据中心。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;单调读monotonic-reads&#34;&gt;单调读（monotonic reads）&lt;/h2&gt;
&lt;p&gt;单调读一致性保证不会发生多次读同一条数据出现回滚（moving backward）的现象。这个是比强一致性弱，但是比最终一致性强的保证。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181118-ddia-chapter05-replication/figure5-4.jpg&#34; alt=&#34;figure 5-4&#34; title=&#34;figure 5-4&#34;&gt;&lt;/p&gt;
&lt;p&gt;在上图中，用户2345发起了两次读请求，第一次向从节点1发起的请求拿到了最新的数据，但是第二次向从节点2发起的请求得到了旧的数据，这在用户看来，数据发生了“回滚”。&lt;/p&gt;
&lt;p&gt;单调读一致性可以确保不会发生这种异常。当读取数据时，单调读保证：如果某个用户进行多次读取，则绝对不会看到数据回滚现象，即在读取到新值之后又发生读取到旧值的情况。&lt;/p&gt;
&lt;p&gt;实现单调读一致性的一种方式每个用户的每次读取都从固定的同一副本上进行读取。&lt;/p&gt;
&lt;h2 id=&#34;前缀一致读consistent-prefix-reads&#34;&gt;前缀一致读（consistent prefix reads）&lt;/h2&gt;
&lt;p&gt;前缀一致性读保证，对于一系列按照某个顺序发生的写请求，读取这些内容时也会按照当时写入的顺序来。&lt;/p&gt;
&lt;p&gt;例如，正常情况下，是如下的对话：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;poons先生：cake小姐，您能看见多远的未来？&lt;/li&gt;
&lt;li&gt;cacke小姐：通常约10秒，poons先生。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181118-ddia-chapter05-replication/figure5-5.jpg&#34; alt=&#34;figure 5-5&#34; title=&#34;figure 5-5&#34;&gt;&lt;/p&gt;
&lt;p&gt;但是在上图中，从观察者角度，数据的先后顺序发生了混淆，导致了逻辑上的混乱。&lt;/p&gt;
&lt;p&gt;这种问题是分区情况下出现的特殊问题，在分布式数据库中，不同的分区独立运行，因此不存在全局写入顺序，这就导致用户从数据库中读取数据时，可能看到数据库某部分的旧值和一部分的新值。&lt;/p&gt;
&lt;p&gt;实现前缀一致性的一种方案是确保任何具有因果顺序关系的写入都交给一个分区来完成，但是该方案真实实现起来效率不高。&lt;/p&gt;
&lt;h2 id=&#34;复制滞后的解决方案&#34;&gt;复制滞后的解决方案&lt;/h2&gt;
&lt;h1 id=&#34;多主节点复制&#34;&gt;多主节点复制&lt;/h1&gt;
&lt;h2 id=&#34;适用场景&#34;&gt;适用场景&lt;/h2&gt;
&lt;h3 id=&#34;多数据中心&#34;&gt;多数据中心&lt;/h3&gt;
&lt;p&gt;为了容忍整个数据中心级别故障或更接近用户，可以把数据库的副本横跨多个数据中心。在每个数据中心内，采用常规的主从复制方案；而在数据中心之间，由各个数据中心的主节点来负责同其他数据中心的主节点进行数据的交换、更新。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181118-ddia-chapter05-replication/figure5-6.jpg&#34; alt=&#34;figure 5-6&#34; title=&#34;figure 5-6&#34;&gt;&lt;/p&gt;
&lt;p&gt;主从复制的优缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;优点&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;性能：每个写操作可以在本地数据中心就近快速响应，采用异步复制方式将变化同步到其他数据中心。&lt;/li&gt;
&lt;li&gt;容忍数据中心失败：单个数据中心失败，不影响其他数据中心的继续运行。&lt;/li&gt;
&lt;li&gt;容忍网络问题：主从复制模型中写操作是同步操作，对数据中心之间的网络性能和稳定性等要求更高。多主节点模型采用异步复制，可以更好的容忍这类问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缺点：多个数据中心可能同时修改同一份数据，造成写冲突。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;离线客户端操作&#34;&gt;离线客户端操作&lt;/h3&gt;
&lt;p&gt;每个客户端可以认为是一个独立的数据中心，这样用户就可以在离线的状态下使用客户端，而在网络恢复之后再将数据同步到服务器。&lt;/p&gt;
&lt;h3 id=&#34;协作编辑&#34;&gt;协作编辑&lt;/h3&gt;
&lt;p&gt;允许多个用户同时编辑文档，如google docs。这样每个用户就是一个独立的数据中心了。&lt;/p&gt;
&lt;h2 id=&#34;处理写冲突&#34;&gt;处理写冲突&lt;/h2&gt;
&lt;p&gt;多主复制最大的问题就是要解决写冲突，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181118-ddia-chapter05-replication/figure5-7.jpg&#34; alt=&#34;figure 5-7&#34; title=&#34;figure 5-7&#34;&gt;&lt;/p&gt;
&lt;p&gt;两个用户同时编辑wiki页面，发生了写冲突。&lt;/p&gt;
&lt;h3 id=&#34;同步与异步冲突检测&#34;&gt;同步与异步冲突检测&lt;/h3&gt;
&lt;p&gt;如果是主从复制数据库，第二个写请求会被阻塞到第一个写请求完成。而在多主从复制模型下，两个写请求都是成功的，并且只有在之后才能检测到写冲突，而那时候要用户来解决冲突已经为时已晚了。&lt;/p&gt;
&lt;p&gt;如果要多主从复制模型来做到同步检测冲突，又失去了多主节点的优势：允许每个主节点接受写请求。&lt;/p&gt;
&lt;p&gt;因此如果确实想要做到同步检测写冲突，应该考虑使用单主节点的模型而不是多主从节点模型。&lt;/p&gt;
&lt;h3 id=&#34;避免冲突&#34;&gt;避免冲突&lt;/h3&gt;
&lt;p&gt;如果应用层能保证针对特定的一条记录，每次修改都经过同一个主节点，就能避免写冲突问题。&lt;/p&gt;
&lt;p&gt;但是，在数据中心发生故障，不得不路由请求到另外的数据中心，或者用户漫游到了另一个位置，更靠近另一个数据中心等场景下，冲突避免不再有效。&lt;/p&gt;
&lt;h3 id=&#34;收敛于一致状态&#34;&gt;收敛于一致状态&lt;/h3&gt;
&lt;p&gt;有以下方式解决冲突的收敛：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给每个写入分配唯一的ID，如时间戳、足够长的随机数、UUID等，规定只有高ID的写入做为胜利者。如果是基于时间戳的对比，这种技术被称为后写入者获胜（last write win），但是很容易造成数据丢失。&lt;/li&gt;
&lt;li&gt;给每个副本分配一个唯一的ID，并制定规则比如最高ID的副本写入成功，这种方式也会导致数据丢失。&lt;/li&gt;
&lt;li&gt;以某种方式将这些值合并在一起。&lt;/li&gt;
&lt;li&gt;使用预定义的格式将这些冲突的值返回给应用层，由应用层来解决。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;自定义冲突解决逻辑&#34;&gt;自定义冲突解决逻辑&lt;/h3&gt;
&lt;p&gt;解决冲突最合适的方式还是依靠应用层，可以在写入或者读取时执行。&lt;/p&gt;
&lt;h2 id=&#34;拓扑结构&#34;&gt;拓扑结构&lt;/h2&gt;
&lt;h1 id=&#34;无主节点复制&#34;&gt;无主节点复制&lt;/h1&gt;
&lt;p&gt;放弃主节点，允许所有节点处理来自客户端的写请求，如Dynamo、Riak等。&lt;/p&gt;
&lt;h2 id=&#34;节点失效时写入数据库&#34;&gt;节点失效时写入数据库&lt;/h2&gt;
&lt;p&gt;对于无主节点复制的集群而言，当向有三个副本的集群写入数据时，只要其中有两个副本写入完成则认为写入成功，而可以容忍其中一个节点的失效。那么当这个失效节点重新上线时，则可能读到已经过期的数据。为了解决这个问题，当客户端从集群中读取数据时，并不是只向一个副本发起请求，而是并行地发送到多个副本，客户端可以根据数据版本号来确定哪个数据最新。&lt;/p&gt;
&lt;h2 id=&#34;读写quorum&#34;&gt;读写quorum&lt;/h2&gt;
&lt;p&gt;在有三个副本的情况下，如果有两个副本写入成功，那么意味着最多有一个副本可能包含旧的值，此时如果向至少两个副本发起读请求，通过版本号可以确定至少有一个包含新的值。&lt;/p&gt;
&lt;p&gt;推而广之，如果有n个副本，写入需要w个节点确认，读取必须至少查询r个节点，则只需要w+r&amp;gt;n，那么读取的节点中一定包含新值。&lt;/p&gt;
&lt;p&gt;上述参数通常是可以配置，比如n取奇数值，而r、w去(n+1)/2。也可以根据业务需求灵活配置，比如对于读多写少的业务，设置w=n或者r=1，这样读取速度更快，但是只要一个节点的写入失败而导致quorum写入失败。&lt;/p&gt;
&lt;h2 id=&#34;quorum一致性的局限性&#34;&gt;quorum一致性的局限性&lt;/h2&gt;
&lt;h2 id=&#34;检测并发写&#34;&gt;检测并发写&lt;/h2&gt;
&lt;p&gt;请求在不同节点上可能会呈现出不同的顺序，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181118-ddia-chapter05-replication/figure5-12.jpg&#34; alt=&#34;figure 5-12&#34; title=&#34;figure 5-12&#34;&gt;&lt;/p&gt;
&lt;p&gt;客户端A和B同时发起向主键X的写请求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点1收到客户端A的写请求，但是由于节点紧接着就失效了，没有收到客户端B的写请求。&lt;/li&gt;
&lt;li&gt;节点2首先收到A的写请求，接着才收到B的写请求。&lt;/li&gt;
&lt;li&gt;节点3与2相反，先收到B再收到A的写请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果处理方式仅仅是每次收到新的写请求就简单覆盖原来的值，那么这些节点永远也无法达成一致。&lt;/p&gt;
&lt;p&gt;所以需要一种更合理的方式来解决并发写冲突。&lt;/p&gt;
&lt;h3 id=&#34;最后写入者胜出last-write-win简称lww&#34;&gt;最后写入者胜出（Last Write Win，简称LWW）&lt;/h3&gt;
&lt;p&gt;为每个写请求附件一个时间戳，然后选择最新即最大的时间戳，丢弃较早时间戳的写入，这种方案称为Last Write Win。&lt;/p&gt;
&lt;p&gt;这种方案的问题在于：物理时间本身就不可信任，一个机器上的时间到了另一个机器上并不就精准。另外，牺牲了部分的写入数据，比如某客户端写入时返回成功，但是会被后面并发写入但是被认为更晚时间的写入给覆盖掉，这样这部分认为写入成功的数据就丢失了。&lt;/p&gt;
&lt;p&gt;要确保LWW无副作用的唯一办法是：之写入一次然后写入值视为不可变。这样就能避免对同一个主键的覆盖。例如，cassandra的推荐使用方式是使用UUID做为主键，这样每个写操作都针对不同的、系统唯一的主键。&lt;/p&gt;
&lt;h3 id=&#34;happen-before关系与并发&#34;&gt;Happen-before关系与并发&lt;/h3&gt;
&lt;p&gt;两件事情A、B只有三种可能存在的关系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A在B之前发生。&lt;/li&gt;
&lt;li&gt;B在A之前发生。&lt;/li&gt;
&lt;li&gt;A、B并发进行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一件事情在另一件事情之前发生，说明两者之间存在依赖关系。比如A说了一句话，而B需要对这句话进行回应，回应这个事件就依赖于A说话这个事件，此时B的回应依赖于A的话，因此B的回应肯定发生A说话之后。&lt;/p&gt;
&lt;p&gt;如果两件事情之间没有依赖关系，那么先后顺序是无所谓的，即并发进行。&lt;/p&gt;
&lt;p&gt;来看一个实际的例子，两个客户端同时向一个购物车添加物品：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.codedump.info/media/imgs/20181118-ddia-chapter05-replication/figure5-13.jpg&#34; alt=&#34;figure 5-13&#34; title=&#34;figure 5-13&#34;&gt;&lt;/p&gt;
&lt;p&gt;流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端1首先将牛奶放入购物车，服务器分配版本号1，将值与版本号一起返回给客户端。&lt;/li&gt;
&lt;li&gt;客户端2将鸡蛋放入购物车，因为此时客户端2并不知道客户端1已经放入了牛奶，因此认为鸡蛋是购物车中的唯一物品。服务器写入并分配版本号2，将鸡蛋和牛奶存储为两个单独的值，最后将版本号2和值返回给客户端2。&lt;/li&gt;
&lt;li&gt;同理，客户端1再次写入时也没有意识到2已经修改了购物车，此时它想继续添加免费，认为此时购物车的内容应该是[牛奶,面粉]，因此将这个值与版本号1一起发给服务器。服务器收到之后，意识到是针对版本号1做的修改，即将[牛奶]修改成[牛奶面粉]，但是另一个值[鸡蛋]则是新的并发操作。因此，服务器分配了一个新的版本号3，版本号3的值[牛奶,面粉]覆盖版本1的[牛奶]，同时保留版本号2的值[鸡蛋]，一起返回给客户端1。&lt;/li&gt;
&lt;li&gt;客户端2想加入火腿，而它也不知道客户端1添加了面粉。其收到的最后一个响应中服务器给的值是[牛奶]和[鸡蛋]，因此进行了合并并且加入自己要添加的火腿，向服务器发送了版本号2以及新的值[鸡蛋,牛奶,火腿]。服务器检测到版本号2将覆盖原来的值[鸡蛋]，但是与[牛奶,面粉]是同时发生，所以设置了版本号4并将这些值一起返回给客户端2。&lt;/li&gt;
&lt;li&gt;最后，客户端1想添加培根，在以前的版本3中从服务器收到了值[牛奶,面粉]和[鸡蛋]，所以进行了合并，将添加了培根以及合并之后的值[牛奶,面粉,鸡蛋,培根]和版本号3来覆盖[牛奶,面粉]，但是由于与[鸡蛋，牛奶，火腿]并发，所以服务器会保留这些值。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;服务器判断操作是否并发的依据主要依靠版本号：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务器为每个主键维护一个版本号，每当主键新值写入时递增版本号，并将新版本号与写入的值一起保存。&lt;/li&gt;
&lt;li&gt;当客户端读取主键时，服务器将返回所有（未被覆盖）当前值以及最新的版本号，且要求写入之前，客户端必须先发送读请求。&lt;/li&gt;
&lt;li&gt;客户端写主键，写请求必须包含之前读到的版本号、读到的值和新值合并后的集合。写请求的响应可以像读请求一样，返回所有值，这样就可以像购物车例子那样一步步链接起多个写入的值。&lt;/li&gt;
&lt;li&gt;当服务器收到带有特定版本的写入时，覆盖该版本号或更低版本的所有值（因为知道这些值已经被合并到新传入的值集合中），但必须保留更高版本号的所有值（因为这些值与当前的写操作属于并发）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种方案不会让写入的值丢失，但是需要在客户端做合并操作，将多个写入的值进行合并。&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
